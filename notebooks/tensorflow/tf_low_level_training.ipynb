{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_low_level_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tensorflow/tf_low_level_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cPPSaNy-gP69",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Low Level TensorFlow, Part II: Training\n",
        "\n",
        "* https://www.tensorflow.org/guide/low_level_intro"
      ]
    },
    {
      "metadata": {
        "id": "iTAja3gRgTL5",
        "colab_type": "code",
        "outputId": "82a40e20-9c0a-4ff7-b74e-360d7dc3dd14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# import and check version\n",
        "import tensorflow as tf\n",
        "# tf can be really verbose\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c64ihdObg50w",
        "colab_type": "code",
        "outputId": "a42f642b-2fd2-4688-9086-85a1e01968ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# a small sanity check, does tf seem to work ok? \n",
        "sess = tf.Session()\n",
        "hello = tf.constant('Hello TF!')\n",
        "print(sess.run(hello))\n",
        "sess.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello TF!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-PfYL1utj2cV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## First define a computational graph composed of operations and tensors"
      ]
    },
    {
      "metadata": {
        "id": "dOUcAYf0geaR",
        "colab_type": "code",
        "outputId": "b15d81a5-8465-43df-e56a-b171aebcf0ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant(3.0, dtype=tf.float32)\n",
        "b = tf.constant(4.0) # also tf.float32 implicitly\n",
        "total = a + b\n",
        "print(a)\n",
        "print(b)\n",
        "print(total)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
            "Tensor(\"add:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3AVKQKRdkG4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Then use a session to execute the graph"
      ]
    },
    {
      "metadata": {
        "id": "zxzdtsjBhRBq",
        "colab_type": "code",
        "outputId": "006e4bb2-5c07-4c03-b89a-33dcb98f6782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# sessions need to be closed in order not to leak ressources, this makes sure close is called in any case\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(total))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwWVwSQEnRYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Graphs can be executed on CPU, GPU, and even TPU"
      ]
    },
    {
      "metadata": {
        "id": "84U3aIyckAE-",
        "colab_type": "code",
        "outputId": "d026b01b-1b0b-4c2a-ca6a-6609088ba5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# let's see what compute devices we have available, hopefully a GPU \n",
        "# if you do not see it, switch on under Runtime->Change runtime type\n",
        "with tf.Session() as sess:\n",
        "  devices = sess.list_devices()\n",
        "  for d in devices:\n",
        "      print(d.name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/job:localhost/replica:0/task:0/device:CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0\n",
            "/job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JbBI7grykjYA",
        "colab_type": "code",
        "outputId": "26ad3c97-aa1d-49aa-adf3-68bee59ebb62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:XLA_CPU:0\"):\n",
        "  with tf.Session() as sess:\n",
        "    print(sess.run(total))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eh-SNHmkszW6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feeding data to a graph"
      ]
    },
    {
      "metadata": {
        "id": "59okIq9ss2Sv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "z = x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gHCCsfZUs6L1",
        "colab_type": "code",
        "outputId": "4ff4aa26-503a-42b6-8707-0bd8c60bf8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(z))\n",
        "  except tf.errors.InvalidArgumentError as iae:\n",
        "     print(iae.message)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You must feed a value for placeholder tensor 'Placeholder' with dtype float\n",
            "\t [[node Placeholder (defined at <ipython-input-7-3b59dde2b9f0>:1)  = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
            "\t [[{{node add_1/_1}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7_add_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dBD4j4ySt_2N",
        "colab_type": "code",
        "outputId": "89054ae8-e944-48bf-9c63-d82fedc0c6e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    print(sess.run(z, feed_dict={x: 3.0, y: 4.5}))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QWgaGNB2y_Ah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading in data sets"
      ]
    },
    {
      "metadata": {
        "id": "Xn-mZWj8v80A",
        "colab_type": "code",
        "outputId": "119a2718-2139-4cf3-a3db-ceb40f2c0514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "r = tf.random_normal([10, 2])\n",
        "dataset = tf.data.Dataset.from_tensor_slices(r)\n",
        "iterator = dataset.make_initializable_iterator()\n",
        "next_row = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(iterator.initializer)\n",
        "  while True:\n",
        "    try:\n",
        "      data = sess.run(next_row)\n",
        "      print(data)\n",
        "      print(sess.run(z, feed_dict={x: data[0], y: data[1]}))\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.59269613 -1.0008177 ]\n",
            "-1.5935137\n",
            "[ 0.5592084  -0.98474556]\n",
            "-0.42553717\n",
            "[ 1.2175804  -0.80723673]\n",
            "0.4103437\n",
            "[0.28345087 0.661987  ]\n",
            "0.9454379\n",
            "[-1.2553709   0.46523964]\n",
            "-0.7901312\n",
            "[-0.2941359  1.6356422]\n",
            "1.3415062\n",
            "[-0.54164934 -1.6740425 ]\n",
            "-2.2156918\n",
            "[-0.32486457 -0.5762184 ]\n",
            "-0.901083\n",
            "[0.98022515 0.79792726]\n",
            "1.7781525\n",
            "[ 1.6103048  -0.54175496]\n",
            "1.0685499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tfiiUqmL1agX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ]
    },
    {
      "metadata": {
        "id": "0vtrxsInmMgy",
        "colab_type": "code",
        "outputId": "ca76d311-eb1a-49f1-dc36-cea87e34874b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "y = tf.layers.dense(inputs=x, units=1)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))\n",
        "  except tf.errors.FailedPreconditionError as fpe:\n",
        "    print(fpe.message)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempting to use uninitialized value dense/kernel\n",
            "\t [[node dense/kernel/read (defined at <ipython-input-11-eb68a0e5f9f4>:2)  = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel)]]\n",
            "\t [[{{node dense/BiasAdd/_3}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_dense/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xa1xPFPj2U69",
        "colab_type": "code",
        "outputId": "7e1917f3-b549-4e16-f197-c184b049e8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.8728956]\n",
            " [3.037486 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W8838NMT231q",
        "colab_type": "code",
        "outputId": "d93657c8-95fa-48cc-fdf8-ed67193e5135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "y = tf.layers.dense(inputs=x, units=2, activation=tf.nn.tanh)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.75823957 0.99993545]\n",
            " [0.99061966 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ev1OcEkRpXX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature columns\n",
        "\n",
        "transform a diverse range of raw data into formats input layers can accept\n",
        "\n",
        "* https://www.tensorflow.org/guide/feature_columns\n",
        "* https://www.tensorflow.org/api_docs/python/tf/feature_column/input_layer"
      ]
    },
    {
      "metadata": {
        "id": "qQXhw_Cc4RpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = {\n",
        "    'sales' : [[5], [10], [8], [9]],\n",
        "    'department': ['sports', 'sports', 'gardening', 'gardening']\n",
        "}\n",
        "\n",
        "# numeric values are simple\n",
        "sales_column = tf.feature_column.numeric_column('sales')\n",
        "columns = {\n",
        "   sales_column\n",
        "}\n",
        "\n",
        "inputs = tf.feature_column.input_layer(features, columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sik2BwYTl7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cfa6df44-090f-4fdd-a53d-b5f9ed8f4bf0"
      },
      "cell_type": "code",
      "source": [
        "# categories are harders, as NNs only accept dense numeric values\n",
        "\n",
        "categorical_department_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        'department', ['sports', 'gardening'])\n",
        "\n",
        "columns = {\n",
        "  sales_column,\n",
        "  categorical_department_column\n",
        "}\n",
        "\n",
        "# we can decide if we want the category to be encoded as embedding or multi-hot \n",
        "try:\n",
        "  inputs = tf.feature_column.input_layer(features, columns)\n",
        "except ValueError as ve:\n",
        "  print(ve)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Items of feature_columns must be a _DenseColumn. You can wrap a categorical column with an embedding_column or indicator_column. Given: _VocabularyListCategoricalColumn(key='department', vocabulary_list=('sports', 'gardening'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E-M3BkBTTtws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "multi_hot_department_column = tf.feature_column.indicator_column(categorical_department_column)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jzFojsKJV3RY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "columns = {\n",
        "  sales_column,\n",
        "  multi_hot_department_column\n",
        "}\n",
        "\n",
        "inputs = tf.feature_column.input_layer(features, columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl_3pPjPXWsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "249bfc03-a3cd-4259-b01e-89ce20c09bc6"
      },
      "cell_type": "code",
      "source": [
        "# feature columns also need initialization\n",
        "var_init = tf.global_variables_initializer()\n",
        "table_init = tf.tables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run((var_init, table_init))\n",
        "  # first two are departments last entry is just sales as is\n",
        "  print(sess.run(inputs))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.  0.  5.]\n",
            " [ 1.  0. 10.]\n",
            " [ 0.  1.  8.]\n",
            " [ 0.  1.  9.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cvr_yfAoYanQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c8b10057-2463-41af-feb9-4cc07373fef3"
      },
      "cell_type": "code",
      "source": [
        "# multi (one in our case) hot encoding of departments\n",
        "columns = {\n",
        "  multi_hot_department_column\n",
        "}\n",
        "\n",
        "inputs = tf.feature_column.input_layer(features, columns)\n",
        "var_init = tf.global_variables_initializer()\n",
        "table_init = tf.tables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run((var_init, table_init))\n",
        "  print(sess.run(inputs))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w9w-Imr2ZXI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "397c62e1-75c5-4a79-e054-ab76ee03228e"
      },
      "cell_type": "code",
      "source": [
        "# alternative, embedding in three dimensions\n",
        "embedding_department_column = tf.feature_column.embedding_column(categorical_department_column, dimension=3)\n",
        "columns = {\n",
        "  embedding_department_column\n",
        "}\n",
        "\n",
        "inputs = tf.feature_column.input_layer(features, columns)\n",
        "var_init = tf.global_variables_initializer()\n",
        "table_init = tf.tables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run((var_init, table_init))\n",
        "  print(sess.run(inputs))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.14460449  0.24125229 -0.10900439]\n",
            " [-0.14460449  0.24125229 -0.10900439]\n",
            " [-0.30600104  0.80903935 -0.7531071 ]\n",
            " [-0.30600104  0.80903935 -0.7531071 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VkTKGeziaOyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}