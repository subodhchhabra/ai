{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-low-level-intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tensorflow/tf_low_level_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cPPSaNy-gP69",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Low Level TensorFlow\n",
        "\n",
        "* https://www.tensorflow.org/guide/low_level_intro"
      ]
    },
    {
      "metadata": {
        "id": "iTAja3gRgTL5",
        "colab_type": "code",
        "outputId": "d0c7d7ed-2a78-4ab8-8e8e-90b19035101f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# import and check version\n",
        "import tensorflow as tf\n",
        "# normally we would switch off very verbose warnings, but in this case output from tf might be intersting to understand what is going on\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c64ihdObg50w",
        "colab_type": "code",
        "outputId": "15f20639-4071-4e8b-de70-93dd14c80dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# a small sanity check, does tf seem to work ok? \n",
        "sess = tf.Session()\n",
        "hello = tf.constant('Hello TF!')\n",
        "print(sess.run(hello))\n",
        "sess.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello TF!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-PfYL1utj2cV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## First define a computational graph composed of operations and tensors"
      ]
    },
    {
      "metadata": {
        "id": "dOUcAYf0geaR",
        "colab_type": "code",
        "outputId": "a00fbafa-4fd8-4018-c09c-df7160fb8b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant(3.0, dtype=tf.float32)\n",
        "b = tf.constant(4.0) # also tf.float32 implicitly\n",
        "total = a + b\n",
        "print(a)\n",
        "print(b)\n",
        "print(total)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
            "Tensor(\"add:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3AVKQKRdkG4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Then use a session to execute the graph"
      ]
    },
    {
      "metadata": {
        "id": "zxzdtsjBhRBq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22ee408c-fe92-4ea3-b958-4df4c2d96ed3"
      },
      "cell_type": "code",
      "source": [
        "# sessions need to be closed in order not to leak ressources, this makes sure close is called in any case\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(total))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwWVwSQEnRYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Graphs can be executed on CPU, GPU, and even TPU"
      ]
    },
    {
      "metadata": {
        "id": "84U3aIyckAE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0eda6fb2-f7d1-4e8b-ef13-f621ac36d7a5"
      },
      "cell_type": "code",
      "source": [
        "# let's see what compute devices we have available, hopefully a GPU \n",
        "# if you do not see it, switch on under Runtime->Change runtime type\n",
        "with tf.Session() as sess:\n",
        "  devices = sess.list_devices()\n",
        "  for d in devices:\n",
        "      print(d.name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/job:localhost/replica:0/task:0/device:CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0\n",
            "/job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JbBI7grykjYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e2b17a6-2fc8-43de-cfc6-8f397c22b421"
      },
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:XLA_CPU:0\"):\n",
        "  with tf.Session() as sess:\n",
        "    print(sess.run(total))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eh-SNHmkszW6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feeding data to a graph"
      ]
    },
    {
      "metadata": {
        "id": "59okIq9ss2Sv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "z = x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gHCCsfZUs6L1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6c5213db-29c3-4cdd-a817-d7eb282ae129"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(z))\n",
        "  except tf.errors.InvalidArgumentError as iae:\n",
        "     print(iae.message)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You must feed a value for placeholder tensor 'Placeholder' with dtype float\n",
            "\t [[node Placeholder (defined at <ipython-input-7-3b59dde2b9f0>:1)  = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
            "\t [[{{node add_1/_1}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7_add_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dBD4j4ySt_2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "846ec5c3-1575-4678-82c8-652f20d2b66f"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    print(sess.run(z, feed_dict={x: 3.0, y: 4.5}))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QWgaGNB2y_Ah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading in data sets"
      ]
    },
    {
      "metadata": {
        "id": "Xn-mZWj8v80A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1c36f378-a055-4c19-d327-a3212d8c076d"
      },
      "cell_type": "code",
      "source": [
        "r = tf.random_normal([10, 2])\n",
        "dataset = tf.data.Dataset.from_tensor_slices(r)\n",
        "iterator = dataset.make_initializable_iterator()\n",
        "next_row = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(iterator.initializer)\n",
        "  while True:\n",
        "    try:\n",
        "      data = sess.run(next_row)\n",
        "      print(data)\n",
        "      print(sess.run(z, feed_dict={x: data[0], y: data[1]}))\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5567033  0.59676325]\n",
            "1.1534666\n",
            "[1.5197729  0.07503483]\n",
            "1.5948077\n",
            "[1.1668001 1.7912807]\n",
            "2.9580808\n",
            "[0.03675369 2.1832776 ]\n",
            "2.2200313\n",
            "[1.202217   0.36507607]\n",
            "1.567293\n",
            "[ 0.08671668 -2.465631  ]\n",
            "-2.3789144\n",
            "[ 0.21527272 -0.00577643]\n",
            "0.20949629\n",
            "[ 1.5193942  -0.69126767]\n",
            "0.8281265\n",
            "[0.11737215 0.20017597]\n",
            "0.31754813\n",
            "[ 0.7450656  -0.49466598]\n",
            "0.25039965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tfiiUqmL1agX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ]
    },
    {
      "metadata": {
        "id": "0vtrxsInmMgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c0ee64d2-764c-4bdc-94dc-9e0d44cb3ff9"
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "y = tf.layers.dense(x, units=1)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))\n",
        "  except tf.errors.FailedPreconditionError as fpe:\n",
        "    print(fpe.message)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempting to use uninitialized value dense/kernel\n",
            "\t [[node dense/kernel/read (defined at <ipython-input-11-34fd23289168>:2)  = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel)]]\n",
            "\t [[{{node dense/BiasAdd/_3}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_dense/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xa1xPFPj2U69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70aa48b4-35ab-41e3-f63b-7253aebca957"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.82065153]\n",
            " [ 0.34443474]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W8838NMT231q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da6b66eb-4703-4ea6-d4ae-81d2f10be4ac"
      },
      "cell_type": "code",
      "source": [
        "y = tf.layers.dense(x, units=2, activation=tf.nn.tanh)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.18206427 -0.61147606]\n",
            " [-0.92939186  0.23843162]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQXhw_Cc4RpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}