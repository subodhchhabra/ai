{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-low-level-intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tensorflow/tf_low_level_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cPPSaNy-gP69",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Low Level TensorFlow\n",
        "\n",
        "* https://www.tensorflow.org/guide/low_level_intro"
      ]
    },
    {
      "metadata": {
        "id": "iTAja3gRgTL5",
        "colab_type": "code",
        "outputId": "1940dbdd-e551-487f-e179-70542efc87ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# import and check version\n",
        "import tensorflow as tf\n",
        "# normally we would switch off very verbose warnings, but in this case output from tf might be intersting to understand what is going on\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c64ihdObg50w",
        "colab_type": "code",
        "outputId": "3556939e-f886-40ea-9a2b-d8dd69348b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# a small sanity check, does tf seem to work ok? \n",
        "sess = tf.Session()\n",
        "hello = tf.constant('Hello TF!')\n",
        "print(sess.run(hello))\n",
        "sess.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello TF!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-PfYL1utj2cV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## First define a computational graph composed of operations and tensors"
      ]
    },
    {
      "metadata": {
        "id": "dOUcAYf0geaR",
        "colab_type": "code",
        "outputId": "9c729387-4318-4100-f79e-c5ced2e56faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant(3.0, dtype=tf.float32)\n",
        "b = tf.constant(4.0) # also tf.float32 implicitly\n",
        "total = a + b\n",
        "print(a)\n",
        "print(b)\n",
        "print(total)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
            "Tensor(\"add:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3AVKQKRdkG4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Then use a session to execute the graph"
      ]
    },
    {
      "metadata": {
        "id": "zxzdtsjBhRBq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09674cd5-c89d-4b09-f3a8-45bd63733c2f"
      },
      "cell_type": "code",
      "source": [
        "# sessions need to be closed in order not to leak ressources, this makes sure close is called in any case\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(total))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwWVwSQEnRYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Graphs can be executed on CPU, GPU, and even TPU"
      ]
    },
    {
      "metadata": {
        "id": "84U3aIyckAE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d8cd3ce-016f-4ae9-ad9a-af3ea8a5aeb7"
      },
      "cell_type": "code",
      "source": [
        "# let's see what compute devices we have available, hopefully a GPU \n",
        "# if you do not see it, switch on under Runtime->Change runtime type\n",
        "with tf.Session() as sess:\n",
        "  devices = sess.list_devices()\n",
        "  for d in devices:\n",
        "      print(d.name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/job:localhost/replica:0/task:0/device:CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0\n",
            "/job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JbBI7grykjYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5568bf71-f413-45d9-c708-81e112e5c0e2"
      },
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:XLA_CPU:0\"):\n",
        "  with tf.Session() as sess:\n",
        "    print(sess.run(total))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eh-SNHmkszW6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feeding data to a graph"
      ]
    },
    {
      "metadata": {
        "id": "59okIq9ss2Sv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "z = x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gHCCsfZUs6L1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "bc758d4d-2b85-4ac9-e4b5-5a8d18323c73"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(z))\n",
        "  except tf.errors.InvalidArgumentError as iae:\n",
        "     print(iae.message)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You must feed a value for placeholder tensor 'Placeholder' with dtype float\n",
            "\t [[node Placeholder (defined at <ipython-input-7-3b59dde2b9f0>:1)  = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
            "\t [[{{node add_1/_1}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7_add_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dBD4j4ySt_2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ca845b7-614f-4dbc-c28d-57731bc67cd6"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    print(sess.run(z, feed_dict={x: 3.0, y: 4.5}))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QWgaGNB2y_Ah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading in data sets"
      ]
    },
    {
      "metadata": {
        "id": "Xn-mZWj8v80A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "245b19bd-3671-4eca-d763-e8fe6c88bf8c"
      },
      "cell_type": "code",
      "source": [
        "r = tf.random_normal([10, 2])\n",
        "dataset = tf.data.Dataset.from_tensor_slices(r)\n",
        "iterator = dataset.make_initializable_iterator()\n",
        "next_row = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(iterator.initializer)\n",
        "  while True:\n",
        "    try:\n",
        "      data = sess.run(next_row)\n",
        "      print(data)\n",
        "      print(sess.run(z, feed_dict={x: data[0], y: data[1]}))\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.30656144 -0.2231097 ]\n",
            "-0.52967113\n",
            "[0.9838555 1.5583036]\n",
            "2.542159\n",
            "[-0.09219715  0.6565507 ]\n",
            "0.5643536\n",
            "[-0.32772714 -0.07921953]\n",
            "-0.40694666\n",
            "[0.32865947 0.26698926]\n",
            "0.59564877\n",
            "[-0.8940253  1.5394799]\n",
            "0.6454545\n",
            "[ 1.021821  -0.5212544]\n",
            "0.5005666\n",
            "[-1.4199775  0.6531753]\n",
            "-0.76680225\n",
            "[-0.9527003  0.7765848]\n",
            "-0.17611551\n",
            "[ 1.2446895 -0.5352399]\n",
            "0.7094496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tfiiUqmL1agX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ]
    },
    {
      "metadata": {
        "id": "0vtrxsInmMgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4fa8258b-620b-4012-ccc9-c0f608286f8f"
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "y = tf.layers.dense(inputs=x, units=1)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))\n",
        "  except tf.errors.FailedPreconditionError as fpe:\n",
        "    print(fpe.message)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempting to use uninitialized value dense/kernel\n",
            "\t [[node dense/kernel/read (defined at <ipython-input-11-eb68a0e5f9f4>:2)  = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel)]]\n",
            "\t [[{{node dense/BiasAdd/_3}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_dense/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xa1xPFPj2U69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "531dfcda-68ec-4d53-e58f-2c9a53eb474f"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -5.247522]\n",
            " [-11.800678]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W8838NMT231q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d6aecd45-34ae-4e39-923e-e63e63952120"
      },
      "cell_type": "code",
      "source": [
        "y = tf.layers.dense(inputs=x, units=2, activation=tf.nn.tanh, )\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.99962664 -0.9998242 ]\n",
            " [-0.99999994 -1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQXhw_Cc4RpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}