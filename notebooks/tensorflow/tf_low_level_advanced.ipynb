{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-low-level-intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tensorflow/tf_low_level_advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cPPSaNy-gP69",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Low Level TensorFlow, Part I: Basics\n",
        "\n",
        "* https://www.tensorflow.org/guide/low_level_intro"
      ]
    },
    {
      "metadata": {
        "id": "iTAja3gRgTL5",
        "colab_type": "code",
        "outputId": "ed895b1a-0c39-4e9a-c28a-a8755b51b965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# import and check version\n",
        "import tensorflow as tf\n",
        "# tf can be really verbose\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c64ihdObg50w",
        "colab_type": "code",
        "outputId": "f10d5590-e986-40bd-a360-617ebca10546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# a small sanity check, does tf seem to work ok? \n",
        "hello = tf.constant('Hello TF!')\n",
        "sess = tf.Session()\n",
        "print(sess.run(hello))\n",
        "sess.close()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello TF!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-PfYL1utj2cV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## First define a computational graph composed of operations and tensors\n",
        "\n",
        "* the main object you manipulate and pass around is the tf.Tensor. \n",
        "* a tf.Tensor object represents a partially defined computation that will eventually produce a value\n",
        "* tf.Tensor is a generalization of vectors and matrices to potentially higher dimensions\n",
        "* TensorFlow represents tf.Tensor as n-dimensional arrays of base datatypes\n",
        "* TensorFlow programs work by first building a graph of tf.Tensor object\n",
        "* detailing how each tensor is computed based on the other available tensors by running parts of this graph to achieve the desired results\n",
        "\n",
        "https://www.tensorflow.org/guide/tensors"
      ]
    },
    {
      "metadata": {
        "id": "dOUcAYf0geaR",
        "colab_type": "code",
        "outputId": "d3ccb7ab-9cbb-4a13-d82d-167e8a0ef788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant(3.0, dtype=tf.float32) # special type of tensor\n",
        "b = tf.constant(4.0) # also tf.float32 implicitly\n",
        "total = a + b\n",
        "print(a)\n",
        "print(b)\n",
        "print(total)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_32:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Const_33:0\", shape=(), dtype=float32)\n",
            "Tensor(\"add_12:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5fzarMAizDe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be1611da-123b-4242-8793-56558065a720"
      },
      "cell_type": "code",
      "source": [
        "# types need to match\n",
        "try:\n",
        "  tf.constant(3.0, dtype=tf.float32) + tf.constant(4, dtype=tf.int32)\n",
        "except TypeError as te:\n",
        "  print(te)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input 'y' of 'Add' Op has type int32 that does not match type float32 of argument 'x'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EHXJmwG8z2vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cbbdf6c-fa69-4cff-c966-9d068f495e84"
      },
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/dtypes/cast\n",
        "a = tf.constant(3, dtype=tf.int32)\n",
        "b = tf.cast(tf.constant(4.0, dtype=tf.float32), tf.int32)\n",
        "int_total = a + b\n",
        "int_total"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_14:0' shape=() dtype=int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "3AVKQKRdkG4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Then use a session to execute the graph"
      ]
    },
    {
      "metadata": {
        "id": "zxzdtsjBhRBq",
        "colab_type": "code",
        "outputId": "81d71b3f-5025-4517-cdac-17f5f96d26af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# sessions need to be closed in order not to leak ressources, this makes sure close is called in any case\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(total))\n",
        "  print(sess.run(int_total))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwWVwSQEnRYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Graphs can be executed on CPU, GPU, and even TPU"
      ]
    },
    {
      "metadata": {
        "id": "84U3aIyckAE-",
        "colab_type": "code",
        "outputId": "ef4edfcd-e645-4511-dc55-584f1612bbe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# let's see what compute devices we have available, hopefully a GPU \n",
        "# if you do not see it, switch on under Runtime->Change runtime type\n",
        "with tf.Session() as sess:\n",
        "  devices = sess.list_devices()\n",
        "  for d in devices:\n",
        "      print(d.name)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/job:localhost/replica:0/task:0/device:CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0\n",
            "/job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OComIhjm50ka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51fa2f5e-05b2-4d4f-c81b-ce4d6aa4c058"
      },
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "QqJqNhO46B7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c15fb115-e384-48cf-a286-560dc7d97cf9"
      },
      "cell_type": "code",
      "source": [
        "# GPU requires nvidia cuda\n",
        "tf.test.is_built_with_cuda()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "JbBI7grykjYA",
        "colab_type": "code",
        "outputId": "129da773-31fd-4785-a664-79946213c2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:XLA_CPU:0\"):\n",
        "  with tf.Session() as sess:\n",
        "    print(sess.run(total))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eh-SNHmkszW6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feeding data to a graph"
      ]
    },
    {
      "metadata": {
        "id": "59okIq9ss2Sv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "z = x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gHCCsfZUs6L1",
        "colab_type": "code",
        "outputId": "df2007ce-cb78-40ff-cf7e-83a9def59b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(z))\n",
        "  except tf.errors.InvalidArgumentError as iae:\n",
        "     print(iae.message)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You must feed a value for placeholder tensor 'Placeholder' with dtype float\n",
            "\t [[node Placeholder (defined at <ipython-input-61-3b59dde2b9f0>:1)  = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dBD4j4ySt_2N",
        "colab_type": "code",
        "outputId": "4e4b7c5c-6b10-4783-9a40-873d2b173c06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    print(sess.run(z, feed_dict={x: 3.0, y: 4.5}))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QWgaGNB2y_Ah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading in data sets (optional)"
      ]
    },
    {
      "metadata": {
        "id": "Xn-mZWj8v80A",
        "colab_type": "code",
        "outputId": "119a2718-2139-4cf3-a3db-ceb40f2c0514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "r = tf.random_normal([10, 2])\n",
        "dataset = tf.data.Dataset.from_tensor_slices(r)\n",
        "iterator = dataset.make_initializable_iterator()\n",
        "next_row = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(iterator.initializer)\n",
        "  while True:\n",
        "    try:\n",
        "      data = sess.run(next_row)\n",
        "      print(data)\n",
        "      print(sess.run(z, feed_dict={x: data[0], y: data[1]}))\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.59269613 -1.0008177 ]\n",
            "-1.5935137\n",
            "[ 0.5592084  -0.98474556]\n",
            "-0.42553717\n",
            "[ 1.2175804  -0.80723673]\n",
            "0.4103437\n",
            "[0.28345087 0.661987  ]\n",
            "0.9454379\n",
            "[-1.2553709   0.46523964]\n",
            "-0.7901312\n",
            "[-0.2941359  1.6356422]\n",
            "1.3415062\n",
            "[-0.54164934 -1.6740425 ]\n",
            "-2.2156918\n",
            "[-0.32486457 -0.5762184 ]\n",
            "-0.901083\n",
            "[0.98022515 0.79792726]\n",
            "1.7781525\n",
            "[ 1.6103048  -0.54175496]\n",
            "1.0685499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tfiiUqmL1agX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ]
    },
    {
      "metadata": {
        "id": "0vtrxsInmMgy",
        "colab_type": "code",
        "outputId": "ca76d311-eb1a-49f1-dc36-cea87e34874b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "y = tf.layers.dense(inputs=x, units=1)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  try:\n",
        "    print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))\n",
        "  except tf.errors.FailedPreconditionError as fpe:\n",
        "    print(fpe.message)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempting to use uninitialized value dense/kernel\n",
            "\t [[node dense/kernel/read (defined at <ipython-input-11-eb68a0e5f9f4>:2)  = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel)]]\n",
            "\t [[{{node dense/BiasAdd/_3}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_dense/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xa1xPFPj2U69",
        "colab_type": "code",
        "outputId": "7e1917f3-b549-4e16-f197-c184b049e8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.8728956]\n",
            " [3.037486 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W8838NMT231q",
        "colab_type": "code",
        "outputId": "d93657c8-95fa-48cc-fdf8-ed67193e5135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "y = tf.layers.dense(inputs=x, units=2, activation=tf.nn.tanh)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.75823957 0.99993545]\n",
            " [0.99061966 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ev1OcEkRpXX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature columns\n",
        "\n",
        "transform a diverse range of raw data into formats input layers can accept\n",
        "\n",
        "* https://www.tensorflow.org/guide/feature_columns\n",
        "* https://www.tensorflow.org/api_docs/python/tf/feature_column/input_layer"
      ]
    },
    {
      "metadata": {
        "id": "qQXhw_Cc4RpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = {\n",
        "    'sales' : [[5], [10], [8], [9]],\n",
        "    'department': ['sports', 'sports', 'gardening', 'gardening']\n",
        "}\n",
        "\n",
        "# numeric values are simple\n",
        "sales_column = tf.feature_column.numeric_column('sales')\n",
        "columns = {\n",
        "   sales_column\n",
        "}\n",
        "\n",
        "inputs = tf.feature_column.input_layer(features, columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sik2BwYTl7E",
        "colab_type": "code",
        "outputId": "cfa6df44-090f-4fdd-a53d-b5f9ed8f4bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# categories are harders, as NNs only accept dense numeric values\n",
        "\n",
        "categorical_department_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        'department', ['sports', 'gardening'])\n",
        "\n",
        "columns = {\n",
        "  sales_column,\n",
        "  categorical_department_column\n",
        "}\n",
        "\n",
        "# we can decide if we want the category to be encoded as embedding or multi-hot \n",
        "try:\n",
        "  inputs = tf.feature_column.input_layer(features, columns)\n",
        "except ValueError as ve:\n",
        "  print(ve)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Items of feature_columns must be a _DenseColumn. You can wrap a categorical column with an embedding_column or indicator_column. Given: _VocabularyListCategoricalColumn(key='department', vocabulary_list=('sports', 'gardening'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E-M3BkBTTtws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "multi_hot_department_column = tf.feature_column.indicator_column(categorical_department_column)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jzFojsKJV3RY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "columns = {\n",
        "  sales_column,\n",
        "  multi_hot_department_column\n",
        "}\n",
        "\n",
        "inputs = tf.feature_column.input_layer(features, columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl_3pPjPXWsu",
        "colab_type": "code",
        "outputId": "249bfc03-a3cd-4259-b01e-89ce20c09bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# feature columns also need initialization\n",
        "var_init = tf.global_variables_initializer()\n",
        "table_init = tf.tables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run((var_init, table_init))\n",
        "  # first two are departments last entry is just sales as is\n",
        "  print(sess.run(inputs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.  0.  5.]\n",
            " [ 1.  0. 10.]\n",
            " [ 0.  1.  8.]\n",
            " [ 0.  1.  9.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cvr_yfAoYanQ",
        "colab_type": "code",
        "outputId": "c8b10057-2463-41af-feb9-4cc07373fef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# multi (one in our case) hot encoding of departments\n",
        "columns = {\n",
        "  multi_hot_department_column\n",
        "}\n",
        "\n",
        "inputs = tf.feature_column.input_layer(features, columns)\n",
        "var_init = tf.global_variables_initializer()\n",
        "table_init = tf.tables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run((var_init, table_init))\n",
        "  print(sess.run(inputs))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w9w-Imr2ZXI1",
        "colab_type": "code",
        "outputId": "397c62e1-75c5-4a79-e054-ab76ee03228e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# alternative, embedding in three dimensions\n",
        "embedding_department_column = tf.feature_column.embedding_column(categorical_department_column, dimension=3)\n",
        "columns = {\n",
        "  embedding_department_column\n",
        "}\n",
        "\n",
        "inputs = tf.feature_column.input_layer(features, columns)\n",
        "var_init = tf.global_variables_initializer()\n",
        "table_init = tf.tables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run((var_init, table_init))\n",
        "  print(sess.run(inputs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.14460449  0.24125229 -0.10900439]\n",
            " [-0.14460449  0.24125229 -0.10900439]\n",
            " [-0.30600104  0.80903935 -0.7531071 ]\n",
            " [-0.30600104  0.80903935 -0.7531071 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VkTKGeziaOyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}