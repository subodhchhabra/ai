{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v10\n",
        "\n",
        "## Changes from v9\n",
        "* Fighting Overfitting as proposed in https://arxiv.org/abs/1812.02341\n",
        "  1. Batch Normalization\n",
        "  1. Encourage Exploration (increase entropy bonus again) (https://arxiv.org/pdf/1812.02341.pdf)\n",
        "  1. deeper networks (only shown for convolutions on video games)\n",
        "* As a consequence reduced training time to 1/5 as model converges really fast\n",
        "* No other real change noticeable\n",
        "\n",
        "## next steps\n",
        "* configure custom network \n",
        "  * including L2 regularization / Dropout\n",
        "  * not possible to just configure these two\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        max_paths = 4\n",
        "        self.action_space = spaces.Discrete(max_paths)\n",
        "      \n",
        "        positions = len(self.map)\n",
        "        # observations: position, reward of all 4 local paths, rest reward of all locations\n",
        "        # non existing path is -1000 and no position change\n",
        "        # look at what #getObservation returns if you are confused\n",
        "        low = np.append(np.append([0], np.full(max_paths, -1000)), np.full(positions, 0))\n",
        "        high = np.append(np.append([positions - 1], np.full(max_paths, 1000)), np.full(positions, 1000))\n",
        "        self.observation_space = spaces.Box(low=low,\n",
        "                                             high=high,\n",
        "                                             dtype=np.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = np.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=np.float32)\n",
        "        all_rest_rewards = list(self.customer_reward.values())\n",
        "        result = np.append(result, all_rest_rewards)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/2)\n",
        "#       number_per_consultant = int(number_of_customers/1.5)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "outputId": "459883b2-0c43-4d30-e0c9-f28e4f8ab290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.   700.   900.  -200. -1000.     0.  1000.  1000.     0.     0.\n",
            "  1000.     0.  1000.     0.     0.     0.     0.  1000.  1000.]\n",
            "{'S': 0, 'A': 1000, 'B': 1000, 'C': 0, 'D': 0, 'E': 1000, 'F': 0, 'G': 1000, 'H': 0, 'K': 0, 'L': 0, 'M': 0, 'N': 1000, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "f9d2c34d-ae42-4912-e560-9f33a6419c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3485
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.  1000.\n",
            "  1000.  1000.     0.  1000.  1000.     0.     0.     0.  1000.]\n",
            "Episode:    0   Step:    1  S --0-> A R=-0.05 totalR=-0.05 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    2  A --3-> D R= 0.15 totalR= 0.10 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    3  D --1-> F R= 0.16 totalR= 0.26 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.25 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.17 totalR= 0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.17 totalR=-0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.17 totalR=-0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.17 totalR=-0.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.42 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.17 totalR=-0.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  F --1-> E R= 0.15 totalR=-0.44 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R= 0.15 totalR=-0.29 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR=-0.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.17 totalR=-0.47 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.02 totalR=-0.49 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.02 totalR=-0.51 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.02 totalR=-0.53 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.05 totalR=-0.58 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  S --2-> C R=-0.03 totalR=-0.61 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   20  C --1-> B R=-0.01 totalR=-0.62 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.62 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  C --3-> L R=-0.03 totalR=-0.66 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.17 totalR=-0.82 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.17 totalR=-0.99 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-1.02 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-1.03 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.02 totalR=-1.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.02 totalR=-1.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.02 totalR=-1.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.05 totalR=-1.13 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.02 totalR=-1.15 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.02 totalR=-1.17 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.17 totalR=-1.33 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.05 totalR=-1.38 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.02 totalR=-1.40 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-1.41 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   37  F --2-> G R=-0.03 totalR=-1.44 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.17 totalR=-1.61 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.17 totalR=-1.77 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.81 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-1.84 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.17 totalR=-2.01 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-2.04 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.02 totalR=-2.06 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.17 totalR=-2.22 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.02 totalR=-2.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.17 totalR=-2.41 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.17 totalR=-2.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-2.61 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.17 totalR=-2.77 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-2.81 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.02 totalR=-2.82 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.02 totalR=-2.84 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.02 totalR=-2.86 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.17 totalR=-3.02 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.02 totalR=-3.04 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.02 totalR=-3.06 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.17 totalR=-3.22 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.02 totalR=-3.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.02 totalR=-3.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.17 totalR=-3.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.17 totalR=-3.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.17 totalR=-3.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.17 totalR=-3.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.17 totalR=-4.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.02 totalR=-4.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.02 totalR=-4.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.02 totalR=-4.14 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.05 totalR=-4.19 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   70  S --0-> A R=-0.05 totalR=-4.24 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   71  A --1-> B R=-0.02 totalR=-4.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   72  B --1-> A R=-0.02 totalR=-4.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   73  A --2-> E R=-0.02 totalR=-4.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   74  E --0-> A R=-0.02 totalR=-4.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   75  A --0-> S R=-0.05 totalR=-4.36 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   76  S --1-> B R=-0.02 totalR=-4.37 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   77  B --3-> K R= 0.13 totalR=-4.24 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   78  K --0-> B R=-0.03 totalR=-4.27 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   79  B --1-> A R=-0.02 totalR=-4.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   80  A --2-> E R=-0.02 totalR=-4.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   81  E --2-> H R=-0.02 totalR=-4.32 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   82  H --3-> H R=-0.17 totalR=-4.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   83  H --0-> E R=-0.02 totalR=-4.51 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   84  E --1-> F R=-0.02 totalR=-4.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   85  F --1-> E R=-0.02 totalR=-4.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   86  E --3-> E R=-0.17 totalR=-4.71 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   87  E --1-> F R=-0.02 totalR=-4.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   88  F --1-> E R=-0.02 totalR=-4.74 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   89  E --3-> E R=-0.17 totalR=-4.91 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   90  E --2-> H R=-0.02 totalR=-4.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   91  H --3-> H R=-0.17 totalR=-5.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   92  H --3-> H R=-0.17 totalR=-5.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   93  H --2-> H R=-0.17 totalR=-5.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   94  H --2-> H R=-0.17 totalR=-5.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   95  H --3-> H R=-0.17 totalR=-5.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   96  H --0-> E R=-0.02 totalR=-5.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   97  E --2-> H R=-0.02 totalR=-5.79 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   98  H --3-> H R=-0.17 totalR=-5.96 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   99  H --1-> K R=-0.05 totalR=-6.01 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  100  K --0-> B R=-0.03 totalR=-6.04 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  101  B --1-> A R=-0.02 totalR=-6.06 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  102  A --2-> E R=-0.02 totalR=-6.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  103  E --0-> A R=-0.02 totalR=-6.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  104  A --3-> D R=-0.02 totalR=-6.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  105  D --0-> A R=-0.02 totalR=-6.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  106  A --2-> E R=-0.02 totalR=-6.14 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  107  E --0-> A R=-0.02 totalR=-6.16 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  108  A --3-> D R=-0.02 totalR=-6.17 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  109  D --3-> D R=-0.17 totalR=-6.34 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  110  D --0-> A R=-0.02 totalR=-6.36 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  111  A --3-> D R=-0.02 totalR=-6.37 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  112  D --0-> A R=-0.02 totalR=-6.39 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  113  A --0-> S R=-0.05 totalR=-6.44 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  114  S --0-> A R=-0.05 totalR=-6.49 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  115  A --0-> S R=-0.05 totalR=-6.54 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  116  S --2-> C R=-0.03 totalR=-6.57 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  117  C --3-> L R=-0.03 totalR=-6.61 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  118  L --0-> C R=-0.03 totalR=-6.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  119  C --3-> L R=-0.03 totalR=-6.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  120  L --2-> L R=-0.17 totalR=-6.84 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  121  L --3-> L R=-0.17 totalR=-7.01 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  122  L --3-> L R=-0.17 totalR=-7.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  123  L --1-> M R=-0.01 totalR=-7.18 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  124  M --1-> L R=-0.01 totalR=-7.19 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  125  L --1-> M R=-0.01 totalR=-7.20 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  126  M --0-> C R=-0.02 totalR=-7.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  127  C --1-> B R=-0.01 totalR=-7.22 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  128  B --1-> A R=-0.02 totalR=-7.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  129  A --1-> B R=-0.02 totalR=-7.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  130  B --3-> K R=-0.03 totalR=-7.29 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  131  K --0-> B R=-0.03 totalR=-7.32 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  132  B --3-> K R=-0.03 totalR=-7.36 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  133  K --1-> H R=-0.05 totalR=-7.41 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  134  H --2-> H R=-0.17 totalR=-7.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  135  H --0-> E R=-0.02 totalR=-7.59 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  136  E --1-> F R=-0.02 totalR=-7.61 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  137  F --2-> G R=-0.03 totalR=-7.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  138  G --0-> F R=-0.03 totalR=-7.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  139  F --2-> G R=-0.03 totalR=-7.71 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  140  G --0-> F R=-0.03 totalR=-7.74 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  141  F --1-> E R=-0.02 totalR=-7.76 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  142  E --3-> E R=-0.17 totalR=-7.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  143  E --2-> H R=-0.02 totalR=-7.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  144  H --2-> H R=-0.17 totalR=-8.11 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  145  H --1-> K R=-0.05 totalR=-8.16 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  146  K --0-> B R=-0.03 totalR=-8.19 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  147  B --3-> K R=-0.03 totalR=-8.22 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  148  K --1-> H R=-0.05 totalR=-8.27 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  149  H --1-> K R=-0.05 totalR=-8.32 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  150  K --3-> K R=-0.17 totalR=-8.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  151  K --0-> B R=-0.03 totalR=-8.52 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  152  B --2-> C R=-0.01 totalR=-8.53 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  153  C --2-> M R=-0.02 totalR=-8.55 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  154  M --3-> M R=-0.17 totalR=-8.72 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  155  M --2-> N R=-0.02 totalR=-8.73 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  156  N --3-> N R=-0.17 totalR=-8.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  157  N --3-> N R=-0.17 totalR=-9.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  158  N --3-> N R=-0.17 totalR=-9.23 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  159  N --2-> N R=-0.17 totalR=-9.40 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  160  N --1-> O R= 0.15 totalR=-9.25 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:  161  O --2-> O R=-0.17 totalR=-9.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  162  O --2-> O R=-0.17 totalR=-9.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  163  O --3-> O R=-0.17 totalR=-9.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  164  O --2-> O R=-0.17 totalR=-9.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  165  O --3-> O R=-0.17 totalR=-10.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  166  O --3-> O R=-0.17 totalR=-10.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  167  O --2-> O R=-0.17 totalR=-10.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  168  O --2-> O R=-0.17 totalR=-10.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  169  O --3-> O R=-0.17 totalR=-10.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  170  O --0-> N R=-0.02 totalR=-10.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  171  N --1-> O R=-0.02 totalR=-10.78 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  172  O --2-> O R=-0.17 totalR=-10.95 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  173  O --3-> O R=-0.17 totalR=-11.12 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  174  O --2-> O R=-0.17 totalR=-11.28 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  175  O --1-> G R=-0.05 totalR=-11.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  176  G --2-> G R=-0.17 totalR=-11.50 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  177  G --1-> O R=-0.05 totalR=-11.55 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  178  O --0-> N R=-0.02 totalR=-11.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  179  N --2-> N R=-0.17 totalR=-11.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  180  N --2-> N R=-0.17 totalR=-11.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  181  N --3-> N R=-0.17 totalR=-12.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  182  N --0-> M R=-0.02 totalR=-12.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  183  M --3-> M R=-0.17 totalR=-12.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  184  M --2-> N R=-0.02 totalR=-12.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  185  N --3-> N R=-0.17 totalR=-12.43 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  186  N --0-> M R=-0.02 totalR=-12.45 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  187  M --0-> C R=-0.02 totalR=-12.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  188  C --2-> M R=-0.02 totalR=-12.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  189  M --0-> C R=-0.02 totalR=-12.50 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  190  C --2-> M R=-0.02 totalR=-12.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  191  M --3-> M R=-0.17 totalR=-12.68 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  192  M --2-> N R=-0.02 totalR=-12.70 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  193  N --2-> N R=-0.17 totalR=-12.87 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  194  N --3-> N R=-0.17 totalR=-13.03 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  195  N --0-> M R=-0.02 totalR=-13.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  196  M --0-> C R=-0.02 totalR=-13.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  197  C --0-> S R=-0.03 totalR=-13.10 cost= 200 customerR=   0 optimum=6000\n",
            "Done: episodes=     1  avgSteps=197.00  avgTotalReward=-13.10\n",
            "Episode finished after 197 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.     0.     0.     0.     0.     0.\n",
            "     0.     0.     0.     0.     0.     0.     0.     0.     0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWpCU8xH0ZKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ]
    },
    {
      "metadata": {
        "id": "7NxTojLi0N0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import json\n",
        "\n",
        "class Baseline():\n",
        "\n",
        "  def __init__(self, env):\n",
        "    self.map = env.map\n",
        "    self.rewards = env.customer_reward.copy()\n",
        "\n",
        "  def as_string(self, state):\n",
        "    # reward/cost does not hurt, but is useless, path obsucres same state\n",
        "    new_state = {\n",
        "        'rewards': state['rewards'],\n",
        "        'position': state['position']\n",
        "    }\n",
        "    return json.dumps(new_state, sort_keys=True)\n",
        "  \n",
        "  def is_goal(self, state):\n",
        "    if state['position'] != 'S': return False\n",
        "    for reward in state['rewards'].values():\n",
        "      if reward != 0: return False\n",
        "    return True\n",
        "    \n",
        "\n",
        "  def expand(self, state):\n",
        "    states = []\n",
        "    for position, cost in self.map[state['position']]:\n",
        "      new_state = deepcopy(state)\n",
        "      new_state['position'] = position\n",
        "      new_state['rewards'][position] = 0\n",
        "      reward = state['rewards'][position]\n",
        "      new_state['reward'] += reward\n",
        "      new_state['cost'] += cost\n",
        "      new_state['path'].append(position)\n",
        "      states.append(new_state)\n",
        "    return states\n",
        "\n",
        "  def search(self, root, max_depth = 25):\n",
        "      closed = set()\n",
        "      open = [root]\n",
        "\n",
        "      while open:\n",
        "          state = open.pop(0)\n",
        "          if self.as_string(state) in closed: continue  \n",
        "\n",
        "          closed.add(self.as_string(state))\n",
        "\n",
        "          depth = len(state['path'])\n",
        "          if depth > max_depth:\n",
        "            print(\"Visited:\", len(closed))\n",
        "            print(\"Reached max depth, without reaching goal\")\n",
        "            return None\n",
        "\n",
        "          if self.is_goal(state):\n",
        "              print(\"Scaled reward:\", (state['reward'] - state['cost']) / 6000)            \n",
        "              print(\"Perfect path\", state['path'])\n",
        "              return state\n",
        "\n",
        "          expanded = self.expand(state)\n",
        "          open += expanded\n",
        "          # make this best first\n",
        "          open.sort(key=lambda state: state['cost'])\n",
        "        \n",
        "  def find_optimum(self):\n",
        "    initial_state = {\n",
        "        'rewards': self.rewards.copy(),\n",
        "        'position': 'S',\n",
        "        'reward': 0,\n",
        "        'cost': 0,\n",
        "        'path': ['S']\n",
        "    }\n",
        "    return self.search(initial_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "Estimation\n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* all rewards: 6000\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n",
        "* estimate: no illegal moves and between\n",
        "  * half the travel cost: (6000 - 1250) / 6000 = .79\n",
        "  * and full traval cost (6000 - 2500) / 6000 = 0.58\n",
        "* additionally: the agent only sees very little of the whole scenario\n",
        "  * changes with every episode\n",
        "  * was ok when network can learn fixed scenario\n"
      ]
    },
    {
      "metadata": {
        "id": "Qvi-T-YuEO0A",
        "colab_type": "code",
        "outputId": "207520bf-cd2a-4eb3-a735-df363fad9d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "aae7b3ed-215c-44f0-8113-8797c2986c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1343
        }
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "# https://arxiv.org/abs/1607.06450 for layer_norm\n",
        "\n",
        "# lr linear from lr=1e-2 to lr=1e-4 (default lr=3e-4)\n",
        "def lr_range(frac):\n",
        "  # we get the remaining updates between 1 and 0\n",
        "  start_lr = 1e-2\n",
        "  end_lr = 1e-4\n",
        "  diff_lr = start_lr - end_lr\n",
        "  lr = end_lr + diff_lr * frac\n",
        "  return lr\n",
        "  \n",
        "  \n",
        "%time model = ppo2.learn(\\\n",
        "    env=monitored_env,\\\n",
        "    network='mlp',\\\n",
        "    num_hidden=100,\\\n",
        "    num_layers=3,\\\n",
        "    lr=lr_range,\\\n",
        "    gamma=1.0,\\\n",
        "    ent_coef=0.05,\\\n",
        "    layer_norm=True,\\\n",
        "    total_timesteps=100000)\n",
        "\n",
        "# model.save('berater-ppo-v10.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-01-20-11-42-00-516303\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0182927    |\n",
            "| clipfrac           | 0.33862305   |\n",
            "| eplenmean          | 124          |\n",
            "| eprewmean          | -7.7355595   |\n",
            "| explained_variance | 0.0854       |\n",
            "| fps                | 459          |\n",
            "| nupdates           | 1            |\n",
            "| policy_entropy     | 1.368455     |\n",
            "| policy_loss        | -0.023739578 |\n",
            "| serial_timesteps   | 2048         |\n",
            "| time_elapsed       | 4.46         |\n",
            "| total_timesteps    | 2048         |\n",
            "| value_loss         | 0.83213806   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.023345873  |\n",
            "| clipfrac           | 0.24499512   |\n",
            "| eplenmean          | 32.1         |\n",
            "| eprewmean          | 0.02524999   |\n",
            "| explained_variance | -0.296       |\n",
            "| fps                | 494          |\n",
            "| nupdates           | 10           |\n",
            "| policy_entropy     | 0.9668902    |\n",
            "| policy_loss        | -0.021635238 |\n",
            "| serial_timesteps   | 20480        |\n",
            "| time_elapsed       | 41.5         |\n",
            "| total_timesteps    | 20480        |\n",
            "| value_loss         | 0.051904947  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.02105514   |\n",
            "| clipfrac           | 0.15112305   |\n",
            "| eplenmean          | 19.1         |\n",
            "| eprewmean          | 0.5788334    |\n",
            "| explained_variance | 0.707        |\n",
            "| fps                | 494          |\n",
            "| nupdates           | 20           |\n",
            "| policy_entropy     | 0.5581855    |\n",
            "| policy_loss        | -0.01160668  |\n",
            "| serial_timesteps   | 40960        |\n",
            "| time_elapsed       | 82.5         |\n",
            "| total_timesteps    | 40960        |\n",
            "| value_loss         | 0.0058481703 |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012872087  |\n",
            "| clipfrac           | 0.1060791    |\n",
            "| eplenmean          | 18.4         |\n",
            "| eprewmean          | 0.6355       |\n",
            "| explained_variance | 0.808        |\n",
            "| fps                | 490          |\n",
            "| nupdates           | 30           |\n",
            "| policy_entropy     | 0.41601473   |\n",
            "| policy_loss        | -0.008156966 |\n",
            "| serial_timesteps   | 61440        |\n",
            "| time_elapsed       | 124          |\n",
            "| total_timesteps    | 61440        |\n",
            "| value_loss         | 0.0043741832 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0030018743  |\n",
            "| clipfrac           | 0.035888672   |\n",
            "| eplenmean          | 17.4          |\n",
            "| eprewmean          | 0.6590001     |\n",
            "| explained_variance | 0.869         |\n",
            "| fps                | 494           |\n",
            "| nupdates           | 40            |\n",
            "| policy_entropy     | 0.35707977    |\n",
            "| policy_loss        | -0.0076489337 |\n",
            "| serial_timesteps   | 81920         |\n",
            "| time_elapsed       | 165           |\n",
            "| total_timesteps    | 81920         |\n",
            "| value_loss         | 0.0032126666  |\n",
            "--------------------------------------\n",
            "CPU times: user 4min 15s, sys: 38 s, total: 4min 53s\n",
            "Wall time: 3min 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "4d167cef-8f51-4679-826e-f1768dafe151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9f50ede198>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAFKCAYAAAAjekdZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XlgE3X+P/5n0vRueieFHlzlKBQK\nFFSgUOQo6Efxo6xC1wXW9UAFRRRW2f5cq7sLIoIH6B7i8XP5uFLB6orrUi9QxEIRsEDlaoECLTRJ\n6ZWeOeb7R+nQ0NK0ZdLJ8Xz8NTOZTF59E/rszLzn/VYIgiCAiIiIZKeUuwAiIiJqxlAmIiJyEgxl\nIiIiJ8FQJiIichIMZSIiIifBUCYiInISqp7+QL2+RtLjhYUFoKKiTtJjeiq2pTTYjtJhW0qHbSmN\n7rajRqPu1H4uf6asUnnJXYLbYFtKg+0oHbaldNiW0nB0O7p8KBMREbkLhjIREZGTYCgTERE5CYYy\nERGRk2AoExEROQmGMhERkZNgKBMRETkJhjIREZGTYCgTERE5CYYyERGRk2AoExEROQmGMhERkZNg\nKBMRETkJhjIREZGT6NR8yqtWrUJ+fj4UCgUyMjKQlJQEACgrK8Py5cvF/c6dO4dly5Zh1qxZjqmW\niIjIjdkN5by8PBQXFyMrKwtFRUXIyMhAVlYWACAqKgqbNm0CAJjNZsyfPx9Tp051bMVERERuyu7l\n69zcXEyfPh0AEB8fj6qqKhiNxjb7ffLJJ5g5cyYCAwOlr5KIiMgD2A1lg8GAsLAwcT08PBx6vb7N\nflu2bMHdd98tbXVEREQepFP3lFsTBKHNtoMHD2LAgAEICgqy+/6wsACoVF5d/dgOaTRqSY/nydiW\n0mA7SodtKR22pTQc2Y52Q1mr1cJgMIjrOp0OGo3GZp+dO3di/PjxnfrAioq6LpbYMY1GDb2+RtJj\neiq2pTTYjtJhW0qHbSmN7rZjZ4Pc7uXrlJQU5OTkAAAKCgqg1WrbnBEfPnwYCQkJXS6SiIiIrrB7\nppycnIzExESkp6dDoVAgMzMT2dnZUKvVSEtLAwDo9XpEREQ4vFgiIiJ31ql7yq2fRQbQ5qx427Zt\n0lVERETkoTiiFxERkZNgKBMRETkJhjIREZGTYCgTERE5CYYyERGRk2AoExFRp+w+fAFvbSuAxWqV\nu5R2GetNqDQ2ttle22BCY5PF7vsbmswoNdSi7JK0g1x1RZeH2SQiIvd35FQ5XvkoH68tmYjgAB98\n93MJ3t9+HACwp6AMYwZrsOiu4VAoFOJ7BEGwWZfSV/vO4cNvTmLpPSORFB8BQRBwrLgCVgDb955F\nXYMZpy9UAwCiwgMwZrAGE4b3wrNv7xWP0V7Nrb2ZfRgFZyoAAK8+PhEhgT4O+Vk6ohDaG8zagaQe\n5o1Dx0mHbSkNtqN02JbS6agtW2KgJazMFisWvrzT7jF9vJV47K4RyC8qx+RR0Vi5aT8mj4xG+rRB\nktVtFQT86b19OKu7MjvhryYPwMffnbqu4w7vH46FdyQiyN8bAGAyW/Dw2u/E1/+xfDK825mnwdHD\nbDKUScS2lAbbUTpsS+lcqy1zj1zElp2FiAoLwFNzRwJQ4Pn38nChvP1LuCPjI5BfVN7hZ735ZCr8\nfbt3IfanYzrUN5oREeKHtZt/7tYxump8YhRyC8rE9RcfHoeosIB293V0KPPyNRGRh/rk+1PY9uMZ\nAEClscnmTBEAHpo1DP/JLYbZbMWTc0bCZLYiVts890Hmu3k41+rstbXFr34vXvbuCpPZgr9+eqTT\n+993awJSRvSCl1IJqyBAEAQcLa7AJ9+fwukLzcH5q8kDMG1MLPx8VLhQXottP55B2aU68XUANoEM\n4JqB3BMYykREHuJsWQ2ef28fAGBAdDBOlTbfg02fOhCbvy1ss//4xF4Yn9ir3WP98bdj21zifmjW\nMGzc9gsAYOn6HwAAIYE+yJg/BppQ/w5rs1oF/PuHM+2+tuTuJAyODUWAnwoFpy/h65/OIX3aIESF\nXwlPpUIBKBQY3j8Cif3CcaG8Dj8cvoAZN/SBt6q5T3PviEAsnJUovuetbQXYc1Ugy42Xr0nEtpQG\n21E6bEtpVNQ0Ytmbu9t9LToyEH958CacuViNdZt/Rm2DGYn9w/HbmUMQaSdIgSudu6yCAKVCgera\nJizd8EOb/YIDffCbtMG4IUGLRpMFL7y3Dxcv93KO0QRCV1EPk7m5V3fa2DgMig3BmCEah3Uca23b\n7tNQeSkRHxMCPx8v9Im69qVm3lO2g/9ppcO2lAbbUTpsS2ksXb8L1XWmdl/721OT4evTtkPT9Th4\nUo8NHx9u97WM+WOwatP+a77XS6nAxqenSFqPlHhPmYiIrovFeuXcS6lQ4O1npjj08aXRgzR4d8VU\nAMB5nRHPvZsnvnZ1IIepfVFR0/xs8R/mJWNQbKhDanIVDGUiIjclCAJ+LjSgtsGMkCAfvPrYRPG1\nnrgsDACx2iAs+VUSPv3hFM6WXekYFqMJxJ8fuKlHanAlDGUiIjf0+pZ8m0eXOnN/2FFGDYrEqEGR\nOHhSj89/PINZKf0xamCkbPU4M4YyEVEXNZksOHOxBhcv1SE6MlC8JLv+iUniYBRyu/pZ4vm3DpWp\nkitGD9Jg9CCN3GU4NYYyETkVXUUdjp+rxKSkaNTWt985SW6PrPuu3e1LXt8l3kuVgyAI2PxNIb76\n6ZzN9g1LJ6FfXDg7zbkAhjIROZUV/9gDAHjvi2MAOtf5x2K1oqHJgkA/x5+lmi0dT8ZgMlvaHZ7R\n0dp77OmeKfG49aa+PV4LdR9niSIip9DQZEaJobbN9m/2n7/me2rqmnChvBYPrdmJx1/bhUN2hn/U\nVdRh3zHdddVZc/nRosgQP/z5wZuQ2C8Mz903FoNiQwAAJnOPPmUKoPkM+epA/t2tCQxkF8QzZSKS\nXW2DCY+/tqvd1/KO6vDwHbaP75RXNeD3f/uxzb6vbcnH289MaR7dqZUmkwUvf3gQRZdHsAqbPwYD\nY0K6VevWnc0jX40YEIGYyEAsSx8NAAgJ8gUAmC6fSe8/rsPnPxZj0V3D7Y5mdb1aBt0AmgfpePWx\nlB7rXU3SYigTkayaTJY2gfzU3JHo1ysYz72bh8qaRnyz/zzC1H5485P2B6Ro7cGXdmBZ+ihEBPvh\nrc8KEKMJxO7DF232OXmussNQvlTdgP3H9UgdGQ1vbyVOl1ZjQHQwahvM4jjJ1qvGXfL2ag7BJzf8\nYDNpw/99eQJPzhlpvyGug66yHkDz1ISLZ49w6GeRYzGUiUhWb35iOwHBsrmjkNg/HABwy7h+2PzV\ncfzr65N2jzNxRG/8cPgCAGBdq9mFzlxs27lpy84ijBoUid4RgTbb/7unGJXGJrGj1IffXPtzr56e\n8NjZSnG5dc/nw6c6vqQuhVc/ygdw5SydXBdDmYhkYxUEMbTuuzUBqSOjbV6fmzYYm7863uZ9c6YM\nxNghmjbP3sZqg7D5GkE6cURv/O5/EvD8e/twTmfEt/tL8JsZg8XXj5+twJadRZ2qe+GsYfD1tu3M\nNSmpNz7bfabd/e9f/S1W/CYZg+OkH62qrsEsjoh1983xkh+fehZDmYgcqryqAa9tzYcmxB+FJVWI\niQzEyIGR0FXW45fTlwAA3iplm0AGAJWXEq8+PhFf7TuHQH8VBsaEdNgTe8YNcQhX+9pM/zclOQZz\npwyEz+UQXXrPSCx7czcqaxshCALMFgEqLwVe+tfBTv9Mw/qFt9l256QBGD+8F/x9Vfjsh9OYcUOc\n2JMcAFZ/cADvPDMF9Y1m+Hh7QeV1/f1sP9pRiO17z4rrsZqg6z4myYuhTEQO1dIhq0Tf3LP6+LlK\nHD9XabPP7NQB13x/SKBPl84AxyZoxeUn7k7CyKtGjgoJ9IHKS4H9x/V44KUdAABNqJ/NPrMm9ENi\n/3Cs/uAAHv/VCHHAC0EQYLEK1wzUlnl4580YAgCYlhyLbw5c6T3e8nmRIX5Y8+iEa/4MLTMuXcul\n6gb8M+e4TW/zRXcOv+b+5DoYykTkMIaq+k7td/OoGEk/951npqC2wdzu6FpKpQJmi20nLX1lg7jc\nevCPqwcCUSgUUHl1vlfz3VPiER8TjJx951Dc6t62oaoB96/+FgBw41AtFs5KhFLZfNyi0iq8kvUz\nZqfGY9qYWJQYarHynz/hxqFa3Dg0Cv/dexYFl68wtDZmCEfKcgcMZSKSnCAIOKcz4vn39gEAYiID\nYWwwoV+UGjclRmH0QA2Ky2owOC7U7llhdygUig6Hu4wI9kN5dUOb7b+7NUHSOny9vTAusRfGJfZC\nfaMZL394sE3Hs7yjOhwqKsf6JyZhw8eHxXvsH3x1ApNHReOPb+8FAHyffwHf519o8xmDYkPw6J3D\n+QiUm2AoE5Hk1m7+GUeLK8T1ZxeMbTNnb0unJ6kDuTP+8uBNqG0wwWyxoqq2qTmgBWBcYi+Hfaa/\nrwrP3XcDKmoasafgok2nsoYmC/Yf17fpqf1tBwOnjB4UiTlTBiIqPMBhNVPPYygTkWSsgoADx/U2\ngTxtTGybQJabr4+XWJM2LACD7OwvpTC1L24d1xdpN8Sh0tiIp/+WCwDYcbBE3GfamFh8s/88Nn9b\n2Ob9y9NHoU+U2mkmviBpcZhNIpLMP7cfs+n5PGaIBnOmDJSxIuel8lIiMsQf90xp7sR24nLnt4du\nH4ZxiVE2+86fOQRR4QG4K3UAhvULZyC7sU6dKa9atQr5+flQKBTIyMhAUlKS+NqFCxfw1FNPwWQy\nYdiwYfjTn/7ksGKJyHl88OUJfHPgPO6ZEo+jxRU4csq281GfqCAsvoujS9kztG+Yzbq3Som+UWoM\n7RsmXnGYlNQbU0ZL2xmOnJPdUM7Ly0NxcTGysrJQVFSEjIwMZGVlia+vXr0a999/P9LS0vDCCy+g\ntLQU0dFtnzckItdmtQo4eb4Sg2JDcVZXIz7qs2VH2wE3BseGYBGHe+yUfr2CERzog+raJgDNtwBU\nXkr8/tej0dBkhspLKckzzeQa7IZybm4upk+fDgCIj49HVVUVjEYjgoKCYLVasX//frzyyisAgMzM\nTMdWS0SyefGD/Sgqqba7358fuBExHMSiS5IGRIhDhIYE+ojb/XzY7cfT2P0XNxgMSExMFNfDw8Oh\n1+sRFBSES5cuITAwEC+++CIKCgowduxYLFu2zKEFE5E82gvkOG0QzumMAIBXH59oEyjUeXdM7IeK\nmgZowgIcMhQnuY4u/xkmtJoZRRAElJWVYcGCBYiJicHChQuxc+dO3Hzzzdd8f1hYAFQSTwCu0agl\nPZ4nY1tKw93a8ffrv2+zLT1tCH5zSwKsVkG85OoI7taW7dFo1Fj9uNb+jhJ8Dl0/R7aj3VDWarUw\nGAziuk6ng0bTPHJMWFgYoqOj0adPHwDA+PHjcfLkyQ5DuaKi7jpLtqXRqKHXt50FhrqObSkNd2rH\n6romPPO3XDSaLACapwa8OTkGA2NC4Ovt5fCf053aUm5sS2l0tx07G+R2/7RNSUlBTk4OAKCgoABa\nrRZBQc33i1QqFeLi4nDmzBnx9f79+3e5WCJyTkvX/yAGMgDcmzYYif3C28yQRETSsHumnJycjMTE\nRKSnp0OhUCAzMxPZ2dlQq9VIS0tDRkYGVqxYAUEQMHjwYEydOtXeIYnIBf35gRsRpvaVuwwit9ap\ne8rLly+3WU9IuDI+bN++ffHhhx9KWxUR9TirIKBEX4tYTSAUCgX+9dUJ8bWJI3qzRzVRD2B/eyIP\nZrFasfnrQvj7eeHzH4vF7UvvScLXl8ddvnGoFvffNlSuEok8CkOZqAfUNZhR12iCn48KQf7eKCqp\nQmSof7uPEDU0mfHkG7tx60198Omu0wCAvy+bDB8H3MfdebDUZr7fFq9tOSQuL5g5RPLPJaL2MZSJ\nHKixyYIv953FJ5fD9WpXz9cLAF//dB6NTRYxkAHgkXXfIX3qQMy4sY+k9X3Q6hJ1e958MhX+vvw1\nQdRT+L+NyIEef30XzBZrp/a1WK0oKqnGJ9+favf1zd8W4tSFasRogjBrQr/rqstiteKRtd+12T5n\nykB8tKN5ZqKIYD8GMlEP4/84IgepqGm0G8gmswXl1Y3IeGtPu6/7+XhhcFwoDhU1z7Obd1QHHNVh\nxti465oOce8vZbBYmwcCio8ORq/wAIxL7IXE/uHILbiIczojMn93Q7ePT0Tdw1AmcgCrVcC23Vcu\nP98+oR9mpw4AAPzrqxNiJ6riMiN+Pmlo9xgvLhwnTmC/42AJNuUcF1/bcbAEvcID8M5/fsGg2FAs\nuTup3WO0p9FkwdufHxXXH71zOMKD/cT1P8xLhrHexOkBiWTAUCZygAfX7BCXH//VCIwepBHX700b\nDIsgYMeBErzzn6Mou2Q7yt0Dtw1FUnwE1AFXOoFNGR2DySOj8cT6XahtMIuXmAHg50IDDFX1iAzx\n71Rtrf8IeO3xiQi+qrOZn4+KEyEQyYTzgRE52IgBEW22qS+fhbYO5AduG4o3lqYiZURvm0BuoVQq\n8OrjE9v9jL2/lAEATpyrhL6yvsN6Nm77BQAwMDakTSATkbz45zCRxJpaDUsJoN2JGm6f0A+f7T4j\nrg+JC0XKiN52j63yUiI+OhhFpbYzNn383SkE+Xvj/e3Nl7hn3BCHIXGhSOwf3uZRqlGDInHghB7z\nZ/BRJyJnwzNlIokVnCoXl//21OR291F5KbH64XEAmjtzPX3v6E4fP2P+GMReHl3r1cdSxO0tgQwA\nX+47hw3Zh/HIurY9rOsaTACAXpfvVxOR8+CZMpGEKmoa8dxbuQCAyBC/DntIa8MC2n1O2R6FQoE/\nPXCjuB4S5IMqY1OHNbWMWZ175CKOna2EQgF4q/g3OZGzYSgTSWjHwRJx+fkeeqRo7aIJ2LjtF5jM\nVtw8OgaDYkNgrDfh6b81/3Gw7M3d6B0RgCW/SsLGz5vvJ0Po4IBEJBuGMpFEquua8PmPZwAAowdF\nIsCvZx4p8lIq8cj/DrfZ5uejwpK7k7B+a/NwmRfK6/CHVs9C/+Whm3qkNiLqGoYykQTuX/2tzfpj\ns0fIVMkVIwaEt7v99gn90DsisIerIaLO4E0lout0/GyFzfrAuFAoFAqZqrnCS6nEuyum4o2lk2y2\nD+sbJlNFRGQPQ5noOmz78Qxe+tdBm20zbuorUzXtC/DzxjOtencPjguVsRoi6ggvXxN1w///32P4\nPr/UZpuXUoEpyTG4ZVxfGAxGmSpr35A+YfjT/TeiV0QAlEr5z+KJqH0MZaIuajRZ2gQyAKx5dALC\n1L5Ocem6PbHaILlLICI7GMpEXWCsN2HJ67vabF9053DxWWAiou5iKBN1wWetZn5atXAcR8UiIkmx\noxdRF7SMaz0wJoSBTESSYygTdUGcVg2gecIHIiKpMZSJusBssQIAvLycszMXEbk2hjJRF1TVNk/8\nENhDQ2gSkWdhKJPHO1RkwCffn4IgdDxLg66yHtv3ngUAREdymEoikh57X5NHslit8FIqYbZY8dqW\n5kkbJozohaiwK523BEHAsbOV8FIqsOtQKXYfvii+FuTPM2Uikh5DmTzOoaJyvJF9GPNnDEafKLW4\n/VhxhU0on9MZ8fKHB9u8//YJ/XqiTCLyQAxl8giCIKChyQJ/XxW++7kEZosV7/33mM0+728/jtSR\n0eKIXC2XqlubcUMcZqcO6JGaicjzMJTJI/xcaMCGjw9j4R3DUHDm0jX3++qn8zivM+KHwxfavHbn\nxP64Y2J/R5ZJRB6OoUwe4fufm8eqfuuzXzrcb/M3J9tse/WxFIQEcQhNInI89r4mj6ANazv61ogB\nEeLykruT2n1f/95qBjIR9ZhOnSmvWrUK+fn5UCgUyMjIQFLSlV9gU6dORa9eveDl5QUAWLt2LaKi\nohxTLVE3NZktNuuzJvTD2AQtDp8qBwCMGhjZ5j3zZw7BlNExPVIfERHQiVDOy8tDcXExsrKyUFRU\nhIyMDGRlZdnss3HjRgQG8rlNcl6lhlqb9eEDwhGnDcL6JybB17v5gtGrj0/EW58V4GhxBRL6hDKQ\niajH2Q3l3NxcTJ8+HQAQHx+PqqoqGI1GBAVxblZyHSfPV4nL8dHBGBQbCsD2eeOQQB8sTx+FH49c\nxOhBbc+ciYgczW4oGwwGJCYmiuvh4eHQ6/U2oZyZmYmSkhKMGTMGy5Yt63CS97CwAKhUXtdZti2N\nRm1/J+oUd2zLi+W2Z8lrlqTCx/va38E7pwZf92e6YzvKhW0pHbalNBzZjl3ufX31UIRLlizBpEmT\nEBISgsWLFyMnJwe33HLLNd9fUVHX9So7oNGoodfXSHpMT+WObWkyW5FfaAAARAT74uH/HY6qSmm/\ng1dzx3aUC9tSOmxLaXS3HTsb5HZDWavVwmAwiOs6nQ4ajUZcv/POO8Xl1NRUnDhxosNQJupJf3p/\nH0r0zWfKs1L6Y2BMiMwVERFdm91HolJSUpCTkwMAKCgogFarFS9d19TU4IEHHkBTU/PMOfv27cOg\nQYMcWC5R55UYasVABoC+Ubx0R0TOze6ZcnJyMhITE5Geng6FQoHMzExkZ2dDrVYjLS0NqampmDt3\nLnx9fTFs2DCeJZPTyLpqIJBYLZ8QICLnphDszVcnManvafA+iXTcpS2bTBas2rQfZ3VGAMDzv7vB\nZuIJR3OXdnQGbEvpsC2l4eh7yhzRi9zOy5sPioEMALFaPr5HRK6BoUxup6ik2mZd2cEjekREzoSh\nTG4nVtN87zg40AcL7xgmczVERJ3HWaLIrTSZLDh/ucf1usUT4KXk351E5DoYyuQWrIKAS9UNeOG9\nfQCAMLUvA5mIXA5DmVyeyWzF4699jyazVdx2R0o/+QoiIuomnkqQy9NX1tsEMgCkjOgtUzVERN3H\nUCaXp6+sb7NN5cWvNhG5Hl6+JpdnqGoAADw0axi0of4YEH39szwREcmBoUwu74OvTgAAeoUHoH9v\nBjIRuS5e4yOXdvCkXlyO48hdROTiGMrk0j774Yy4zPvIROTq+FuMXFZDkxnFZc0Dw79w/40yV0NE\ndP0YyuSyTl+4MlMLL10TkTtgKJPLMlQ1Pwo1dohG5kqIiKTBUCaXVVnTCACYNDJa5kqIiKTBUCaX\ntP+4Dp/sOg0ACAvylbkaIiJpMJTJJb35yRFxOSyYoUxE7oGhTC6nsclisx7o5y1TJURE0mIok8sp\nq6iTuwQiIofgMJvkcmrqTQCA4EAfPDVnpMzVEBFJh2fK5HKqjU0AgDsn9kefKLXM1RARSYehTC6n\nrtEMAAj0571kInIvDGVyOfWXQ9nPx0vmSoiIpMVQJpfTcLn3NUOZiNwNQ5lczjmdEQDg78N+ikTk\nXhjK5HIOnyoHAAQF8J4yEbkXhjK5nEC/5jPkUA6vSURuhqFMLqWxyQKTxYoYTaDcpRARSY6hTC6l\nuKwGTSYrEvuFy10KEZHkGMrkUlZ/cAAA0Cs8QOZKiIik16lQXrVqFebOnYv09HQcOnSo3X3WrVuH\n+fPnS1ocUWs1dU3icmSon4yVEBE5ht1QzsvLQ3FxMbKysrBy5UqsXLmyzT6FhYXYt2+fQwokalFd\nZxKXYyKDZKyEiMgx7IZybm4upk+fDgCIj49HVVUVjEajzT6rV6/Gk08+6ZgKiS6rMjYCAIb2DUOY\nmj2vicj92B19wWAwIDExUVwPDw+HXq9HUFDzmUp2djZuvPFGxMTEdOoDw8ICoFJJOxKTRsNJCaTi\njG1psVjx5Gvf4XRpNQBg9tRBTllna85enythW0qHbSkNR7Zjl4dEEgRBXK6srER2djbee+89lJWV\nder9FRLPhavRqKHX10h6TE/lrG1ZU9ckBjIA9NMEOGWdLZy1HV0R21I6bEtpdLcdOxvkdi9fa7Va\nGAwGcV2n00Gj0QAA9uzZg0uXLuE3v/kNHnvsMRQUFGDVqlVdLpaoIy/+3wGbdS8lHxogIvdk97db\nSkoKcnJyAAAFBQXQarXipetbbrkFX3zxBT766CO88cYbSExMREZGhmMrJo9z8dKVqyuP3jlcxkqI\niBzL7uXr5ORkJCYmIj09HQqFApmZmcjOzoZarUZaWlpP1EgerPXtkud/dwP6RPGeGBG5r07dU16+\nfLnNekJCQpt9YmNjsWnTJmmqIrqsurb52eSEPqEMZCJye7w5R06t5dlkPpdMRJ6AoUxOrb7RDADw\n85X2MToiImfEWeLJKZUYamGorBdDOcCXX1Uicn/8TUdO6Y9v77VZ92MoE5EH4OVrcjoNTeY223pz\nVigi8gAMZXI6xRfbjpbTJ4odvYjI/TGUyel8n1/aZpufDy9fE5H7YyiT08ktaB5H/f+bP0bcplQq\n5CqHiKjH8PSDnIrZYhWX+0cH47XHJ6LJZJGxIiKinsNQJqfSepxrpUKB4EAfGashIupZvHxNTiW3\n4CIAQBvmL3MlREQ9j6FMTuW/e84CAHQV9TJXQkTU8xjK5FRaLlfPmtBP3kKIiGTAUCanEh8dDACY\nPjZW5kqIiHoeQ5mcRtmlOhw8aYC/rwqB/t5yl0NE1OMYyuQ0Xt96CACg8lJAqeBzyUTkeRjK5DR8\nvJu/jk/OGSlzJURE8mAok9M4W2ZEoJ8K/XoFy10KEZEsGMrkFHYdah7vurah7QxRRESegqFMsqtv\nNOO9L44BAEYNjJS5GiIi+TCUSXaHT5WLy/f9T4KMlRARyYuhTLI7VVotLgcHcKxrIvJcDGWSXcuQ\nmq8+liJzJURE8mIok+xOXahGeLAvQoJ85S6FiEhWnLqRZHPwpB7fHihBdW0TEvuHy10OEZHsGMok\nmw0fHxaXe4cHyFgJEZFz4OVrkkWJ3mizfsNQrUyVEBE5D4YyyeLtz4+Ky+MTe2FgTIiM1RAROQeG\nMsliwOUpGicl9cZDs4ZBwQkoiIgYytTzBEHAjoMlAIBZKf3kLYaIyIkwlKnH7T1aJi6H8jEoIiJR\np3pfr1q1Cvn5+VAoFMjIyEBSUpL42kcffYStW7dCqVQiISEBmZmZvBRJHdp3VAcAGD4gHCov/l1I\nRNTCbijn5eWhuLgYWVlZKCoqQkZGBrKysgAA9fX1+M9//oMPPvgA3t7eWLBgAQ4ePIjk5GSHF06u\nRxAEPPnGblTXNgEAlvwqyc4vRMm1AAAUMklEQVQ7iIg8i93TlNzcXEyfPh0AEB8fj6qqKhiNzY+z\n+Pv74/3334e3tzfq6+thNBqh0WgcWzG5rJp6kxjIAHiWTER0FbtnygaDAYmJieJ6eHg49Ho9goKC\nxG1vvfUW/vnPf2LBggWIi4vr8HhhYQFQqbyuo+S2NBq1pMfzZI5sy2+/Oi4ujx0a5db/bu78s/U0\ntqV02JbScGQ7dnlEL0EQ2mxbuHAhFixYgIceeghjxozBmDFjrvn+ioq6rn5khzQaNfT6GkmP6akc\n3Zb/t/2YuLzw9qFu++/G76R02JbSYVtKo7vt2Nkgt3v9UKvVwmAwiOs6nU68RF1ZWYl9+/YBAPz8\n/JCamooDBw50uVhyf+d1V0bwmpYcy0vXRETtsPubMSUlBTk5OQCAgoICaLVa8dK12WzGihUrUFtb\nCwA4fPgw+vfv78ByyVX9M+fKpes5UwfKWAkRkfOye/k6OTkZiYmJSE9Ph0KhQGZmJrKzs6FWq5GW\nlobFixdjwYIFUKlUGDJkCKZNm9YTdZMLaWyyoLCkSlz3VvEsmYioPZ26p7x8+XKb9YSEBHF59uzZ\nmD17trRVkVs5eFIvdwlERC6BpyzkUPuP61FhbBTXF981XMZqiIicG+dTJod5f/sxfPdzqbh+16T+\nGDOEUzQSEV0Lz5TJYVoHMgB4scc1EVGH+FuSekxokI/cJRAROTWGMjlMcIC3zfpYXromIuoQQ5kc\nwioIqKk32Wzz8ZZ2eFUiInfDjl7kEDV1JggCMDI+AmFqX4wf3kvukoiInB5DmRyi6vJjUJpQf9yb\nNljmaoiIXAMvX5NDXLzUPPGI+qr7ykREdG0MZZKc2WLF3/9dAACorjPZ2ZuIiFowlElyxRevTGv2\nP+P6ylgJEZFrYSiT5PSV9QCA6MhAhKl9Za6GiMh1MJRJct/sPw8AmMspGomIuoShTJIrKq0GAESG\n+MlcCRGRa2Eok8NEhQXIXQIRkUvhc8okKasgQAFgUGwIlEqF3OUQEbkUnimTpBoazRAABPjx+WQi\noq5iKJOk6hrNAAB/X45zTUTUVQxlklRdQ3MoB/jyTJmIqKsYyiSp+pYzZT92VyAi6iqGMkmq5fJ1\ngC9DmYioqxjKJKmWM+UAnikTEXUZQ5kk1XJP2Z9nykREXcZQJkmJ95R92PuaiKirGMokqSazFQDg\ny1AmIuoyhjJJqtLYCADw9WYoExF1FUOZJFPfaMbuwxcBAD4MZSKiLmMok2RKDbXiso+KXy0ioq5i\nF1mSxNHiChw+VS6uqwN8ZKyGiMg1MZTpulUZG/HyhwfF9d4RAfDmmTIRUZd1KpRXrVqF/Px8KBQK\nZGRkICkpSXxtz549eOWVV6BUKtG/f3+sXLkSSiV/IXuSqtomm/V7pw+WqRIiItdmNz3z8vJQXFyM\nrKwsrFy5EitXrrR5/bnnnsP69euxefNm1NbWYteuXQ4rlpzT1aEcEshL10RE3WE3lHNzczF9+nQA\nQHx8PKqqqmA0GsXXs7Oz0atXLwBAeHg4KioqHFQqOavC81U266FqX5kqISJybXZD2WAwICwsTFwP\nDw+HXq8X14OCggAAOp0Ou3fvxuTJkx1QJjmz42croFAACX1CMTU5BkH+nLaRiKg7utzRSxCENtvK\ny8vxyCOPIDMz0ybA2xMWFgCVStpnWDUataTH82TdacsLl+oRHRmIl5/gH2Qt+J2UDttSOmxLaTiy\nHe2GslarhcFgENd1Oh00Go24bjQa8dBDD2Hp0qWYOHGi3Q+sqKjrZqnt02jU0OtrJD2mp+puWzaZ\nLfBS+vDf4TJ+J6XDtpQO21Ia3W3Hzga53cvXKSkpyMnJAQAUFBRAq9WKl6wBYPXq1fjtb3+L1NTU\nLhdJrq/4Yg0amyw4W2a0vzMREXXI7plycnIyEhMTkZ6eDoVCgczMTGRnZ0OtVmPixIn49NNPUVxc\njK1btwIAbr/9dsydO9fhhZNz+GhHodwlEBG5jU7dU16+fLnNekJCgrh85MgRaSsil6JUKgAAqSN7\ny1wJEZHr4ygf1G1WQUCpoRY+3kr89pYE+28gIqIOMZSp2y5VNaCiphFJ8ZFQKBRyl0NE5PIYytRt\nT/89FwAQHREgcyVERO6BoUzdYm31vDonnyAikgZ/m1K3GOtN4vKoQZoO9iQios7i1I3UZT8euYC3\nPz8KAEgZ0QsxkYEyV0RE5B54pkxdYhUEMZABQBvG+8lERFJhKFOXXDDU2qyPT4ySqRIiIvfDUKYu\nOXL6ks16ZIi/TJUQEbkf3lOmLsn6tnlYzUGxIXjm3mSZqyEici88U6ZOs1qvPAZ12/h+4hCbREQk\nDYYydVpDk0VcHtav43mziYio6xjK1Gn5Rc3zaqsDvKHy4leHiEhq/M1KnbZx2y8AgJo6k509iYio\nOxjK1GWL7hwudwlERG6Jva+p0wJ8VQjy98bYBK3cpRARuSWeKVOnGOtNqGs0ozdnhCIichiGMnWK\nrqIeAIfVJCJyJIYydYquog4AoA3jCF5ERI7CUCa7jPUmvPvFMQAMZSIiR2Iok10ffVsIs8UKgKFM\nRORIDGWyq77JLC5HhvjJWAkRkXtjKJNdMZGBAIDZqQPgpeRXhojIUfgbluyqbWg+U07oy/GuiYgc\niaFMHRIEAd/sPw8A8OZ410REDsXfstShJpNVXPbiVI1ERA7FUKYONZiuTNcYffneMhEROQZDmTpU\nU9sEAJg4ojeUPFMmInIohjJ1aN8xHQBgYGyIzJUQEbk/hjJ16GxZDQAgebBG5kqIiNwfQ5muqbbB\nhPyicgCAr7eXzNUQEbm/ToXyqlWrMHfuXKSnp+PQoUM2rzU2NuKZZ57B7NmzHVIgyeerfefEZZUX\n7ycTETma3VDOy8tDcXExsrKysHLlSqxcudLm9TVr1mDo0KEOK5Dkc/CkQVxWKBjKRESOZjeUc3Nz\nMX36dABAfHw8qqqqYDQaxdeffPJJ8XVyL2WXp2skIqKeYTeUDQYDwsKuDK8YHh4OvV4vrgcFBTmm\nMpKV2WJFk8mK8GBf/PG3Y+Uuh4jII6i6+gZBEK7rA8PCAqBSSdtpSKNRS3o8T9bSluVV9QCAxAGR\nuDEpRs6SXBK/k9JhW0qHbSkNR7aj3VDWarUwGK7cW9TpdNBouv94TIXEl0Q1GjX0+hpJj+mpWrfl\n9/mlAICjp8vZvl3E76R02JbSYVtKo7vt2Nkgt3v5OiUlBTk5OQCAgoICaLVaXrL2AD8euQgA6Nc7\nWOZKiIg8h90z5eTkZCQmJiI9PR0KhQKZmZnIzs6GWq1GWloalixZgosXL+L06dOYP38+5syZg1mz\nZvVE7eQgTSYLTpyrBABMS+alayKintKpe8rLly+3WU9ISBCX169fL21FJLs3PzkiLg+OC5WxEiIi\nz8IRvagNH+/mr8WU0TF8PpmIqAcxlElksQrIyTuLwvNVAIBpY2JlroiIyLN0+ZEocl9f551F1reF\n4nqQv7eM1RAReR6eKZOoRG+0WQ/w499sREQ9iaFMAJpH8Ppk55WzZG2oP1Re/HoQEfUk/tYlABDv\nIwOAv68XVj8yXsZqiIg8E0OZYLUKWPPhQXH9jaWpMlZDROS5GMoezioIOFpcIa6nTxvEx6CIiGTC\nnjwebtEr36HJZBXXU0f2lrEaIiLPxjNlD9c6kJfdmww/H/6dRkQkF4ayB7NYrTbr0RpONEJEJCeG\nsgerb7SIy32ighAfy3GuiYjkxFD2YK07eD3/uxvhpWQHLyIiOTGUPVilsVHuEoiIqBWGsgcLV/sC\nAOZOHShzJUREBDCUPZrJ3NzRy9fbS+ZKiIgIYCh7tKbLoeyt4teAiMgZ8LexB6utNwFgKBMROQv+\nNvZgW3YWyV0CERG1wlD2YC1nyEPi+HwyEZEzYCh7sN4RAfD18UJIkK/cpRARERjKHstktuJsmREc\nL4SIyHkwlD3UppzjAGyH2iQiInkxlD1UkL83AKCPlpNQEBE5C4ayhwr0b56icfbkATJXQkRELTh5\nrgfasrMQX+adAwAE+HnLXA0REbVgKHug/+45Ky5rQvxkrISIiFrj5WsPY7ZYbdb5OBQRkfNgKHuY\nopIquUsgIqJrYCh7GF1lvbj84O1DZayEiIiuxnvKHubnkwYAwMN3JOKmYVEyV0NERK11KpRXrVqF\n/Px8KBQKZGRkICkpSXztxx9/xCuvvAIvLy+kpqZi8eLFDiuWuu9SdQMMVQ04eDmUB8WGyFwRERFd\nzW4o5+Xlobi4GFlZWSgqKkJGRgaysrLE1//yl7/gnXfeQVRUFObNm4eZM2di4MCBDi2aum79x4dw\ntswIAAgJ9EF4MHtdExE5G7v3lHNzczF9+nQAQHx8PKqqqmA0Nv9yP3fuHEJCQtC7d28olUpMnjwZ\nubm5jq2YukwQBDGQASDAj3ctiIickd1QNhgMCAsLE9fDw8Oh1+sBAHq9HuHh4e2+Rs7DWG+yWR/M\nqRqJiJxSl0+ZBEG4rg/UaNTX9f6eOqY70QDYtu5/O7cv21ISbEfpsC2lw7aUhiPb0e6ZslarhcFg\nENd1Oh00Gk27r5WVlUGr1TqgTCIiIvdnN5RTUlKQk5MDACgoKIBWq0VQUPPMQrGxsTAajTh//jzM\nZjN27NiBlJQUx1ZMRETkphRCJ65Hr127Fj/99BMUCgUyMzPxyy+/QK1WIy0tDfv27cPatWsBADNm\nzMADDzzg8KKJiIjcUadCmYiIiByPw2wSERE5CYYyERGRk3DpUSQ6Gv7T061Zswb79++H2WzGww8/\njBEjRuDpp5+GxWKBRqPByy+/DB8fH3z22Wd4//33oVQqMWfOHNxzzz0wmUxYsWIFSktL4eXlhRdf\nfBFxcXE4duwYnn/+eQDAkCFD8MILL8j7Q/aghoYG3H777Vi0aBHGjx/Ptuymzz77DG+//TZUKhWW\nLFmCIUOGsC27qLa2Fs888wyqqqpgMpmwePFiaDSadtvg7bffxvbt26FQKPDYY49h8uTJqKmpwbJl\ny1BTU4OAgACsW7cOoaGhHjVk8okTJ7Bo0SLcd999mDdvHi5cuOCw72F7/wYdElzU3r17hYULFwqC\nIAiFhYXCnDlzZK7IeeTm5goPPvigIAiCcOnSJWHy5MnCihUrhC+++EIQBEFYt26d8MEHHwi1tbXC\njBkzhOrqaqG+vl647bbbhIqKCiE7O1t4/vnnBUEQhF27dglPPPGEIAiCMG/ePCE/P18QBEF46qmn\nhJ07d8rw08njlVdeEWbPni18/PHHbMtuunTpkjBjxgyhpqZGKCsrE5599lm2ZTds2rRJWLt2rSAI\ngnDx4kVh5syZ7bbB2bNnhbvuuktobGwUysvLhZkzZwpms1nYsGGDsHHjRkEQBGHz5s3CmjVrBEEQ\nhFtvvVUoLS0VLBaL8Otf/1o4efKkPD+gg9XW1grz5s0Tnn32WWHTpk2CIAgO+x5e69+gIy57+bqj\n4T893Q033IDXX38dABAcHIz6+nrs3bsX06ZNAwBMmTIFubm5yM/Px4gRI6BWq+Hn54fk5GQcOHAA\nubm5SEtLAwBMmDABBw4cQFNTE0pKSsSrES3H8ARFRUUoLCzEzTffDABsy27Kzc3F+PHjERQUBK1W\niz//+c9sy24ICwtDZWUlAKC6uhqhoaHttsHevXsxadIk+Pj4IDw8HDExMSgsLLRpx5Z9PWnIZB8f\nH2zcuNFmTA1HfQ+v9W/QEZcN5Y6G//R0Xl5eCAgIAABs3boVqampqK+vh4+PDwAgIiICer0eBoOh\n3WFSW29XKpVQKBQwGAwIDg4W9205hid46aWXsGLFCnGdbdk958+fR0NDAx555BHce++9yM3NZVt2\nw2233YbS0lKkpaVh3rx5ePrpp9ttg860Y0REBHQ6nUcNmaxSqeDnZzshj6O+h9c6Rof1XfdP6CQE\nPtnVxtdff42tW7fi3XffxYwZM8Tt12qrrmz3lPb+9NNPMWrUKMTFxbX7OtuyayorK/HGG2+gtLQU\nCxYssPnZ2Zad8+9//xvR0dF45513cOzYMSxevBhq9ZVhH9le18eR38POtLfLnil3NPwnAbt27cLf\n//53bNy4EWq1GgEBAWhoaABwZTjU9tqwZXvLX3MmkwmCIECj0YiXzFofw93t3LkT33zzDebMmYMt\nW7bgr3/9K9uymyIiIjB69GioVCr06dMHgYGBCAwMZFt20YEDBzBx4kQAQEJCAhobG1FRUSG+fq12\nbL29pR3t7espHPV/ujvt6rKh3NHwn56upqYGa9aswT/+8Q+EhjbPCDVhwgSxvb788ktMmjQJI0eO\nxOHDh1FdXY3a2locOHAAY8eORUpKCrZv3w4A2LFjB2666SZ4e3tjwIAB+Omnn2yO4e5ee+01fPzx\nx/joo49wzz33YNGiRWzLbpo4cSL27NkDq9WKiooK1NXVsS27oW/fvsjPzwcAlJSUIDAwEPHx8W3a\nYNy4cdi5cyeamppQVlYGnU6HgQMH2rRjy76ePmSyo76H1/o36IhLj+h19fCfCQkJcpfkFLKysrBh\nwwb0799f3LZ69Wo8++yzaGxsRHR0NF588UV4e3tj+/bteOedd6BQKDBv3jzccccdsFgsePbZZ3Hm\nzBn4+Phg9erV6N27NwoLC/Hcc8/BarVi5MiR+MMf/iDjT9nzNmzYgJiYGEycOBHPPPMM27IbNm/e\njK1btwIAHn30UYwYMYJt2UW1tbXIyMhAeXk5zGYznnjiCWg0mnbbYNOmTdi2bRsUCgWWLl2K8ePH\no7a2Fr///e9RWVmJ4OBgvPzyy1Cr1R4zZPKRI0fw0ksvoaSkBCqVClFRUVi7di1WrFjhkO9he/8G\nHXHpUCYiInInLnv5moiIyN0wlImIiJwEQ5mIiMhJMJSJiIicBEOZiIjISTCUiYiInARDmYiIyEkw\nlImIiJzE/wPj4+Z6UMkq7wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "id": "H_QTckfBra7l",
        "colab_type": "code",
        "outputId": "7f7ea6d1-b5a2-4939-cafd-76f3a2363155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "baseline = Baseline(env)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 0, 'B': 1000, 'C': 0, 'D': 1000, 'E': 0, 'F': 0, 'G': 1000, 'H': 1000, 'K': 0, 'L': 1000, 'M': 1000, 'N': 0, 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "40ffd50b-906b-411d-c30d-cf1e5423df26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:    4   Step:    1  S --1-> B R= 0.15 totalR= 0.15 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    4   Step:    2  B --2-> C R=-0.01 totalR= 0.14 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:    3  C --2-> M R= 0.15 totalR= 0.29 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    4   Step:    4  M --1-> L R= 0.16 totalR= 0.45 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    4   Step:    5  L --1-> M R=-0.01 totalR= 0.44 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:    6  M --1-> L R=-0.01 totalR= 0.43 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:    7  L --1-> M R=-0.01 totalR= 0.42 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:    8  M --1-> L R=-0.01 totalR= 0.42 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:    9  L --1-> M R=-0.01 totalR= 0.41 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   10  M --1-> L R=-0.01 totalR= 0.40 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   11  L --1-> M R=-0.01 totalR= 0.39 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   12  M --1-> L R=-0.01 totalR= 0.38 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   13  L --1-> M R=-0.01 totalR= 0.37 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   14  M --1-> L R=-0.01 totalR= 0.37 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   15  L --1-> M R=-0.01 totalR= 0.36 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   16  M --1-> L R=-0.01 totalR= 0.35 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   17  L --1-> M R=-0.01 totalR= 0.34 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   18  M --0-> C R=-0.02 totalR= 0.32 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   19  C --1-> B R=-0.01 totalR= 0.32 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   20  B --1-> A R=-0.02 totalR= 0.30 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   21  A --3-> D R= 0.15 totalR= 0.45 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    4   Step:   22  D --1-> F R=-0.01 totalR= 0.44 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   23  F --2-> G R= 0.13 totalR= 0.57 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    4   Step:   24  G --0-> F R=-0.03 totalR= 0.54 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   25  F --1-> E R=-0.02 totalR= 0.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   26  E --2-> H R= 0.15 totalR= 0.67 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    4   Step:   27  H --0-> E R=-0.02 totalR= 0.66 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   28  E --0-> A R=-0.02 totalR= 0.64 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   29  A --1-> B R=-0.02 totalR= 0.62 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    4   Step:   30  B --0-> S R=-0.02 totalR= 0.61 cost= 100 customerR=   0 optimum=6000\n",
            "Episode finished after 30 timesteps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3z35_dMMt6SW",
        "colab_type": "code",
        "outputId": "531e77e1-2c66-4309-c139-a7e13d38c35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%time optimum = baseline.find_optimum()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaled reward: 0.775\n",
            "Perfect path ['S', 'B', 'C', 'M', 'L', 'M', 'N', 'M', 'C', 'B', 'A', 'D', 'F', 'E', 'A', 'B', 'S']\n",
            "CPU times: user 76.8 ms, sys: 2.4 ms, total: 79.2 ms\n",
            "Wall time: 81 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KMb58O_q067F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}