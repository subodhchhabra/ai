{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v7\n",
        "\n",
        "## Changes from v6\n",
        "1. per episode set certain rewards to 0 to simulate different customers per consultant\n",
        "  \n",
        "## next steps\n",
        "1. cut off init phase when plotting learning curve\n",
        "1. configure custom network including regularization (https://blog.openai.com/quantifying-generalization-in-reinforcement-learning/)\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        # position, and up to 4 paths from that position, non existing path is -1000 and no position change\n",
        "        self.observation_space = spaces.Box(low=numpy.array([0,-1000,-1000,-1000,-1000]),\n",
        "                                             high=numpy.array([13,1000,1000,1000,1000]),\n",
        "                                             dtype=numpy.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = numpy.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=numpy.float32)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = len(self.map) - 1\n",
        "      number_per_consultant = int(number_of_customers/2)\n",
        "#       number_per_consultant = int(number_of_customers/1.5)\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e26f1a94-53c3-4842-bc4b-cc2fbeca4320"
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.  -300.   900.   800. -1000.]\n",
            "{'S': 0, 'A': 0, 'B': 1000, 'C': 1000, 'D': 0, 'E': 0, 'F': 1000, 'G': 0, 'H': 0, 'K': 1000, 'L': 1000, 'M': 0, 'N': 0, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "dde6fa10-d641-4ad2-a27c-047c76ac1c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.  -300.   900.   800. -1000.]\n",
            "Episode:    0   Step:    1  S --0-> A R=-0.05 totalR=-0.05 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    2  A --3-> D R=-0.02 totalR=-0.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    3  D --1-> F R=-0.01 totalR=-0.07 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR=-0.08 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.17 totalR=-0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.17 totalR=-0.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.17 totalR=-0.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.17 totalR=-0.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.76 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.17 totalR=-0.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  F --1-> E R= 0.15 totalR=-0.77 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R=-0.02 totalR=-0.79 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR=-0.81 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.17 totalR=-0.97 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.02 totalR=-0.99 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.02 totalR=-1.01 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.02 totalR=-1.02 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.05 totalR=-1.07 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  S --2-> C R= 0.13 totalR=-0.94 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   20  C --1-> B R= 0.16 totalR=-0.78 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.79 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  C --3-> L R= 0.13 totalR=-0.66 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.17 totalR=-0.82 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.17 totalR=-0.99 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-1.02 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-1.03 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.02 totalR=-1.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.02 totalR=-1.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.02 totalR=-1.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.05 totalR=-1.13 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.02 totalR=-1.15 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.02 totalR=-1.17 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.17 totalR=-1.33 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.05 totalR=-1.38 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.02 totalR=-1.40 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-1.41 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   37  F --2-> G R= 0.13 totalR=-1.27 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.17 totalR=-1.44 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.17 totalR=-1.61 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-1.68 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.17 totalR=-1.84 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-1.88 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.02 totalR=-1.89 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.17 totalR=-2.06 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.02 totalR=-2.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.17 totalR=-2.24 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.17 totalR=-2.41 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-2.44 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.17 totalR=-2.61 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-2.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.02 totalR=-2.66 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.02 totalR=-2.67 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.02 totalR=-2.69 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.17 totalR=-2.86 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.02 totalR=-2.87 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.02 totalR=-2.89 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.17 totalR=-3.06 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.02 totalR=-3.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.02 totalR=-3.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.17 totalR=-3.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.17 totalR=-3.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.17 totalR=-3.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.17 totalR=-3.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.17 totalR=-3.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.02 totalR=-3.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.02 totalR=-3.96 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.02 totalR=-3.97 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.05 totalR=-4.02 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   70  S --0-> A R=-0.05 totalR=-4.07 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   71  A --1-> B R=-0.02 totalR=-4.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   72  B --1-> A R=-0.02 totalR=-4.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   73  A --2-> E R=-0.02 totalR=-4.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   74  E --0-> A R=-0.02 totalR=-4.14 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   75  A --0-> S R=-0.05 totalR=-4.19 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   76  S --1-> B R=-0.02 totalR=-4.21 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   77  B --3-> K R=-0.03 totalR=-4.24 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   78  K --0-> B R=-0.03 totalR=-4.27 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   79  B --1-> A R=-0.02 totalR=-4.29 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   80  A --2-> E R=-0.02 totalR=-4.31 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   81  E --2-> H R=-0.02 totalR=-4.32 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   82  H --3-> H R=-0.17 totalR=-4.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   83  H --0-> E R=-0.02 totalR=-4.51 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   84  E --1-> F R=-0.02 totalR=-4.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   85  F --1-> E R=-0.02 totalR=-4.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   86  E --3-> E R=-0.17 totalR=-4.71 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   87  E --1-> F R=-0.02 totalR=-4.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   88  F --1-> E R=-0.02 totalR=-4.74 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   89  E --3-> E R=-0.17 totalR=-4.91 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   90  E --2-> H R=-0.02 totalR=-4.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   91  H --3-> H R=-0.17 totalR=-5.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   92  H --3-> H R=-0.17 totalR=-5.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   93  H --2-> H R=-0.17 totalR=-5.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   94  H --2-> H R=-0.17 totalR=-5.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   95  H --3-> H R=-0.17 totalR=-5.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   96  H --0-> E R=-0.02 totalR=-5.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   97  E --2-> H R=-0.02 totalR=-5.79 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   98  H --3-> H R=-0.17 totalR=-5.96 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   99  H --1-> K R=-0.05 totalR=-6.01 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  100  K --0-> B R=-0.03 totalR=-6.04 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  101  B --1-> A R=-0.02 totalR=-6.06 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  102  A --2-> E R=-0.02 totalR=-6.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  103  E --0-> A R=-0.02 totalR=-6.09 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  104  A --3-> D R=-0.02 totalR=-6.11 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  105  D --0-> A R=-0.02 totalR=-6.12 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  106  A --2-> E R=-0.02 totalR=-6.14 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  107  E --0-> A R=-0.02 totalR=-6.16 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  108  A --3-> D R=-0.02 totalR=-6.17 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  109  D --3-> D R=-0.17 totalR=-6.34 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  110  D --0-> A R=-0.02 totalR=-6.36 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  111  A --3-> D R=-0.02 totalR=-6.37 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  112  D --0-> A R=-0.02 totalR=-6.39 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  113  A --0-> S R=-0.05 totalR=-6.44 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  114  S --0-> A R=-0.05 totalR=-6.49 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  115  A --0-> S R=-0.05 totalR=-6.54 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  116  S --2-> C R=-0.03 totalR=-6.57 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  117  C --3-> L R=-0.03 totalR=-6.61 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  118  L --0-> C R=-0.03 totalR=-6.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  119  C --3-> L R=-0.03 totalR=-6.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  120  L --2-> L R=-0.17 totalR=-6.84 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  121  L --3-> L R=-0.17 totalR=-7.01 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  122  L --3-> L R=-0.17 totalR=-7.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  123  L --1-> M R=-0.01 totalR=-7.18 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  124  M --1-> L R=-0.01 totalR=-7.19 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  125  L --1-> M R=-0.01 totalR=-7.20 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  126  M --0-> C R=-0.02 totalR=-7.22 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  127  C --1-> B R=-0.01 totalR=-7.22 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  128  B --1-> A R=-0.02 totalR=-7.24 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  129  A --1-> B R=-0.02 totalR=-7.26 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  130  B --3-> K R=-0.03 totalR=-7.29 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  131  K --0-> B R=-0.03 totalR=-7.32 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  132  B --3-> K R=-0.03 totalR=-7.36 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  133  K --1-> H R=-0.05 totalR=-7.41 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  134  H --2-> H R=-0.17 totalR=-7.57 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  135  H --0-> E R=-0.02 totalR=-7.59 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  136  E --1-> F R=-0.02 totalR=-7.61 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  137  F --2-> G R=-0.03 totalR=-7.64 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  138  G --0-> F R=-0.03 totalR=-7.67 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  139  F --2-> G R=-0.03 totalR=-7.71 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  140  G --0-> F R=-0.03 totalR=-7.74 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  141  F --1-> E R=-0.02 totalR=-7.76 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  142  E --3-> E R=-0.17 totalR=-7.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  143  E --2-> H R=-0.02 totalR=-7.94 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  144  H --2-> H R=-0.17 totalR=-8.11 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  145  H --1-> K R=-0.05 totalR=-8.16 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  146  K --0-> B R=-0.03 totalR=-8.19 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  147  B --3-> K R=-0.03 totalR=-8.22 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  148  K --1-> H R=-0.05 totalR=-8.28 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  149  H --1-> K R=-0.05 totalR=-8.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  150  K --3-> K R=-0.17 totalR=-8.49 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  151  K --0-> B R=-0.03 totalR=-8.53 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  152  B --2-> C R=-0.01 totalR=-8.53 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  153  C --2-> M R=-0.02 totalR=-8.55 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  154  M --3-> M R=-0.17 totalR=-8.72 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  155  M --2-> N R= 0.15 totalR=-8.57 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:  156  N --3-> N R=-0.17 totalR=-8.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  157  N --3-> N R=-0.17 totalR=-8.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  158  N --3-> N R=-0.17 totalR=-9.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  159  N --2-> N R=-0.17 totalR=-9.23 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  160  N --1-> O R=-0.02 totalR=-9.25 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  161  O --2-> O R=-0.17 totalR=-9.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  162  O --2-> O R=-0.17 totalR=-9.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  163  O --3-> O R=-0.17 totalR=-9.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  164  O --2-> O R=-0.17 totalR=-9.92 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  165  O --3-> O R=-0.17 totalR=-10.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  166  O --3-> O R=-0.17 totalR=-10.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  167  O --2-> O R=-0.17 totalR=-10.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  168  O --2-> O R=-0.17 totalR=-10.58 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  169  O --3-> O R=-0.17 totalR=-10.75 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  170  O --0-> N R=-0.02 totalR=-10.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  171  N --1-> O R=-0.02 totalR=-10.78 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  172  O --2-> O R=-0.17 totalR=-10.95 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  173  O --3-> O R=-0.17 totalR=-11.12 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  174  O --2-> O R=-0.17 totalR=-11.28 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  175  O --1-> G R=-0.05 totalR=-11.33 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  176  G --2-> G R=-0.17 totalR=-11.50 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  177  G --1-> O R=-0.05 totalR=-11.55 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  178  O --0-> N R=-0.02 totalR=-11.57 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  179  N --2-> N R=-0.17 totalR=-11.73 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  180  N --2-> N R=-0.17 totalR=-11.90 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  181  N --3-> N R=-0.17 totalR=-12.07 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  182  N --0-> M R=-0.02 totalR=-12.08 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  183  M --3-> M R=-0.17 totalR=-12.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  184  M --2-> N R=-0.02 totalR=-12.27 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  185  N --3-> N R=-0.17 totalR=-12.43 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  186  N --0-> M R=-0.02 totalR=-12.45 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  187  M --0-> C R=-0.02 totalR=-12.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  188  C --2-> M R=-0.02 totalR=-12.48 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  189  M --0-> C R=-0.02 totalR=-12.50 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  190  C --2-> M R=-0.02 totalR=-12.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  191  M --3-> M R=-0.17 totalR=-12.68 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  192  M --2-> N R=-0.02 totalR=-12.70 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  193  N --2-> N R=-0.17 totalR=-12.87 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  194  N --3-> N R=-0.17 totalR=-13.03 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  195  N --0-> M R=-0.02 totalR=-13.05 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  196  M --0-> C R=-0.02 totalR=-13.07 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:  197  C --0-> S R=-0.03 totalR=-13.10 cost= 200 customerR=   0 optimum=6000\n",
            "Done: episodes=     1  avgSteps=197.00  avgTotalReward=-13.10\n",
            "Episode finished after 197 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "* random has lower total reward than version with dense customers \n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* additional pernalty for liiegal moves 1000\n",
        "* all rewards: 6000\n",
        "* perfect score???\n",
        "* estimate: half the travel cost and no illegal moves: (6000 - 1250) / 6000 = .79\n",
        "* but: rewards are much more sparse while routes stay the same, maybe expect less\n"
      ]
    },
    {
      "metadata": {
        "id": "Qvi-T-YuEO0A",
        "colab_type": "code",
        "outputId": "220a1222-b752-4dd0-c594-20607742240e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "30eface0-b445-4008-f4fa-e75500bc23a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12563
        }
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/models.py#L30\n",
        "%time model = ppo2.learn(\\\n",
        "    env=monitored_env,\\\n",
        "    network='mlp',\\\n",
        "    num_hidden=2000,\\\n",
        "    num_layers=3,\\\n",
        "    ent_coef=0.03,\\\n",
        "    total_timesteps=1000000)\n",
        "\n",
        "# %time model = ppo2.learn(\\\n",
        "#     env=monitored_env,\\\n",
        "#     network='mlp',\\\n",
        "#     num_hidden=2000,\\\n",
        "#     num_layers=3,\\\n",
        "#     ent_coef=0.1,\\\n",
        "#     total_timesteps=500000)\n",
        "\n",
        "# model = ppo2.learn(\n",
        "#     env=monitored_env,\\\n",
        "#     layer_norm=True,\\\n",
        "#     network='mlp',\\\n",
        "#     num_hidden=2000,\\\n",
        "#     activation=tf.nn.relu,\\\n",
        "#     num_layers=3,\\\n",
        "#     ent_coef=0.03,\\\n",
        "#     total_timesteps=1000000)\n",
        "\n",
        "# monitored_env = bench.Monitor(env, log_dir)\n",
        "# https://en.wikipedia.org/wiki/Q-learning#Influence_of_variables\n",
        "# %time model = deepq.learn(\\\n",
        "#         monitored_env,\\\n",
        "#         seed=42,\\\n",
        "#         network='mlp',\\\n",
        "#         lr=1e-3,\\\n",
        "#         gamma=0.99,\\\n",
        "#         total_timesteps=30000,\\\n",
        "#         buffer_size=50000,\\\n",
        "#         exploration_fraction=0.5,\\\n",
        "#         exploration_final_eps=0.02,\\\n",
        "#         print_freq=1000)\n",
        "\n",
        "model.save('berater-ppo-v7.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-01-03-17-53-40-512762\n",
            "-------------------------------------\n",
            "| approxkl           | 0.024177177  |\n",
            "| clipfrac           | 0.3881836    |\n",
            "| eplenmean          | 170          |\n",
            "| eprewmean          | -10.956254   |\n",
            "| explained_variance | -0.726       |\n",
            "| fps                | 302          |\n",
            "| nupdates           | 1            |\n",
            "| policy_entropy     | 1.3623753    |\n",
            "| policy_loss        | -0.016835421 |\n",
            "| serial_timesteps   | 2048         |\n",
            "| time_elapsed       | 6.77         |\n",
            "| total_timesteps    | 2048         |\n",
            "| value_loss         | 3.8393013    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.015946671  |\n",
            "| clipfrac           | 0.23449707   |\n",
            "| eplenmean          | 62           |\n",
            "| eprewmean          | -0.60100025  |\n",
            "| explained_variance | 0.0156       |\n",
            "| fps                | 320          |\n",
            "| nupdates           | 10           |\n",
            "| policy_entropy     | 1.0334549    |\n",
            "| policy_loss        | 0.0014418864 |\n",
            "| serial_timesteps   | 20480        |\n",
            "| time_elapsed       | 61.2         |\n",
            "| total_timesteps    | 20480        |\n",
            "| value_loss         | 0.08584598   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011005503  |\n",
            "| clipfrac           | 0.17163086   |\n",
            "| eplenmean          | 42.9         |\n",
            "| eprewmean          | 0.13516669   |\n",
            "| explained_variance | -0.105       |\n",
            "| fps                | 331          |\n",
            "| nupdates           | 20           |\n",
            "| policy_entropy     | 0.8998661    |\n",
            "| policy_loss        | 0.0017523828 |\n",
            "| serial_timesteps   | 40960        |\n",
            "| time_elapsed       | 122          |\n",
            "| total_timesteps    | 40960        |\n",
            "| value_loss         | 0.025226705  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011286299   |\n",
            "| clipfrac           | 0.16369629    |\n",
            "| eplenmean          | 44.5          |\n",
            "| eprewmean          | 0.10416665    |\n",
            "| explained_variance | 0.0309        |\n",
            "| fps                | 338           |\n",
            "| nupdates           | 30            |\n",
            "| policy_entropy     | 0.88586503    |\n",
            "| policy_loss        | -0.0035313321 |\n",
            "| serial_timesteps   | 61440         |\n",
            "| time_elapsed       | 184           |\n",
            "| total_timesteps    | 61440         |\n",
            "| value_loss         | 0.02617354    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.015842121  |\n",
            "| clipfrac           | 0.2475586    |\n",
            "| eplenmean          | 46.7         |\n",
            "| eprewmean          | 0.091583386  |\n",
            "| explained_variance | 0.276        |\n",
            "| fps                | 339          |\n",
            "| nupdates           | 40           |\n",
            "| policy_entropy     | 0.880702     |\n",
            "| policy_loss        | 0.0015386525 |\n",
            "| serial_timesteps   | 81920        |\n",
            "| time_elapsed       | 245          |\n",
            "| total_timesteps    | 81920        |\n",
            "| value_loss         | 0.023725761  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011928421   |\n",
            "| clipfrac           | 0.18054199    |\n",
            "| eplenmean          | 45.4          |\n",
            "| eprewmean          | 0.15650001    |\n",
            "| explained_variance | 0.213         |\n",
            "| fps                | 334           |\n",
            "| nupdates           | 50            |\n",
            "| policy_entropy     | 0.7974844     |\n",
            "| policy_loss        | -0.0003246335 |\n",
            "| serial_timesteps   | 102400        |\n",
            "| time_elapsed       | 305           |\n",
            "| total_timesteps    | 102400        |\n",
            "| value_loss         | 0.018727742   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010069231   |\n",
            "| clipfrac           | 0.15319824    |\n",
            "| eplenmean          | 53.8          |\n",
            "| eprewmean          | 0.06416674    |\n",
            "| explained_variance | 0.234         |\n",
            "| fps                | 339           |\n",
            "| nupdates           | 60            |\n",
            "| policy_entropy     | 0.7287153     |\n",
            "| policy_loss        | -0.0014136966 |\n",
            "| serial_timesteps   | 122880        |\n",
            "| time_elapsed       | 366           |\n",
            "| total_timesteps    | 122880        |\n",
            "| value_loss         | 0.020971984   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0135428915 |\n",
            "| clipfrac           | 0.19335938   |\n",
            "| eplenmean          | 37.7         |\n",
            "| eprewmean          | 0.32125005   |\n",
            "| explained_variance | 0.292        |\n",
            "| fps                | 335          |\n",
            "| nupdates           | 70           |\n",
            "| policy_entropy     | 0.719994     |\n",
            "| policy_loss        | 0.0019326955 |\n",
            "| serial_timesteps   | 143360       |\n",
            "| time_elapsed       | 427          |\n",
            "| total_timesteps    | 143360       |\n",
            "| value_loss         | 0.013866181  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0073041013  |\n",
            "| clipfrac           | 0.091430664   |\n",
            "| eplenmean          | 34.8          |\n",
            "| eprewmean          | 0.30033332    |\n",
            "| explained_variance | 0.278         |\n",
            "| fps                | 341           |\n",
            "| nupdates           | 80            |\n",
            "| policy_entropy     | 0.6586115     |\n",
            "| policy_loss        | -0.0015038659 |\n",
            "| serial_timesteps   | 163840        |\n",
            "| time_elapsed       | 488           |\n",
            "| total_timesteps    | 163840        |\n",
            "| value_loss         | 0.015785728   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.015818626   |\n",
            "| clipfrac           | 0.080078125   |\n",
            "| eplenmean          | 22.6          |\n",
            "| eprewmean          | 0.45200002    |\n",
            "| explained_variance | -0.366        |\n",
            "| fps                | 322           |\n",
            "| nupdates           | 90            |\n",
            "| policy_entropy     | 0.3580658     |\n",
            "| policy_loss        | -0.0012641815 |\n",
            "| serial_timesteps   | 184320        |\n",
            "| time_elapsed       | 549           |\n",
            "| total_timesteps    | 184320        |\n",
            "| value_loss         | 0.032465868   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.012647734    |\n",
            "| clipfrac           | 0.095214844    |\n",
            "| eplenmean          | 19.5           |\n",
            "| eprewmean          | 0.53675        |\n",
            "| explained_variance | 0.398          |\n",
            "| fps                | 337            |\n",
            "| nupdates           | 100            |\n",
            "| policy_entropy     | 0.30879512     |\n",
            "| policy_loss        | -0.00075081363 |\n",
            "| serial_timesteps   | 204800         |\n",
            "| time_elapsed       | 609            |\n",
            "| total_timesteps    | 204800         |\n",
            "| value_loss         | 0.018003434    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010891131   |\n",
            "| clipfrac           | 0.07800293    |\n",
            "| eplenmean          | 19.5          |\n",
            "| eprewmean          | 0.54583335    |\n",
            "| explained_variance | 0.406         |\n",
            "| fps                | 338           |\n",
            "| nupdates           | 110           |\n",
            "| policy_entropy     | 0.25581518    |\n",
            "| policy_loss        | -0.0031697901 |\n",
            "| serial_timesteps   | 225280        |\n",
            "| time_elapsed       | 670           |\n",
            "| total_timesteps    | 225280        |\n",
            "| value_loss         | 0.014334027   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0250365      |\n",
            "| clipfrac           | 0.10461426     |\n",
            "| eplenmean          | 20.3           |\n",
            "| eprewmean          | 0.5290833      |\n",
            "| explained_variance | 0.422          |\n",
            "| fps                | 341            |\n",
            "| nupdates           | 120            |\n",
            "| policy_entropy     | 0.33576965     |\n",
            "| policy_loss        | -0.00019766146 |\n",
            "| serial_timesteps   | 245760         |\n",
            "| time_elapsed       | 731            |\n",
            "| total_timesteps    | 245760         |\n",
            "| value_loss         | 0.015018473    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010517825  |\n",
            "| clipfrac           | 0.05090332   |\n",
            "| eplenmean          | 17.8         |\n",
            "| eprewmean          | 0.571        |\n",
            "| explained_variance | 0.455        |\n",
            "| fps                | 330          |\n",
            "| nupdates           | 130          |\n",
            "| policy_entropy     | 0.19637649   |\n",
            "| policy_loss        | 0.0012938598 |\n",
            "| serial_timesteps   | 266240       |\n",
            "| time_elapsed       | 791          |\n",
            "| total_timesteps    | 266240       |\n",
            "| value_loss         | 0.014722139  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.016871251   |\n",
            "| clipfrac           | 0.07556152    |\n",
            "| eplenmean          | 18.9          |\n",
            "| eprewmean          | 0.5409167     |\n",
            "| explained_variance | 0.44          |\n",
            "| fps                | 340           |\n",
            "| nupdates           | 140           |\n",
            "| policy_entropy     | 0.23668163    |\n",
            "| policy_loss        | -0.0008042218 |\n",
            "| serial_timesteps   | 286720        |\n",
            "| time_elapsed       | 851           |\n",
            "| total_timesteps    | 286720        |\n",
            "| value_loss         | 0.015742248   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.015267039  |\n",
            "| clipfrac           | 0.09802246   |\n",
            "| eplenmean          | 18.7         |\n",
            "| eprewmean          | 0.54441667   |\n",
            "| explained_variance | 0.297        |\n",
            "| fps                | 349          |\n",
            "| nupdates           | 150          |\n",
            "| policy_entropy     | 0.27113977   |\n",
            "| policy_loss        | -0.006522676 |\n",
            "| serial_timesteps   | 307200       |\n",
            "| time_elapsed       | 910          |\n",
            "| total_timesteps    | 307200       |\n",
            "| value_loss         | 0.016290722  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.014128544  |\n",
            "| clipfrac           | 0.12524414   |\n",
            "| eplenmean          | 20.4         |\n",
            "| eprewmean          | 0.46266666   |\n",
            "| explained_variance | 0.434        |\n",
            "| fps                | 344          |\n",
            "| nupdates           | 160          |\n",
            "| policy_entropy     | 0.30669966   |\n",
            "| policy_loss        | -0.005220105 |\n",
            "| serial_timesteps   | 327680       |\n",
            "| time_elapsed       | 970          |\n",
            "| total_timesteps    | 327680       |\n",
            "| value_loss         | 0.015653014  |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.010361157    |\n",
            "| clipfrac           | 0.080322266    |\n",
            "| eplenmean          | 19.1           |\n",
            "| eprewmean          | 0.55266666     |\n",
            "| explained_variance | 0.441          |\n",
            "| fps                | 337            |\n",
            "| nupdates           | 170            |\n",
            "| policy_entropy     | 0.23292288     |\n",
            "| policy_loss        | -3.8235798e-05 |\n",
            "| serial_timesteps   | 348160         |\n",
            "| time_elapsed       | 1.03e+03       |\n",
            "| total_timesteps    | 348160         |\n",
            "| value_loss         | 0.014856313    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.01268543   |\n",
            "| clipfrac           | 0.09094238   |\n",
            "| eplenmean          | 21.2         |\n",
            "| eprewmean          | 0.5028333    |\n",
            "| explained_variance | 0.427        |\n",
            "| fps                | 347          |\n",
            "| nupdates           | 180          |\n",
            "| policy_entropy     | 0.2685976    |\n",
            "| policy_loss        | 0.0009916946 |\n",
            "| serial_timesteps   | 368640       |\n",
            "| time_elapsed       | 1.09e+03     |\n",
            "| total_timesteps    | 368640       |\n",
            "| value_loss         | 0.013933193  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.025883323  |\n",
            "| clipfrac           | 0.092285156  |\n",
            "| eplenmean          | 19.6         |\n",
            "| eprewmean          | 0.4958333    |\n",
            "| explained_variance | 0.454        |\n",
            "| fps                | 341          |\n",
            "| nupdates           | 190          |\n",
            "| policy_entropy     | 0.31394795   |\n",
            "| policy_loss        | 0.0013619777 |\n",
            "| serial_timesteps   | 389120       |\n",
            "| time_elapsed       | 1.15e+03     |\n",
            "| total_timesteps    | 389120       |\n",
            "| value_loss         | 0.014366043  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.011539715  |\n",
            "| clipfrac           | 0.11608887   |\n",
            "| eplenmean          | 18.9         |\n",
            "| eprewmean          | 0.5340833    |\n",
            "| explained_variance | 0.442        |\n",
            "| fps                | 348          |\n",
            "| nupdates           | 200          |\n",
            "| policy_entropy     | 0.26625568   |\n",
            "| policy_loss        | -0.001174534 |\n",
            "| serial_timesteps   | 409600       |\n",
            "| time_elapsed       | 1.21e+03     |\n",
            "| total_timesteps    | 409600       |\n",
            "| value_loss         | 0.014494464  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.010178238  |\n",
            "| clipfrac           | 0.05053711   |\n",
            "| eplenmean          | 18.4         |\n",
            "| eprewmean          | 0.53533334   |\n",
            "| explained_variance | 0.44         |\n",
            "| fps                | 323          |\n",
            "| nupdates           | 210          |\n",
            "| policy_entropy     | 0.22166494   |\n",
            "| policy_loss        | 0.003345249  |\n",
            "| serial_timesteps   | 430080       |\n",
            "| time_elapsed       | 1.27e+03     |\n",
            "| total_timesteps    | 430080       |\n",
            "| value_loss         | 0.0136443665 |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00445418    |\n",
            "| clipfrac           | 0.045288086   |\n",
            "| eplenmean          | 19.1          |\n",
            "| eprewmean          | 0.54116666    |\n",
            "| explained_variance | 0.45          |\n",
            "| fps                | 337           |\n",
            "| nupdates           | 220           |\n",
            "| policy_entropy     | 0.23178647    |\n",
            "| policy_loss        | 0.00041507138 |\n",
            "| serial_timesteps   | 450560        |\n",
            "| time_elapsed       | 1.33e+03      |\n",
            "| total_timesteps    | 450560        |\n",
            "| value_loss         | 0.01717523    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0033664429  |\n",
            "| clipfrac           | 0.032958984   |\n",
            "| eplenmean          | 17.7          |\n",
            "| eprewmean          | 0.5698334     |\n",
            "| explained_variance | 0.48          |\n",
            "| fps                | 338           |\n",
            "| nupdates           | 230           |\n",
            "| policy_entropy     | 0.21915734    |\n",
            "| policy_loss        | 0.00044163896 |\n",
            "| serial_timesteps   | 471040        |\n",
            "| time_elapsed       | 1.39e+03      |\n",
            "| total_timesteps    | 471040        |\n",
            "| value_loss         | 0.0130224135  |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.040838003 |\n",
            "| clipfrac           | 0.12561035  |\n",
            "| eplenmean          | 23.8        |\n",
            "| eprewmean          | 0.4595      |\n",
            "| explained_variance | 0.451       |\n",
            "| fps                | 335         |\n",
            "| nupdates           | 240         |\n",
            "| policy_entropy     | 0.30218372  |\n",
            "| policy_loss        | -0.00482791 |\n",
            "| serial_timesteps   | 491520      |\n",
            "| time_elapsed       | 1.45e+03    |\n",
            "| total_timesteps    | 491520      |\n",
            "| value_loss         | 0.018272012 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.00558042   |\n",
            "| clipfrac           | 0.038330078  |\n",
            "| eplenmean          | 19.1         |\n",
            "| eprewmean          | 0.5384167    |\n",
            "| explained_variance | 0.488        |\n",
            "| fps                | 322          |\n",
            "| nupdates           | 250          |\n",
            "| policy_entropy     | 0.24916732   |\n",
            "| policy_loss        | 0.0012326968 |\n",
            "| serial_timesteps   | 512000       |\n",
            "| time_elapsed       | 1.51e+03     |\n",
            "| total_timesteps    | 512000       |\n",
            "| value_loss         | 0.013632581  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0047918297 |\n",
            "| clipfrac           | 0.052856445  |\n",
            "| eplenmean          | 19.3         |\n",
            "| eprewmean          | 0.54675      |\n",
            "| explained_variance | 0.476        |\n",
            "| fps                | 340          |\n",
            "| nupdates           | 260          |\n",
            "| policy_entropy     | 0.22975598   |\n",
            "| policy_loss        | -4.37547e-05 |\n",
            "| serial_timesteps   | 532480       |\n",
            "| time_elapsed       | 1.57e+03     |\n",
            "| total_timesteps    | 532480       |\n",
            "| value_loss         | 0.012064733  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0132413255 |\n",
            "| clipfrac           | 0.11303711   |\n",
            "| eplenmean          | 23.9         |\n",
            "| eprewmean          | 0.42958337   |\n",
            "| explained_variance | 0.268        |\n",
            "| fps                | 344          |\n",
            "| nupdates           | 270          |\n",
            "| policy_entropy     | 0.3541968    |\n",
            "| policy_loss        | -0.005277409 |\n",
            "| serial_timesteps   | 552960       |\n",
            "| time_elapsed       | 1.63e+03     |\n",
            "| total_timesteps    | 552960       |\n",
            "| value_loss         | 0.01776901   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.03377834   |\n",
            "| clipfrac           | 0.19909668   |\n",
            "| eplenmean          | 25.9         |\n",
            "| eprewmean          | 0.27775      |\n",
            "| explained_variance | 0.316        |\n",
            "| fps                | 339          |\n",
            "| nupdates           | 280          |\n",
            "| policy_entropy     | 0.3705266    |\n",
            "| policy_loss        | -0.010868687 |\n",
            "| serial_timesteps   | 573440       |\n",
            "| time_elapsed       | 1.7e+03      |\n",
            "| total_timesteps    | 573440       |\n",
            "| value_loss         | 0.021305582  |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0039192485   |\n",
            "| clipfrac           | 0.043701172    |\n",
            "| eplenmean          | 17.4           |\n",
            "| eprewmean          | 0.56125003     |\n",
            "| explained_variance | 0.432          |\n",
            "| fps                | 332            |\n",
            "| nupdates           | 290            |\n",
            "| policy_entropy     | 0.21579511     |\n",
            "| policy_loss        | -0.00014382467 |\n",
            "| serial_timesteps   | 593920         |\n",
            "| time_elapsed       | 1.75e+03       |\n",
            "| total_timesteps    | 593920         |\n",
            "| value_loss         | 0.015229918    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.006454082  |\n",
            "| clipfrac           | 0.045166016  |\n",
            "| eplenmean          | 17.6         |\n",
            "| eprewmean          | 0.57341665   |\n",
            "| explained_variance | 0.492        |\n",
            "| fps                | 343          |\n",
            "| nupdates           | 300          |\n",
            "| policy_entropy     | 0.18771712   |\n",
            "| policy_loss        | 0.0011101891 |\n",
            "| serial_timesteps   | 614400       |\n",
            "| time_elapsed       | 1.81e+03     |\n",
            "| total_timesteps    | 614400       |\n",
            "| value_loss         | 0.012818787  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.008908167 |\n",
            "| clipfrac           | 0.095581055 |\n",
            "| eplenmean          | 18.7        |\n",
            "| eprewmean          | 0.55258334  |\n",
            "| explained_variance | 0.477       |\n",
            "| fps                | 343         |\n",
            "| nupdates           | 310         |\n",
            "| policy_entropy     | 0.24128953  |\n",
            "| policy_loss        | 0.003536658 |\n",
            "| serial_timesteps   | 634880      |\n",
            "| time_elapsed       | 1.87e+03    |\n",
            "| total_timesteps    | 634880      |\n",
            "| value_loss         | 0.013984968 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.007600406   |\n",
            "| clipfrac           | 0.06335449    |\n",
            "| eplenmean          | 18.3          |\n",
            "| eprewmean          | 0.55558336    |\n",
            "| explained_variance | 0.406         |\n",
            "| fps                | 344           |\n",
            "| nupdates           | 320           |\n",
            "| policy_entropy     | 0.20552339    |\n",
            "| policy_loss        | 0.00010455024 |\n",
            "| serial_timesteps   | 655360        |\n",
            "| time_elapsed       | 1.93e+03      |\n",
            "| total_timesteps    | 655360        |\n",
            "| value_loss         | 0.016600234   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0072643096  |\n",
            "| clipfrac           | 0.05883789    |\n",
            "| eplenmean          | 18.5          |\n",
            "| eprewmean          | 0.5485        |\n",
            "| explained_variance | 0.46          |\n",
            "| fps                | 329           |\n",
            "| nupdates           | 330           |\n",
            "| policy_entropy     | 0.24081829    |\n",
            "| policy_loss        | 0.00077866623 |\n",
            "| serial_timesteps   | 675840        |\n",
            "| time_elapsed       | 2e+03         |\n",
            "| total_timesteps    | 675840        |\n",
            "| value_loss         | 0.012806539   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.013132986   |\n",
            "| clipfrac           | 0.091796875   |\n",
            "| eplenmean          | 19.8          |\n",
            "| eprewmean          | 0.5000833     |\n",
            "| explained_variance | 0.483         |\n",
            "| fps                | 344           |\n",
            "| nupdates           | 340           |\n",
            "| policy_entropy     | 0.35132617    |\n",
            "| policy_loss        | 0.00040727755 |\n",
            "| serial_timesteps   | 696320        |\n",
            "| time_elapsed       | 2.05e+03      |\n",
            "| total_timesteps    | 696320        |\n",
            "| value_loss         | 0.014669991   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.02576183   |\n",
            "| clipfrac           | 0.080200195  |\n",
            "| eplenmean          | 18.5         |\n",
            "| eprewmean          | 0.5289167    |\n",
            "| explained_variance | 0.452        |\n",
            "| fps                | 344          |\n",
            "| nupdates           | 350          |\n",
            "| policy_entropy     | 0.17418532   |\n",
            "| policy_loss        | -0.002515376 |\n",
            "| serial_timesteps   | 716800       |\n",
            "| time_elapsed       | 2.11e+03     |\n",
            "| total_timesteps    | 716800       |\n",
            "| value_loss         | 0.017157184  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0021541019  |\n",
            "| clipfrac           | 0.023925781   |\n",
            "| eplenmean          | 17.4          |\n",
            "| eprewmean          | 0.5679167     |\n",
            "| explained_variance | 0.406         |\n",
            "| fps                | 344           |\n",
            "| nupdates           | 360           |\n",
            "| policy_entropy     | 0.19696562    |\n",
            "| policy_loss        | -0.0003609446 |\n",
            "| serial_timesteps   | 737280        |\n",
            "| time_elapsed       | 2.17e+03      |\n",
            "| total_timesteps    | 737280        |\n",
            "| value_loss         | 0.01904216    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009941841  |\n",
            "| clipfrac           | 0.08508301   |\n",
            "| eplenmean          | 17.7         |\n",
            "| eprewmean          | 0.53458333   |\n",
            "| explained_variance | 0.478        |\n",
            "| fps                | 342          |\n",
            "| nupdates           | 370          |\n",
            "| policy_entropy     | 0.21097156   |\n",
            "| policy_loss        | -0.001317797 |\n",
            "| serial_timesteps   | 757760       |\n",
            "| time_elapsed       | 2.23e+03     |\n",
            "| total_timesteps    | 757760       |\n",
            "| value_loss         | 0.014177785  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.010739124 |\n",
            "| clipfrac           | 0.075683594 |\n",
            "| eplenmean          | 19.2        |\n",
            "| eprewmean          | 0.5576667   |\n",
            "| explained_variance | 0.443       |\n",
            "| fps                | 345         |\n",
            "| nupdates           | 380         |\n",
            "| policy_entropy     | 0.2817192   |\n",
            "| policy_loss        | 0.0016285   |\n",
            "| serial_timesteps   | 778240      |\n",
            "| time_elapsed       | 2.29e+03    |\n",
            "| total_timesteps    | 778240      |\n",
            "| value_loss         | 0.013604088 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.006562406  |\n",
            "| clipfrac           | 0.06225586   |\n",
            "| eplenmean          | 18           |\n",
            "| eprewmean          | 0.5735       |\n",
            "| explained_variance | 0.482        |\n",
            "| fps                | 348          |\n",
            "| nupdates           | 390          |\n",
            "| policy_entropy     | 0.24939492   |\n",
            "| policy_loss        | 0.0028693406 |\n",
            "| serial_timesteps   | 798720       |\n",
            "| time_elapsed       | 2.35e+03     |\n",
            "| total_timesteps    | 798720       |\n",
            "| value_loss         | 0.014509615  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0076285074  |\n",
            "| clipfrac           | 0.07287598    |\n",
            "| eplenmean          | 21.7          |\n",
            "| eprewmean          | 0.5326667     |\n",
            "| explained_variance | 0.41          |\n",
            "| fps                | 345           |\n",
            "| nupdates           | 400           |\n",
            "| policy_entropy     | 0.28856677    |\n",
            "| policy_loss        | -0.0041106082 |\n",
            "| serial_timesteps   | 819200        |\n",
            "| time_elapsed       | 2.41e+03      |\n",
            "| total_timesteps    | 819200        |\n",
            "| value_loss         | 0.013151536   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0074762786 |\n",
            "| clipfrac           | 0.036865234  |\n",
            "| eplenmean          | 17.6         |\n",
            "| eprewmean          | 0.575        |\n",
            "| explained_variance | 0.461        |\n",
            "| fps                | 329          |\n",
            "| nupdates           | 410          |\n",
            "| policy_entropy     | 0.13464096   |\n",
            "| policy_loss        | 0.0004496024 |\n",
            "| serial_timesteps   | 839680       |\n",
            "| time_elapsed       | 2.47e+03     |\n",
            "| total_timesteps    | 839680       |\n",
            "| value_loss         | 0.0156239765 |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.03290897  |\n",
            "| clipfrac           | 0.15148926  |\n",
            "| eplenmean          | 17.8        |\n",
            "| eprewmean          | 0.5611667   |\n",
            "| explained_variance | 0.466       |\n",
            "| fps                | 345         |\n",
            "| nupdates           | 420         |\n",
            "| policy_entropy     | 0.19129722  |\n",
            "| policy_loss        | 0.020027542 |\n",
            "| serial_timesteps   | 860160      |\n",
            "| time_elapsed       | 2.53e+03    |\n",
            "| total_timesteps    | 860160      |\n",
            "| value_loss         | 0.014703327 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.010617953   |\n",
            "| clipfrac           | 0.10839844    |\n",
            "| eplenmean          | 28.9          |\n",
            "| eprewmean          | 0.40741664    |\n",
            "| explained_variance | 0.355         |\n",
            "| fps                | 353           |\n",
            "| nupdates           | 430           |\n",
            "| policy_entropy     | 0.43522653    |\n",
            "| policy_loss        | -0.0046791825 |\n",
            "| serial_timesteps   | 880640        |\n",
            "| time_elapsed       | 2.59e+03      |\n",
            "| total_timesteps    | 880640        |\n",
            "| value_loss         | 0.017985096   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.004987305  |\n",
            "| clipfrac           | 0.047851562  |\n",
            "| eplenmean          | 16.2         |\n",
            "| eprewmean          | 0.5909167    |\n",
            "| explained_variance | 0.431        |\n",
            "| fps                | 346          |\n",
            "| nupdates           | 440          |\n",
            "| policy_entropy     | 0.22142467   |\n",
            "| policy_loss        | 0.0005390127 |\n",
            "| serial_timesteps   | 901120       |\n",
            "| time_elapsed       | 2.65e+03     |\n",
            "| total_timesteps    | 901120       |\n",
            "| value_loss         | 0.013398199  |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.01340084     |\n",
            "| clipfrac           | 0.072753906    |\n",
            "| eplenmean          | 18.3           |\n",
            "| eprewmean          | 0.5491667      |\n",
            "| explained_variance | 0.389          |\n",
            "| fps                | 338            |\n",
            "| nupdates           | 450            |\n",
            "| policy_entropy     | 0.2029391      |\n",
            "| policy_loss        | -0.00041098453 |\n",
            "| serial_timesteps   | 921600         |\n",
            "| time_elapsed       | 2.71e+03       |\n",
            "| total_timesteps    | 921600         |\n",
            "| value_loss         | 0.016352538    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.012465898   |\n",
            "| clipfrac           | 0.052246094   |\n",
            "| eplenmean          | 18.3          |\n",
            "| eprewmean          | 0.52608323    |\n",
            "| explained_variance | 0.405         |\n",
            "| fps                | 345           |\n",
            "| nupdates           | 460           |\n",
            "| policy_entropy     | 0.20606555    |\n",
            "| policy_loss        | -0.0019513094 |\n",
            "| serial_timesteps   | 942080        |\n",
            "| time_elapsed       | 2.77e+03      |\n",
            "| total_timesteps    | 942080        |\n",
            "| value_loss         | 0.014843848   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.009367283  |\n",
            "| clipfrac           | 0.10595703   |\n",
            "| eplenmean          | 21.4         |\n",
            "| eprewmean          | 0.48741665   |\n",
            "| explained_variance | 0.429        |\n",
            "| fps                | 346          |\n",
            "| nupdates           | 470          |\n",
            "| policy_entropy     | 0.23717126   |\n",
            "| policy_loss        | 0.0017284114 |\n",
            "| serial_timesteps   | 962560       |\n",
            "| time_elapsed       | 2.83e+03     |\n",
            "| total_timesteps    | 962560       |\n",
            "| value_loss         | 0.015670495  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.011851533   |\n",
            "| clipfrac           | 0.1282959     |\n",
            "| eplenmean          | 19.6          |\n",
            "| eprewmean          | 0.50958335    |\n",
            "| explained_variance | 0.425         |\n",
            "| fps                | 342           |\n",
            "| nupdates           | 480           |\n",
            "| policy_entropy     | 0.32457945    |\n",
            "| policy_loss        | -0.0070044445 |\n",
            "| serial_timesteps   | 983040        |\n",
            "| time_elapsed       | 2.89e+03      |\n",
            "| total_timesteps    | 983040        |\n",
            "| value_loss         | 0.016034642   |\n",
            "--------------------------------------\n",
            "CPU times: user 53min 10s, sys: 11min 36s, total: 1h 4min 46s\n",
            "Wall time: 49min 42s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls -l $log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "4b6e47ab-55b0-4278-88f2-1e35e557cfa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "plt.ylim(0, .75)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)\n",
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fea929ae978>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhhjTCDchBljjDGB/ANyTabT9VegdgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fea93233278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "945e2cee-ca95-46d1-a3bf-c4b08f722c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 1000, 'B': 1000, 'C': 0, 'D': 0, 'E': 1000, 'F': 1000, 'G': 0, 'H': 0, 'K': 1000, 'L': 0, 'M': 1000, 'N': 0, 'O': 0}\n",
            "Episode:    0   Step:    1  S --0-> A R= 0.12 totalR= 0.12 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    2  A --2-> E R= 0.15 totalR= 0.27 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    3  E --1-> F R= 0.15 totalR= 0.42 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    4  F --1-> E R=-0.02 totalR= 0.40 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  E --0-> A R=-0.02 totalR= 0.38 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  A --1-> B R= 0.15 totalR= 0.53 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    7  B --3-> K R= 0.13 totalR= 0.67 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    8  K --0-> B R=-0.03 totalR= 0.63 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  B --2-> C R=-0.01 totalR= 0.62 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  C --2-> M R= 0.15 totalR= 0.78 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   11  M --2-> N R=-0.02 totalR= 0.76 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   12  N --1-> O R=-0.02 totalR= 0.74 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   13  O --1-> G R=-0.05 totalR= 0.69 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  G --0-> F R=-0.03 totalR= 0.66 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  F --1-> E R=-0.02 totalR= 0.64 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  E --0-> A R=-0.02 totalR= 0.62 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  A --0-> S R=-0.05 totalR= 0.57 cost= 300 customerR=   0 optimum=6000\n",
            "Episode finished after 17 timesteps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5fY1da_0l15E",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}