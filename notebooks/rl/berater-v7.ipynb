{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "berater-v7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/rl/berater-v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eU7ylMh1kQ2y"
      },
      "cell_type": "markdown",
      "source": [
        "# Berater Environment v7\n",
        "\n",
        "## Changes from v6\n",
        "1. per episode set certain rewards to 0 to simulate different customers per consultant\n",
        "  \n",
        "## next steps\n",
        "  \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpzHtN3-kQ26"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation (required for colab)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0E567zPTkQ28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/baselines >/dev/null\n",
        "!pip install gym >/dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3OdHyWEEEwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-S4sZG5ZkQ3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "def state_name_to_int(state):\n",
        "    state_name_map = {\n",
        "        'S': 0,\n",
        "        'A': 1,\n",
        "        'B': 2,\n",
        "        'C': 3,\n",
        "        'D': 4,\n",
        "        'E': 5,\n",
        "        'F': 6,\n",
        "        'G': 7,\n",
        "        'H': 8,\n",
        "        'K': 9,\n",
        "        'L': 10,\n",
        "        'M': 11,\n",
        "        'N': 12,\n",
        "        'O': 13\n",
        "    }\n",
        "    return state_name_map[state]\n",
        "\n",
        "def int_to_state_name(state_as_int):\n",
        "    state_map = {\n",
        "        0: 'S',\n",
        "        1: 'A',\n",
        "        2: 'B',\n",
        "        3: 'C',\n",
        "        4: 'D',\n",
        "        5: 'E',\n",
        "        6: 'F',\n",
        "        7: 'G',\n",
        "        8: 'H',\n",
        "        9: 'K',\n",
        "        10: 'L',\n",
        "        11: 'M',\n",
        "        12: 'N',\n",
        "        13: 'O'\n",
        "    }\n",
        "    return state_map[state_as_int]\n",
        "    \n",
        "class BeraterEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The Berater Problem\n",
        "\n",
        "    Actions: \n",
        "    There are 4 discrete deterministic actions, each choosing one direction\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['ansi']}\n",
        "    \n",
        "    showStep = False\n",
        "    showDone = True\n",
        "    envEpisodeModulo = 100\n",
        "\n",
        "    def __init__(self):\n",
        "#         self.map = {\n",
        "#             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
        "#             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
        "#             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
        "#             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
        "#         }\n",
        "        self.map = {\n",
        "            'S': [('A', 300), ('B', 100), ('C', 200 )],\n",
        "            'A': [('S', 300), ('B', 100), ('E', 100 ), ('D', 100 )],\n",
        "            'B': [('S', 100), ('A', 100), ('C', 50 ), ('K', 200 )],\n",
        "            'C': [('S', 200), ('B', 50), ('M', 100 ), ('L', 200 )],\n",
        "            'D': [('A', 100), ('F', 50)],\n",
        "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
        "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
        "            'G': [('F', 200), ('O', 300)],\n",
        "            'H': [('E', 100), ('K', 300)],\n",
        "            'K': [('B', 200), ('H', 300)],\n",
        "            'L': [('C', 200), ('M', 50)],\n",
        "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
        "            'N': [('M', 100), ('O', 100)],\n",
        "            'O': [('N', 100), ('G', 300)]\n",
        "        }\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        # position, and up to 4 paths from that position, non existing path is -1000 and no position change\n",
        "        self.observation_space = spaces.Box(low=numpy.array([0,-1000,-1000,-1000,-1000]),\n",
        "                                             high=numpy.array([13,1000,1000,1000,1000]),\n",
        "                                             dtype=numpy.float32)\n",
        "        self.reward_range = (-1, 1)\n",
        "\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.envReward = 0\n",
        "        self.envEpisodeCount = 0\n",
        "        self.envStepCount = 0\n",
        "\n",
        "        self.reset()\n",
        "        self.optimum = self.calculate_customers_reward()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def iterate_path(self, state, action):\n",
        "        paths = self.map[state]\n",
        "        if action < len(paths):\n",
        "          return paths[action]\n",
        "        else:\n",
        "          # sorry, no such action, stay where you are and pay a high penalty\n",
        "          return (state, 1000)\n",
        "      \n",
        "    def step(self, action):\n",
        "        destination, cost = self.iterate_path(self.state, action)\n",
        "        lastState = self.state\n",
        "        customerReward = self.customer_reward[destination]\n",
        "        reward = (customerReward - cost) / self.optimum\n",
        "\n",
        "        self.state = destination\n",
        "        self.customer_visited(destination)\n",
        "        done = destination == 'S' and self.all_customers_visited()\n",
        "\n",
        "        stateAsInt = state_name_to_int(self.state)\n",
        "        self.totalReward += reward\n",
        "        self.stepCount += 1\n",
        "        self.envReward += reward\n",
        "        self.envStepCount += 1\n",
        "\n",
        "        if self.showStep:\n",
        "            print( \"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) + \n",
        "                   \" Step: \" + (\"%4.0f  \" % self.stepCount) + \n",
        "                   lastState + ' --' + str(action) + '-> ' + self.state + \n",
        "                   ' R=' + (\"% 2.2f\" % reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) + \n",
        "                   ' cost=' + (\"%4.0f\" % cost) + ' customerR=' + (\"%4.0f\" % customerReward) + ' optimum=' + (\"%4.0f\" % self.optimum)      \n",
        "                   )\n",
        "\n",
        "        if done and not self.isDone:\n",
        "            self.envEpisodeCount += 1\n",
        "            if BeraterEnv.showDone:\n",
        "                episodes = BeraterEnv.envEpisodeModulo\n",
        "                if (self.envEpisodeCount % BeraterEnv.envEpisodeModulo != 0):\n",
        "                    episodes = self.envEpisodeCount % BeraterEnv.envEpisodeModulo\n",
        "                print( \"Done: \" + \n",
        "                        (\"episodes=%6.0f  \" % self.envEpisodeCount) + \n",
        "                        (\"avgSteps=%6.2f  \" % (self.envStepCount/episodes)) + \n",
        "                        (\"avgTotalReward=% 3.2f\" % (self.envReward/episodes) )\n",
        "                        )\n",
        "                if (self.envEpisodeCount%BeraterEnv.envEpisodeModulo) == 0:\n",
        "                    self.envReward = 0\n",
        "                    self.envStepCount = 0\n",
        "\n",
        "        self.isDone = done\n",
        "        observation = self.getObservation(stateAsInt)\n",
        "        info = {\"from\": self.state, \"to\": destination}\n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def getObservation(self, position):\n",
        "        result = numpy.array([ position, \n",
        "                               self.getPathObservation(position, 0),\n",
        "                               self.getPathObservation(position, 1),\n",
        "                               self.getPathObservation(position, 2),\n",
        "                               self.getPathObservation(position, 3)\n",
        "                              ],\n",
        "                             dtype=numpy.float32)\n",
        "        return result\n",
        "\n",
        "    def getPathObservation(self, position, path):\n",
        "        source = int_to_state_name(position)\n",
        "        paths = self.map[self.state]\n",
        "        if path < len(paths):\n",
        "          target, cost = paths[path]\n",
        "          reward = self.customer_reward[target] \n",
        "          result = reward - cost\n",
        "        else:\n",
        "          result = -1000\n",
        "\n",
        "        return result\n",
        "\n",
        "    def customer_visited(self, customer):\n",
        "        self.customer_reward[customer] = 0\n",
        "\n",
        "    def all_customers_visited(self):\n",
        "        return self.calculate_customers_reward() == 0\n",
        "\n",
        "    def calculate_customers_reward(self):\n",
        "        sum = 0\n",
        "        for value in self.customer_reward.values():\n",
        "            sum += value\n",
        "        return sum\n",
        "\n",
        "      \n",
        "    def modulate_reward(self):\n",
        "      number_of_customers = 13\n",
        "#       number_per_consultant = int(number_of_customers/2)\n",
        "      number_per_consultant = 10\n",
        "      self.customer_reward = {\n",
        "          'S': 0\n",
        "      }\n",
        "      for customer_nr in range(1, number_of_customers + 1):\n",
        "        self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
        "      \n",
        "      # every consultant only visits a few random customers\n",
        "      samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
        "      key_list = list(self.customer_reward.keys())\n",
        "      for sample in samples:\n",
        "        self.customer_reward[key_list[sample]] = 1000\n",
        "\n",
        "      \n",
        "    def reset(self):\n",
        "        self.totalReward = 0\n",
        "        self.stepCount = 0\n",
        "        self.isDone = False\n",
        "\n",
        "        self.modulate_reward()\n",
        "        self.state = 'S'\n",
        "        return self.getObservation(state_name_to_int(self.state))\n",
        "      \n",
        "    def render(self):\n",
        "      print(self.customer_reward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZBH30Rs95B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68f82856-7f62-4b6e-be3e-23c68e6e4a34"
      },
      "cell_type": "code",
      "source": [
        "env = BeraterEnv()\n",
        "print(env.reset())\n",
        "print(env.customer_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0.   700.   900.  -200. -1000.]\n",
            "{'S': 0, 'A': 1000, 'B': 1000, 'C': 0, 'D': 1000, 'E': 1000, 'F': 1000, 'G': 0, 'H': 0, 'K': 0, 'L': 0, 'M': 0, 'N': 0, 'O': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Usj9iWTskQ3t"
      },
      "cell_type": "markdown",
      "source": [
        "# Try out Environment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oTtUfeONkQ3w",
        "outputId": "69417fc9-6f2b-44e7-aa46-11d307efbd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1275
        }
      },
      "cell_type": "code",
      "source": [
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = True\n",
        "\n",
        "env = BeraterEnv()\n",
        "print(env)\n",
        "observation = env.reset()\n",
        "print(observation)\n",
        "\n",
        "for t in range(1000):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()\n",
        "print(observation)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BeraterEnv instance>\n",
            "[    0.   700.   900.  -200. -1000.]\n",
            "Episode:    0   Step:    1  S --0-> A R= 0.12 totalR= 0.12 cost= 300 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    2  A --3-> D R= 0.15 totalR= 0.27 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:    3  D --1-> F R=-0.01 totalR= 0.26 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    4  F --0-> D R=-0.01 totalR= 0.25 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    5  D --3-> D R=-0.17 totalR= 0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    6  D --3-> D R=-0.17 totalR=-0.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    7  D --3-> D R=-0.17 totalR=-0.25 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    8  D --3-> D R=-0.17 totalR=-0.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:    9  D --1-> F R=-0.01 totalR=-0.42 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   10  F --3-> F R=-0.17 totalR=-0.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   11  F --1-> E R= 0.15 totalR=-0.44 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   12  E --2-> H R=-0.02 totalR=-0.46 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   13  H --0-> E R=-0.02 totalR=-0.47 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   14  E --3-> E R=-0.17 totalR=-0.64 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   15  E --2-> H R=-0.02 totalR=-0.66 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   16  H --0-> E R=-0.02 totalR=-0.68 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   17  E --0-> A R=-0.02 totalR=-0.69 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   18  A --0-> S R=-0.05 totalR=-0.74 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   19  S --2-> C R=-0.03 totalR=-0.78 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   20  C --1-> B R= 0.16 totalR=-0.62 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   21  B --2-> C R=-0.01 totalR=-0.63 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   22  C --3-> L R= 0.13 totalR=-0.49 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   23  L --3-> L R=-0.17 totalR=-0.66 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   24  L --2-> L R=-0.17 totalR=-0.83 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   25  L --0-> C R=-0.03 totalR=-0.86 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   26  C --1-> B R=-0.01 totalR=-0.87 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   27  B --1-> A R=-0.02 totalR=-0.88 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   28  A --1-> B R=-0.02 totalR=-0.90 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   29  B --1-> A R=-0.02 totalR=-0.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   30  A --0-> S R=-0.05 totalR=-0.97 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   31  S --1-> B R=-0.02 totalR=-0.98 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   32  B --0-> S R=-0.02 totalR=-1.00 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   33  S --3-> S R=-0.17 totalR=-1.17 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   34  S --0-> A R=-0.05 totalR=-1.22 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   35  A --3-> D R=-0.02 totalR=-1.23 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   36  D --1-> F R=-0.01 totalR=-1.24 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   37  F --2-> G R= 0.13 totalR=-1.11 cost= 200 customerR=1000 optimum=6000\n",
            "Episode:    0   Step:   38  G --3-> G R=-0.17 totalR=-1.28 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   39  G --3-> G R=-0.17 totalR=-1.44 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   40  G --0-> F R=-0.03 totalR=-1.48 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   41  F --2-> G R=-0.03 totalR=-1.51 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   42  G --3-> G R=-0.17 totalR=-1.68 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   43  G --0-> F R=-0.03 totalR=-1.71 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   44  F --1-> E R=-0.02 totalR=-1.73 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   45  E --3-> E R=-0.17 totalR=-1.89 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   46  E --1-> F R=-0.02 totalR=-1.91 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   47  F --3-> F R=-0.17 totalR=-2.08 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   48  F --3-> F R=-0.17 totalR=-2.24 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   49  F --2-> G R=-0.03 totalR=-2.28 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   50  G --3-> G R=-0.17 totalR=-2.44 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   51  G --0-> F R=-0.03 totalR=-2.48 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   52  F --1-> E R=-0.02 totalR=-2.49 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   53  E --1-> F R=-0.02 totalR=-2.51 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   54  F --1-> E R=-0.02 totalR=-2.52 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   55  E --3-> E R=-0.17 totalR=-2.69 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   56  E --0-> A R=-0.02 totalR=-2.71 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   57  A --3-> D R=-0.02 totalR=-2.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   58  D --2-> D R=-0.17 totalR=-2.89 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   59  D --0-> A R=-0.02 totalR=-2.91 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   60  A --3-> D R=-0.02 totalR=-2.92 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   61  D --3-> D R=-0.17 totalR=-3.09 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   62  D --2-> D R=-0.17 totalR=-3.26 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   63  D --3-> D R=-0.17 totalR=-3.42 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   64  D --2-> D R=-0.17 totalR=-3.59 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   65  D --3-> D R=-0.17 totalR=-3.76 cost=1000 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   66  D --0-> A R=-0.02 totalR=-3.77 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   67  A --2-> E R=-0.02 totalR=-3.79 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   68  E --0-> A R=-0.02 totalR=-3.81 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    0   Step:   69  A --0-> S R=-0.05 totalR=-3.86 cost= 300 customerR=   0 optimum=6000\n",
            "Done: episodes=     1  avgSteps= 69.00  avgTotalReward=-3.86\n",
            "Episode finished after 69 timesteps\n",
            "[    0.  -300.  -100.  -200. -1000.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4GlYjZ3xkQ38"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "\n",
        "* random has lower total reward than version with dense customers \n",
        "* total cost when travelling all paths (back and forth): 2500\n",
        "* additional pernalty for liiegal moves 1000\n",
        "* all rewards: 6000\n",
        "* perfect score???\n",
        "* estimate: half the travel cost and no illegal moves: (6000 - 1250) / 6000 = .79\n"
      ]
    },
    {
      "metadata": {
        "id": "Qvi-T-YuEO0A",
        "colab_type": "code",
        "outputId": "215c5f20-bc98-456e-cdec-f3ba07292ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-rAaTCL0r-ql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r logs\n",
        "!mkdir logs\n",
        "!mkdir logs/berater"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NzbylmYAkQ3-",
        "outputId": "6d094d12-c9a7-4d2a-d3c6-1cf97f2abbb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2584
        }
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_pong.py\n",
        "# log_dir = logger.get_dir()\n",
        "log_dir = '/content/logs/berater/'\n",
        "\n",
        "import gym\n",
        "from baselines import bench\n",
        "from baselines import logger\n",
        "\n",
        "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from baselines.common.vec_env.vec_monitor import VecMonitor\n",
        "from baselines.ppo2 import ppo2\n",
        "\n",
        "BeraterEnv.showStep = False\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "env = BeraterEnv()\n",
        "\n",
        "wrapped_env = DummyVecEnv([lambda: BeraterEnv()])\n",
        "monitored_env = VecMonitor(wrapped_env, log_dir)\n",
        "\n",
        "# https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py\n",
        "model = ppo2.learn(\n",
        "    env=monitored_env,\\\n",
        "    network='mlp',\\\n",
        "    num_hidden=1000,\\\n",
        "    num_layers=3,\\\n",
        "    ent_coef=0.01,\\\n",
        "    total_timesteps=200000)\n",
        "\n",
        "# monitored_env = bench.Monitor(env, log_dir)\n",
        "# https://en.wikipedia.org/wiki/Q-learning#Influence_of_variables\n",
        "# %time model = deepq.learn(\\\n",
        "#         monitored_env,\\\n",
        "#         seed=42,\\\n",
        "#         network='mlp',\\\n",
        "#         lr=1e-3,\\\n",
        "#         gamma=0.99,\\\n",
        "#         total_timesteps=30000,\\\n",
        "#         buffer_size=50000,\\\n",
        "#         exploration_fraction=0.5,\\\n",
        "#         exploration_final_eps=0.02,\\\n",
        "#         print_freq=1000)\n",
        "\n",
        "model.save('berater-ppo-v6.pkl')\n",
        "monitored_env.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/openai-2019-01-03-13-37-27-584300\n",
            "-------------------------------------\n",
            "| approxkl           | 0.016597858  |\n",
            "| clipfrac           | 0.32202148   |\n",
            "| eplenmean          | 116          |\n",
            "| eprewmean          | -7.3377476   |\n",
            "| explained_variance | -0.269       |\n",
            "| fps                | 474          |\n",
            "| nupdates           | 1            |\n",
            "| policy_entropy     | 1.3701648    |\n",
            "| policy_loss        | -0.037757773 |\n",
            "| serial_timesteps   | 2048         |\n",
            "| time_elapsed       | 4.32         |\n",
            "| total_timesteps    | 2048         |\n",
            "| value_loss         | 0.9664724    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.008461479   |\n",
            "| clipfrac           | 0.11669922    |\n",
            "| eplenmean          | 47.9          |\n",
            "| eprewmean          | -0.28241673   |\n",
            "| explained_variance | 0.103         |\n",
            "| fps                | 507           |\n",
            "| nupdates           | 10            |\n",
            "| policy_entropy     | 1.0072985     |\n",
            "| policy_loss        | -0.0053616734 |\n",
            "| serial_timesteps   | 20480         |\n",
            "| time_elapsed       | 42.3          |\n",
            "| total_timesteps    | 20480         |\n",
            "| value_loss         | 0.092960596   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.009541718   |\n",
            "| clipfrac           | 0.14978027    |\n",
            "| eplenmean          | 40.8          |\n",
            "| eprewmean          | 0.13441667    |\n",
            "| explained_variance | 0.167         |\n",
            "| fps                | 496           |\n",
            "| nupdates           | 20            |\n",
            "| policy_entropy     | 0.8695689     |\n",
            "| policy_loss        | -0.0029162194 |\n",
            "| serial_timesteps   | 40960         |\n",
            "| time_elapsed       | 83.5          |\n",
            "| total_timesteps    | 40960         |\n",
            "| value_loss         | 0.024155777   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.012663635  |\n",
            "| clipfrac           | 0.16906738   |\n",
            "| eplenmean          | 42.1         |\n",
            "| eprewmean          | 0.16658328   |\n",
            "| explained_variance | 0.0648       |\n",
            "| fps                | 460          |\n",
            "| nupdates           | 30           |\n",
            "| policy_entropy     | 0.77677065   |\n",
            "| policy_loss        | -0.003887886 |\n",
            "| serial_timesteps   | 61440        |\n",
            "| time_elapsed       | 126          |\n",
            "| total_timesteps    | 61440        |\n",
            "| value_loss         | 0.013983499  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0071777445 |\n",
            "| clipfrac           | 0.10461426   |\n",
            "| eplenmean          | 32.3         |\n",
            "| eprewmean          | 0.3415       |\n",
            "| explained_variance | 0.266        |\n",
            "| fps                | 472          |\n",
            "| nupdates           | 40           |\n",
            "| policy_entropy     | 0.67053473   |\n",
            "| policy_loss        | -0.005003702 |\n",
            "| serial_timesteps   | 81920        |\n",
            "| time_elapsed       | 170          |\n",
            "| total_timesteps    | 81920        |\n",
            "| value_loss         | 0.017489007  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.009316216 |\n",
            "| clipfrac           | 0.12011719  |\n",
            "| eplenmean          | 36          |\n",
            "| eprewmean          | 0.2701667   |\n",
            "| explained_variance | 0.21        |\n",
            "| fps                | 441         |\n",
            "| nupdates           | 50          |\n",
            "| policy_entropy     | 0.5672314   |\n",
            "| policy_loss        | 0.003667352 |\n",
            "| serial_timesteps   | 102400      |\n",
            "| time_elapsed       | 214         |\n",
            "| total_timesteps    | 102400      |\n",
            "| value_loss         | 0.023067739 |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0049117426  |\n",
            "| clipfrac           | 0.060302734   |\n",
            "| eplenmean          | 36.5          |\n",
            "| eprewmean          | 0.2605001     |\n",
            "| explained_variance | 0.318         |\n",
            "| fps                | 464           |\n",
            "| nupdates           | 60            |\n",
            "| policy_entropy     | 0.5825292     |\n",
            "| policy_loss        | -0.0023121068 |\n",
            "| serial_timesteps   | 122880        |\n",
            "| time_elapsed       | 257           |\n",
            "| total_timesteps    | 122880        |\n",
            "| value_loss         | 0.020224473   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.008643235  |\n",
            "| clipfrac           | 0.091552734  |\n",
            "| eplenmean          | 30.6         |\n",
            "| eprewmean          | 0.3610001    |\n",
            "| explained_variance | 0.282        |\n",
            "| fps                | 490          |\n",
            "| nupdates           | 70           |\n",
            "| policy_entropy     | 0.49837917   |\n",
            "| policy_loss        | 0.0009864188 |\n",
            "| serial_timesteps   | 143360       |\n",
            "| time_elapsed       | 300          |\n",
            "| total_timesteps    | 143360       |\n",
            "| value_loss         | 0.02233555   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.006292577  |\n",
            "| clipfrac           | 0.07165527   |\n",
            "| eplenmean          | 33.8         |\n",
            "| eprewmean          | 0.3068334    |\n",
            "| explained_variance | 0.282        |\n",
            "| fps                | 439          |\n",
            "| nupdates           | 80           |\n",
            "| policy_entropy     | 0.49434632   |\n",
            "| policy_loss        | 0.0012119194 |\n",
            "| serial_timesteps   | 163840       |\n",
            "| time_elapsed       | 342          |\n",
            "| total_timesteps    | 163840       |\n",
            "| value_loss         | 0.016090978  |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.008336539    |\n",
            "| clipfrac           | 0.09289551     |\n",
            "| eplenmean          | 32.4           |\n",
            "| eprewmean          | 0.35275        |\n",
            "| explained_variance | 0.343          |\n",
            "| fps                | 507            |\n",
            "| nupdates           | 90             |\n",
            "| policy_entropy     | 0.51927155     |\n",
            "| policy_loss        | -0.00068328076 |\n",
            "| serial_timesteps   | 184320         |\n",
            "| time_elapsed       | 383            |\n",
            "| total_timesteps    | 184320         |\n",
            "| value_loss         | 0.017073447    |\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0cfzto7W8Mpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing Results\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "yBzvtyVcvhkn",
        "colab_type": "code",
        "outputId": "99e96643-be6d-481a-9c36-fe7eda72a3e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l $log_dir"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 140\n",
            "-rw-r--r-- 1 root root 137118 Jan  3 13:44 monitor.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ZWB88EVsRei",
        "colab_type": "code",
        "outputId": "904c2fda-41ab-4ae1-a0fc-1e68cc1da8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "from baselines.common import plot_util as pu\n",
        "results = pu.load_results(log_dir)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/baselines/bench/monitor.py:164: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  df.headers = headers # HACK to preserve backwards compatibility\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "M1G3TPcfsVzb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "r = results[0]\n",
        "# plt.ylim(-1, 1)\n",
        "# plt.plot(np.cumsum(r.monitor.l), r.monitor.r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZc2jIUr8wKQ",
        "colab_type": "code",
        "outputId": "0374067c-0348-490a-fd85-96caf788fcf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(np.cumsum(r.monitor.l), pu.smooth(r.monitor.r, radius=100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f592bbcb3c8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5998e5b828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TtBh4c6-kQ4K"
      },
      "cell_type": "markdown",
      "source": [
        "# Enjoy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ucP0gNhhkQ4O",
        "outputId": "4066d5a5-23dc-4dee-b59f-4b07b088de71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "observation = env.reset()\n",
        "env.render()\n",
        "state = np.zeros((1, 2*128))\n",
        "dones = np.zeros((1))\n",
        "\n",
        "BeraterEnv.showStep = True\n",
        "BeraterEnv.showDone = False\n",
        "\n",
        "for t in range(1000):\n",
        "    actions, _, state, _ = model.step(observation, S=state, M=dones)\n",
        "    observation, reward, done, info = env.step(actions[0])\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        break\n",
        "env.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'S': 0, 'A': 1000, 'B': 0, 'C': 0, 'D': 0, 'E': 1000, 'F': 1000, 'G': 0, 'H': 1000, 'K': 0, 'L': 1000, 'M': 1000, 'N': 0, 'O': 0}\n",
            "Episode:    1   Step:    1  S --1-> B R=-0.02 totalR=-0.02 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:    2  B --1-> A R= 0.15 totalR= 0.13 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    1   Step:    3  A --2-> E R= 0.15 totalR= 0.28 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    1   Step:    4  E --2-> H R= 0.15 totalR= 0.43 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    1   Step:    5  H --0-> E R=-0.02 totalR= 0.42 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:    6  E --1-> F R= 0.15 totalR= 0.57 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    1   Step:    7  F --0-> D R=-0.01 totalR= 0.56 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:    8  D --0-> A R=-0.02 totalR= 0.54 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:    9  A --0-> S R=-0.05 totalR= 0.49 cost= 300 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:   10  S --2-> C R=-0.03 totalR= 0.46 cost= 200 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:   11  C --2-> M R= 0.15 totalR= 0.61 cost= 100 customerR=1000 optimum=6000\n",
            "Episode:    1   Step:   12  M --1-> L R= 0.16 totalR= 0.77 cost=  50 customerR=1000 optimum=6000\n",
            "Episode:    1   Step:   13  L --1-> M R=-0.01 totalR= 0.76 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:   14  M --0-> C R=-0.02 totalR= 0.74 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:   15  C --1-> B R=-0.01 totalR= 0.73 cost=  50 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:   16  B --1-> A R=-0.02 totalR= 0.72 cost= 100 customerR=   0 optimum=6000\n",
            "Episode:    1   Step:   17  A --0-> S R=-0.05 totalR= 0.67 cost= 300 customerR=   0 optimum=6000\n",
            "Episode finished after 17 timesteps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5fY1da_0l15E",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}