{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tf2/embeddings-retrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0SNZ3gZDa36",
        "colab_type": "text"
      },
      "source": [
        "# Airline Embeddings\n",
        "\n",
        "_Basic assumption: airlines fliying similar routes are similar_\n",
        "\n",
        "## Data Sets\n",
        "* Single Flights: http://stat-computing.org/dataexpo/2009/the-data.html\n",
        "* Routes between airports: https://openflights.org/data.html#route\n",
        "\n",
        "## Advanced examples\n",
        "* autoencoders on tabular data: https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/2019_tf/autoencoders_tabular.ipynb\n",
        "* robust training on additional data: https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/2019_tf/autoencoders_stabilize.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv2d1kl3HOBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3864dd6b-d314-4041-8225-96fe3dca770e"
      },
      "source": [
        "!pip install -q tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 346.6MB 41kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 26.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 430kB 40.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 21.2MB/s \n",
            "\u001b[?25h  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur7tExIkHOlQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ac03643-99dd-466e-8ec8-2be6ad613380"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74_7Xj83pNyk",
        "colab_type": "code",
        "outputId": "6d785723-a045-48b8-fc19-48a36223a9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 2321k    0  1917    0     0   3004      0  0:13:11 --:--:--  0:13:11  3000\r100 2321k  100 2321k    0     0  3193k      0 --:--:-- --:--:-- --:--:-- 3193k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CUgJvsutUuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd.read_csv?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q64fxjyqmyU",
        "colab_type": "code",
        "outputId": "1c5d123d-76ab-4930-bb71-aeb31c49fe59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('routes.dat', quotechar=\"'\", sep=',', encoding='utf-8', header=None, na_values='\\\\N',\n",
        "                names=['Airline', 'Airline ID', 'Source airport', 'Source airport ID', 'Destination airport', 'Destination airport ID', 'Codeshare', 'Stops', 'Equipment'])\n",
        "\n",
        "# https://openflights.org/data.html#route\n",
        "  \n",
        "# Airline\t2-letter (IATA) or 3-letter (ICAO) code of the airline.\n",
        "# Airline ID\tUnique OpenFlights identifier for airline (see Airline).\n",
        "# Source airport\t3-letter (IATA) or 4-letter (ICAO) code of the source airport.\n",
        "# Source airport ID\tUnique OpenFlights identifier for source airport (see Airport)\n",
        "# Destination airport\t3-letter (IATA) or 4-letter (ICAO) code of the destination airport.\n",
        "# Destination airport ID\tUnique OpenFlights identifier for destination airport (see Airport)\n",
        "# Codeshare\t\"Y\" if this flight is a codeshare (that is, not operated by Airline, but another carrier), empty otherwise.\n",
        "# Stops\tNumber of stops on this flight (\"0\" for direct)\n",
        "# Equipment\t3-letter codes for plane type(s) generally used on this flight, separated by spaces\n",
        "\n",
        "# df[df['Stops'] == 1] gives only a dozen or so routes, so also drop it\n",
        "df.drop(['Airline ID',\t'Source airport ID', 'Destination airport ID', 'Codeshare', 'Equipment', 'Stops'], axis='columns', inplace=True)\n",
        "len(df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpZAQeL8rJUH",
        "colab_type": "code",
        "outputId": "fbcd209e-7606-4cc9-c7ea-339a96aaa703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Airline</th>\n",
              "      <th>Source airport</th>\n",
              "      <th>Destination airport</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2B</td>\n",
              "      <td>AER</td>\n",
              "      <td>KZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2B</td>\n",
              "      <td>ASF</td>\n",
              "      <td>KZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2B</td>\n",
              "      <td>ASF</td>\n",
              "      <td>MRV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2B</td>\n",
              "      <td>CEK</td>\n",
              "      <td>KZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2B</td>\n",
              "      <td>CEK</td>\n",
              "      <td>OVB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Airline Source airport Destination airport\n",
              "0      2B            AER                 KZN\n",
              "1      2B            ASF                 KZN\n",
              "2      2B            ASF                 MRV\n",
              "3      2B            CEK                 KZN\n",
              "4      2B            CEK                 OVB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EehcSpqtvYwu",
        "colab_type": "code",
        "outputId": "1c78782a-afd5-45db-ae14-becf30816baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sources = df['Source airport'].unique()\n",
        "len(sources)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub5pJVxhvmJ7",
        "colab_type": "code",
        "outputId": "36b4f585-5f69-4512-b39e-8cef35b60ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "destinations = df['Destination airport'].unique()\n",
        "len(destinations)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3418"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1dOL_9-v0oT",
        "colab_type": "code",
        "outputId": "c1303b25-769e-44e4-cf3d-6f1ea3e2f75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "airlines = df['Airline'].unique()\n",
        "len(airlines)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "568"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4YhKffPzMAc",
        "colab_type": "code",
        "outputId": "d3c260d2-b3ac-4185-ed99-a5d5e8048f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "airline_tokenizer = Tokenizer()\n",
        "airline_tokenizer.fit_on_texts(df['Airline'])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "encoded_airlines = np.array(airline_tokenizer.texts_to_sequences(df['Airline'])).reshape(-1)\n",
        "encoded_airlines"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([241, 241, 241, ..., 543, 543, 543])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IBnf4t5zW-q",
        "colab_type": "code",
        "outputId": "9983e48a-368e-4371-8ac2-7cb5cea8b97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(encoded_airlines) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7n-Vq0m2Hu4",
        "colab_type": "code",
        "outputId": "597ede16-7564-4bbc-83b3-5e6a6c705a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "routes = df[['Source airport', 'Destination airport']].apply(lambda x: ' '.join(x), axis=1)\n",
        "routes.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    AER KZN\n",
              "1    ASF KZN\n",
              "2    ASF MRV\n",
              "3    CEK KZN\n",
              "4    CEK OVB\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYV0rPJC0c4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "routes_tokenizer = Tokenizer()\n",
        "routes_tokenizer.fit_on_texts(routes)\n",
        "encoded_routes = np.array(routes_tokenizer.texts_to_sequences(routes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDFKV1Cz8WvF",
        "colab_type": "code",
        "outputId": "0cf96471-1943-4913-ade1-96cd5c11767f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# should be a bit more 3400 as source and destination are from the same set\n",
        "output_dim = len(routes_tokenizer.word_index) + 1\n",
        "output_dim"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3426"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5jz1ykV8Oen",
        "colab_type": "code",
        "outputId": "92324dde-2752-4d18-867b-f1e3bf8ae0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoded_routes[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([511, 491])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKB85wjg7y3Z",
        "colab_type": "code",
        "outputId": "cd84b405-e2bb-45ce-b1dd-503ab6e47c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(encoded_routes)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSm686Cv77Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# sequence of airlines encoded as a unique number\n",
        "x = encoded_airlines\n",
        "# sequence of pair, src, dest encoded as a unique numbers\n",
        "Y = to_categorical(encoded_routes)\n",
        "# for now just the source\n",
        "# Y = to_categorical(encoded_routes[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSi258PHZAf9",
        "colab_type": "code",
        "outputId": "841789b2-ec62-4a88-9c7c-0a5de74df8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Y[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzKAyEvmraN-",
        "colab_type": "text"
      },
      "source": [
        "## 2d embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brvMGP0koGBu",
        "colab_type": "code",
        "outputId": "57a1d1c8-36da-4cab-ea70-5b1c6da97906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Flatten, GlobalAveragePooling1D, Dense, LSTM, GRU, SimpleRNN, Bidirectional, Embedding, RepeatVector\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "seed = 3\n",
        "\n",
        "input_dim = len(airlines) + 1\n",
        "embedding_dim = 2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(name='embedding',\n",
        "                    input_dim=input_dim, \n",
        "                    output_dim=embedding_dim, \n",
        "                    input_length=1,\n",
        "                    embeddings_initializer=glorot_normal(seed=seed)))\n",
        "\n",
        "# https://stackoverflow.com/questions/49295311/what-is-the-difference-between-flatten-and-globalaveragepooling2d-in-keras\n",
        "# averages over all (global) embedding values \n",
        "# model.add(GlobalAveragePooling1D())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=50, activation='relu', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed)))\n",
        "\n",
        "model.add(RepeatVector(2))\n",
        "\n",
        "model.add(SimpleRNN(units=50, return_sequences=True, bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed)))\n",
        "\n",
        "model.add(Dense(units=output_dim, name='output', activation='softmax', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed)))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1, 2)              1138      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                150       \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 2, 50)             0         \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 2, 50)             5050      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2, 3426)           174726    \n",
            "=================================================================\n",
            "Total params: 181,064\n",
            "Trainable params: 181,064\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 633 ms, sys: 237 ms, total: 870 ms\n",
            "Wall time: 933 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twAODgEoDjpN",
        "colab_type": "code",
        "outputId": "d42b89b8-5492-402f-b550-81956a4d8f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict(np.array([x[0]])).shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 3426)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti2efJAYXkqs",
        "colab_type": "code",
        "outputId": "01f75ff3-3348-4426-cb94-91032ad43c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Y[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VE_4hb9DYrR",
        "colab_type": "code",
        "outputId": "26141885-0989-4083-ff1e-c931ade9f2ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "EPOCHS=25\n",
        "BATCH_SIZE=10\n",
        "\n",
        "history = model.fit(x, Y, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "67663/67663 [==============================] - 80s 1ms/sample - loss: 6.1892 - accuracy: 0.0341\n",
            "Epoch 2/25\n",
            "67663/67663 [==============================] - 80s 1ms/sample - loss: 5.2574 - accuracy: 0.0845\n",
            "Epoch 3/25\n",
            "20520/67663 [========>.....................] - ETA: 55s - loss: 4.9859 - accuracy: 0.1070"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9ItdCvWISKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(x, Y, batch_size=BATCH_SIZE)\n",
        "loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61TP5fb03Oeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.yscale('log')\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFV8mg583Rtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.yscale('log')\n",
        "plt.plot(history.history['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DyEK_CODsZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = pd.DataFrame(encoded_airlines).sample(n=200).values.reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvNZOg1itp_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://en.wikipedia.org/wiki/List_of_airline_codes\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_North_America\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_Europe\n",
        "\n",
        "europe_airlines = ['LH', 'BA', 'SK', 'KL', 'AF', 'FR', 'SU', 'EW', 'TP', 'BT', 'U2']\n",
        "us_airlines = ['AA', 'US', 'UA', 'WN', 'DL', 'AS', 'HA']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXnMYvAg5m3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = [airline_tokenizer.word_index[airline_code.lower()] for airline_code in europe_airlines + us_airlines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBuKaNNxExs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = model.get_layer('embedding')\n",
        "embedding_model = Model(inputs=model.input, outputs=embedding_layer.output)\n",
        "embeddings_2d = embedding_model.predict(samples).reshape(-1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gC6uRgMDXTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
        "for index, x_pos, y_pos in zip(samples, embeddings_2d[:, 0], embeddings_2d[:, 1]):\n",
        "  name = airline_tokenizer.index_word[index].upper()\n",
        "#   print(name, (x_pos, y_pos))\n",
        "  plt.annotate(name, (x_pos, y_pos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTOc5V0UDDca",
        "colab_type": "text"
      },
      "source": [
        "## 1d embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZdK4FMtEsAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Flatten, GlobalAveragePooling1D, Dense, LSTM, GRU, SimpleRNN, Bidirectional, Embedding, RepeatVector\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "seed = 7\n",
        "\n",
        "input_dim = len(airlines) + 1\n",
        "embedding_dim = 1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(name='embedding',\n",
        "                    input_dim=input_dim, \n",
        "                    output_dim=embedding_dim, \n",
        "                    input_length=1,\n",
        "                   embeddings_initializer=glorot_normal(seed=seed)))\n",
        "\n",
        "# model.add(GlobalAveragePooling1D())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=50, activation='relu', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed)))\n",
        "\n",
        "model.add(RepeatVector(2))\n",
        "\n",
        "model.add(SimpleRNN(units=50, return_sequences=True, bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed)))\n",
        "\n",
        "model.add(Dense(units=output_dim, name='output', activation='softmax', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed)))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y0ScvHBEbzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "EPOCHS=20\n",
        "BATCH_SIZE=10\n",
        "\n",
        "history = model.fit(x, Y, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fv_XbOyFGxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we expect this to be substantially worse than the 2d version as the bottle neck now is much more narrow\n",
        "loss, accuracy = model.evaluate(x, Y, batch_size=BATCH_SIZE)\n",
        "loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0go51sW9nSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.yscale('log')\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8a3Blxc9oAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.yscale('log')\n",
        "plt.plot(history.history['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaM-ovJLisy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "embedding_layer = model.get_layer('embedding')\n",
        "embedding_model = Model(inputs=model.input, outputs=embedding_layer.output)\n",
        "embeddings_1d = embedding_model.predict(samples).reshape(-1)\n",
        "\n",
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, np.zeros(len(embeddings_1d)))\n",
        "for index, x_pos in zip(samples, embeddings_1d):\n",
        "  name = airline_tokenizer.index_word[index].upper()\n",
        "#   print(name, (x_pos, y_pos))\n",
        "  plt.annotate(name, (x_pos, 0), rotation=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OigqkWUN6t3",
        "colab_type": "text"
      },
      "source": [
        "## Clustering in 2d\n",
        "\n",
        "1d embedding vs size of airline\n",
        "* find what is similar\n",
        "* what is an outlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyyRsXWdN6YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://en.wikipedia.org/wiki/List_of_airline_codes\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_North_America\n",
        "# https://www.tvlon.com/resources/airlinecodes.htm\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_Europe\n",
        "\n",
        "airline_size = {\n",
        "    'LH': 130, 'BA': 105, 'SK': 30, 'KL': 101, 'AF': 101, 'FR': 129, 'SU': 56, 'EW': 24, 'TP': 16, 'BT': 4, 'U2': 88, 'AA': 204, 'US': 204, 'UA': 158, 'WN': 164, 'DL': 192, 'AS': 46, 'HA': 12\n",
        "}\n",
        "sample_names = [airline_tokenizer.index_word[sample].upper() for sample in samples]\n",
        "sample_sizes = [airline_size[name] * 1e6 for name in sample_names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CksSH1wHLzSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "# plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, sample_sizes)\n",
        "for name, x_pos, y_pos in zip(sample_names, embeddings_1d, sample_sizes):\n",
        "  plt.annotate(name, (x_pos,  y_pos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZMqtkZze5fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "embeddings_1d_scaled = StandardScaler().fit_transform(embeddings_1d.reshape(-1, 1))\n",
        "sizes_for_samples_scaled = StandardScaler().fit_transform(np.array(sample_sizes).reshape(-1, 1))\n",
        "X = np.dstack((embeddings_1d_scaled.reshape(-1), sizes_for_samples_scaled.reshape(-1)))[0]\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "X_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74T57XPbwZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "clf = DBSCAN(eps=0.75, min_samples=2)\n",
        "clf.fit(X_scaled)\n",
        "clusters = clf.labels_.astype(np.int)\n",
        "clusters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaRY5XAygF7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import cycle, islice\n",
        "\n",
        "# last color is black to properly display label -1 as noise (black)\n",
        "colors = np.append(np.array(list(islice(cycle(['#AAAAFF', '#ff7f00', '#4daf4a',\n",
        "                                 '#f781bf', '#a65628', '#984ea3',\n",
        "                                 '#999999', '#e41a1c', '#dede00']),\n",
        "                          int(max(clusters) + 1)))), ['#000000'])\n",
        "\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.xlabel('Similarity by typical routes')\n",
        "plt.ylabel('Passengers')\n",
        "\n",
        "plt.scatter(embeddings_1d, sample_sizes, color=colors[clusters], s=200)\n",
        "for name, x_pos, y_pos in zip(sample_names, embeddings_1d, sample_sizes):\n",
        "  plt.annotate(name, (x_pos,  y_pos), fontsize=18, color='grey')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oqyHIYsHIT1",
        "colab_type": "text"
      },
      "source": [
        "## Making results more stable\n",
        "\n",
        "* when you visualize latent spaces they should not change much when re-training or fitting additional data points\n",
        "* when working with autoencoders or embeddings there are two ways to make that happen\n",
        "  1. save model, do not retrain from scratch and only fit new data points with low learning rate\n",
        "  1. save output from embedding and keep new latent space similar by adding to the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5aM3L7Vte_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save complete model\n",
        "model.save('airline-embedding-v1.h5')\n",
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCWb4v05HXCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}