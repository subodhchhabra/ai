{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embeddings-retrain.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tf2/embeddings-retrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0SNZ3gZDa36",
        "colab_type": "text"
      },
      "source": [
        "# Robst Retraining of Airline Embeddings\n",
        "\n",
        "_Keeping existing embeddings as stable as possible when chaning the model or adding new data_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv2d1kl3HOBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur7tExIkHOlQ",
        "colab_type": "code",
        "outputId": "34b282ba-3aa9-4386-b3c6-a54a81fd4c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq6gP6ZWKugz",
        "colab_type": "text"
      },
      "source": [
        "## Step I: Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74_7Xj83pNyk",
        "colab_type": "code",
        "outputId": "9a38df72-9d0e-4386-ae02-f0ca2f3a2edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2321k  100 2321k    0     0  3237k      0 --:--:-- --:--:-- --:--:-- 3237k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q64fxjyqmyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('routes.dat', quotechar=\"'\", sep=',', encoding='utf-8', header=None, na_values='\\\\N',\n",
        "                names=['Airline', 'Airline ID', 'Source airport', 'Source airport ID', 'Destination airport', 'Destination airport ID', 'Codeshare', 'Stops', 'Equipment'])\n",
        "\n",
        "# https://openflights.org/data.html#route\n",
        "  \n",
        "# Airline\t2-letter (IATA) or 3-letter (ICAO) code of the airline.\n",
        "# Airline ID\tUnique OpenFlights identifier for airline (see Airline).\n",
        "# Source airport\t3-letter (IATA) or 4-letter (ICAO) code of the source airport.\n",
        "# Source airport ID\tUnique OpenFlights identifier for source airport (see Airport)\n",
        "# Destination airport\t3-letter (IATA) or 4-letter (ICAO) code of the destination airport.\n",
        "# Destination airport ID\tUnique OpenFlights identifier for destination airport (see Airport)\n",
        "# Codeshare\t\"Y\" if this flight is a codeshare (that is, not operated by Airline, but another carrier), empty otherwise.\n",
        "# Stops\tNumber of stops on this flight (\"0\" for direct)\n",
        "# Equipment\t3-letter codes for plane type(s) generally used on this flight, separated by spaces\n",
        "\n",
        "# df[df['Stops'] == 1] gives only a dozen or so routes, so also drop it\n",
        "df.drop(['Airline ID',\t'Source airport ID', 'Destination airport ID', 'Codeshare', 'Equipment', 'Stops'], axis='columns', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4YhKffPzMAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "airline_tokenizer = Tokenizer()\n",
        "airline_tokenizer.fit_on_texts(df['Airline'])\n",
        "\n",
        "encoded_airlines = np.array(airline_tokenizer.texts_to_sequences(df['Airline'])).reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7n-Vq0m2Hu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "routes = df[['Source airport', 'Destination airport']].apply(lambda x: ' '.join(x), axis=1)\n",
        "\n",
        "routes_tokenizer = Tokenizer()\n",
        "routes_tokenizer.fit_on_texts(routes)\n",
        "encoded_routes = np.array(routes_tokenizer.texts_to_sequences(routes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSm686Cv77Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# sequence of airlines encoded as a unique number\n",
        "X = encoded_airlines\n",
        "# sequence of pair, src, dest encoded as a unique numbers\n",
        "Y = to_categorical(encoded_routes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfrT2dBALBR5",
        "colab_type": "text"
      },
      "source": [
        "## Step II: Using Original 1-d Model to re-create existing embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_0WdDJFLYvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f1f9ec1b-3a0a-41f2-ada4-cc6300edeb96"
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/DJCordhose/ai/master/models/airline-embedding-v1.h5"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 2155k    0  1916    0     0   3756      0  0:09:47 --:--:--  0:09:47  3749\r100 2155k  100 2155k    0     0  3522k      0 --:--:-- --:--:-- --:--:-- 3516k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWLfVeWnLH4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a7d3bc91-7900-4f1a-c3a0-cb1b4a6fe979"
      },
      "source": [
        "# https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('airline-embedding-v1.h5')\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1, 1)              569       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 2, 50)             0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 2, 50)             5050      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2, 3426)           174726    \n",
            "=================================================================\n",
            "Total params: 180,445\n",
            "Trainable params: 180,445\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSsJVEC_MpaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://en.wikipedia.org/wiki/List_of_airline_codes\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_North_America\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_Europe\n",
        "\n",
        "europe_airlines = ['LH', 'BA', 'SK', 'KL', 'AF', 'FR', 'SU', 'EW', 'TP', 'BT', 'U2']\n",
        "us_airlines = ['AA', 'US', 'UA', 'WN', 'DL', 'AS', 'HA']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_iw4PbXMqVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = [airline_tokenizer.word_index[airline_code.lower()] for airline_code in europe_airlines + us_airlines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlK0ecwwMPzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = model.get_layer('embedding')\n",
        "embedding_model = Model(inputs=model.input, outputs=embedding_layer.output)\n",
        "embeddings_1d = embedding_model.predict(samples).reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ysIfwjhdqYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_embeddings = embedding_model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sL6-oHHM52R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "b9840bb8-50ef-4d0c-e8ce-77c19620be5e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, np.zeros(len(embeddings_1d)))\n",
        "for index, x_pos in zip(samples, embeddings_1d):\n",
        "  name = airline_tokenizer.index_word[index].upper()\n",
        "  plt.annotate(name, (x_pos, 0), rotation=80)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD7CAYAAACfQGjDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkAAABBESAIAgQgIAEPT/8V4jQ5xIzYcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvWtuoAfKy6K",
        "colab_type": "text"
      },
      "source": [
        "## Step III: Convert original embedding model to functional API (as sequential will no longer be enough later)\n",
        "\n",
        "https://keras.io/getting-started/functional-api-guide/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZdK4FMtEsAS",
        "colab_type": "code",
        "outputId": "9d70db45-2907-422b-bb4c-ac01a1f3dd11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, LSTM, GRU, SimpleRNN, Embedding, RepeatVector\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "seed = 7\n",
        "\n",
        "airlines = df['Airline'].unique()\n",
        "output_dim = len(routes_tokenizer.word_index) + 1\n",
        "\n",
        "input_dim = len(airlines) + 1\n",
        "embedding_dim = 1\n",
        "\n",
        "main_input = Input(shape=(1,), dtype='int32', name='main_input')\n",
        "\n",
        "x = Embedding(name='embedding',\n",
        "                    input_dim=input_dim, \n",
        "                    output_dim=embedding_dim, \n",
        "                    input_length=1,\n",
        "                    embeddings_initializer=glorot_normal(seed=seed))(main_input)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(units=50, activation='relu', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "x = RepeatVector(2)(x)\n",
        "\n",
        "x = SimpleRNN(units=50, return_sequences=True, bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "main_output = Dense(units=output_dim, name='output', activation='softmax', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "model = Model(inputs=main_input, outputs=main_output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "main_input (InputLayer)      [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1, 1)              569       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "repeat_vector_4 (RepeatVecto (None, 2, 50)             0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_4 (SimpleRNN)     (None, 2, 50)             5050      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2, 3426)           174726    \n",
            "=================================================================\n",
            "Total params: 180,445\n",
            "Trainable params: 180,445\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 241 ms, sys: 2.04 ms, total: 243 ms\n",
            "Wall time: 240 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y0ScvHBEbzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "7c970064-8ba8-426c-80b5-123cc11c182e"
      },
      "source": [
        "%%time\n",
        "\n",
        "EPOCHS=20\n",
        "BATCH_SIZE=10\n",
        "\n",
        "history = model.fit(X, Y, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "67663/67663 [==============================] - 75s 1ms/sample - loss: 6.3985 - accuracy: 0.0224\n",
            "Epoch 2/20\n",
            "67663/67663 [==============================] - 75s 1ms/sample - loss: 5.7587 - accuracy: 0.0396\n",
            "Epoch 3/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 5.4980 - accuracy: 0.0529\n",
            "Epoch 4/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 5.3415 - accuracy: 0.0601\n",
            "Epoch 5/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 5.2412 - accuracy: 0.0655\n",
            "Epoch 6/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 5.1743 - accuracy: 0.0686\n",
            "Epoch 7/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 5.1220 - accuracy: 0.0708\n",
            "Epoch 8/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 5.0822 - accuracy: 0.0727\n",
            "Epoch 9/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 5.0462 - accuracy: 0.0741\n",
            "Epoch 10/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 5.0161 - accuracy: 0.0767\n",
            "Epoch 11/20\n",
            "67663/67663 [==============================] - 73s 1ms/sample - loss: 4.9933 - accuracy: 0.0786\n",
            "Epoch 12/20\n",
            "67663/67663 [==============================] - 73s 1ms/sample - loss: 4.9769 - accuracy: 0.0797\n",
            "Epoch 13/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 4.9564 - accuracy: 0.0810\n",
            "Epoch 14/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 4.9379 - accuracy: 0.0824\n",
            "Epoch 15/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 4.9232 - accuracy: 0.0823\n",
            "Epoch 16/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 4.9089 - accuracy: 0.0839\n",
            "Epoch 17/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 4.8973 - accuracy: 0.0843\n",
            "Epoch 18/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 4.8899 - accuracy: 0.0843\n",
            "Epoch 19/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 4.8770 - accuracy: 0.0857\n",
            "Epoch 20/20\n",
            "67663/67663 [==============================] - 74s 1ms/sample - loss: 4.8671 - accuracy: 0.0856\n",
            "CPU times: user 31min 47s, sys: 3min 35s, total: 35min 22s\n",
            "Wall time: 24min 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fv_XbOyFGxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we expect this to be substantially worse than the 2d version as the bottle neck now is much more narrow\n",
        "loss, accuracy = model.evaluate(X, Y, batch_size=BATCH_SIZE)\n",
        "loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0go51sW9nSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.yscale('log')\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8a3Blxc9oAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.yscale('log')\n",
        "plt.plot(history.history['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaM-ovJLisy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "embedding_layer = model.get_layer('embedding')\n",
        "embedding_model = Model(inputs=model.input, outputs=embedding_layer.output)\n",
        "embeddings_1d = embedding_model.predict(samples).reshape(-1)\n",
        "\n",
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, np.zeros(len(embeddings_1d)))\n",
        "for index, x_pos in zip(samples, embeddings_1d):\n",
        "  name = airline_tokenizer.index_word[index].upper()\n",
        "  plt.annotate(name, (x_pos, 0), rotation=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqP3yh92Rv1b",
        "colab_type": "text"
      },
      "source": [
        "## Step IV: Handle Model Change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frtS1zrbacNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "25302c94-194f-4cf7-c121-63b707fee1d0"
      },
      "source": [
        "%%time\n",
        "\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, LSTM, GRU, SimpleRNN, Embedding, RepeatVector\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "seed = 7\n",
        "\n",
        "airlines = df['Airline'].unique()\n",
        "output_dim = len(routes_tokenizer.word_index) + 1\n",
        "\n",
        "input_dim = len(airlines) + 1\n",
        "embedding_dim = 1\n",
        "\n",
        "main_input = Input(shape=(1,), dtype='int32', name='main_input')\n",
        "\n",
        "x = Embedding(name='embedding',\n",
        "                    input_dim=input_dim, \n",
        "                    output_dim=embedding_dim, \n",
        "                    input_length=1,\n",
        "                    embeddings_initializer=glorot_normal(seed=seed))(main_input)\n",
        "\n",
        "embedding = x # just the latent space as output\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(units=50, activation='relu', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "# second dense layer\n",
        "x = Dense(units=50, activation='relu', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "x = RepeatVector(2)(x)\n",
        "\n",
        "# less units\n",
        "x = SimpleRNN(units=25, return_sequences=True, bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "main_output = Dense(units=output_dim, name='main_output', activation='softmax', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "model = Model(inputs=main_input, outputs=[main_output, embedding])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss={'main_output': 'categorical_crossentropy', 'embedding': 'mae' },\n",
        "              loss_weights={'main_output': .1, 'embedding': 1.})\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "main_input (InputLayer)      [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1, 1)              569       \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "repeat_vector_10 (RepeatVect (None, 2, 50)             0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_10 (SimpleRNN)    (None, 2, 25)             1900      \n",
            "_________________________________________________________________\n",
            "main_output (Dense)          (None, 2, 3426)           89076     \n",
            "=================================================================\n",
            "Total params: 94,195\n",
            "Trainable params: 94,195\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 290 ms, sys: 33.9 ms, total: 324 ms\n",
            "Wall time: 320 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGvvW1TYbnkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "c7a0f5c9-c880-41c4-faa8-95bde5b53eaf"
      },
      "source": [
        "%%time\n",
        "\n",
        "EPOCHS=20\n",
        "BATCH_SIZE=10\n",
        "\n",
        "history = model.fit(x=X, \n",
        "                    y={'main_output': Y, 'embedding': original_embeddings},\n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15320/67663 [=====>........................] - ETA: 1:14 - loss: 7.5179 - main_output_loss: 6.8783 - embedding_loss: 0.6395"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-72ecb6a815e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nEPOCHS=20\\nBATCH_SIZE=10\\n\\nhistory = model.fit(x=X, \\n                    y={'main_output': Y, 'embedding': original_embeddings},\\n                    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3383\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3385\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3386\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3387\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    548\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 549\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    420\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    421\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 422\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    423\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ah1dd-eM6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = model.get_layer('embedding')\n",
        "embedding_model = Model(inputs=model.input, outputs=embedding_layer.output)\n",
        "embeddings_1d = embedding_model.predict(samples).reshape(-1)\n",
        "\n",
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, np.zeros(len(embeddings_1d)))\n",
        "for index, x_pos in zip(samples, embeddings_1d):\n",
        "  name = airline_tokenizer.index_word[index].upper()\n",
        "  plt.annotate(name, (x_pos, 0), rotation=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OigqkWUN6t3",
        "colab_type": "text"
      },
      "source": [
        "## Clustering in 2d\n",
        "\n",
        "1d embedding vs size of airline\n",
        "* find what is similar\n",
        "* what is an outlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyyRsXWdN6YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://en.wikipedia.org/wiki/List_of_airline_codes\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_North_America\n",
        "# https://www.tvlon.com/resources/airlinecodes.htm\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_Europe\n",
        "\n",
        "airline_size = {\n",
        "    'LH': 130, 'BA': 105, 'SK': 30, 'KL': 101, 'AF': 101, 'FR': 129, 'SU': 56, 'EW': 24, 'TP': 16, 'BT': 4, 'U2': 88, 'AA': 204, 'US': 204, 'UA': 158, 'WN': 164, 'DL': 192, 'AS': 46, 'HA': 12\n",
        "}\n",
        "sample_names = [airline_tokenizer.index_word[sample].upper() for sample in samples]\n",
        "sample_sizes = [airline_size[name] * 1e6 for name in sample_names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CksSH1wHLzSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "# plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, sample_sizes)\n",
        "for name, x_pos, y_pos in zip(sample_names, embeddings_1d, sample_sizes):\n",
        "  plt.annotate(name, (x_pos,  y_pos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZMqtkZze5fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "embeddings_1d_scaled = StandardScaler().fit_transform(embeddings_1d.reshape(-1, 1))\n",
        "sizes_for_samples_scaled = StandardScaler().fit_transform(np.array(sample_sizes).reshape(-1, 1))\n",
        "X = np.dstack((embeddings_1d_scaled.reshape(-1), sizes_for_samples_scaled.reshape(-1)))[0]\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "X_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74T57XPbwZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "clf = DBSCAN(eps=0.75, min_samples=2)\n",
        "clf.fit(X_scaled)\n",
        "clusters = clf.labels_.astype(np.int)\n",
        "clusters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaRY5XAygF7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import cycle, islice\n",
        "\n",
        "# last color is black to properly display label -1 as noise (black)\n",
        "colors = np.append(np.array(list(islice(cycle(['#AAAAFF', '#ff7f00', '#4daf4a',\n",
        "                                 '#f781bf', '#a65628', '#984ea3',\n",
        "                                 '#999999', '#e41a1c', '#dede00']),\n",
        "                          int(max(clusters) + 1)))), ['#000000'])\n",
        "\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.xlabel('Similarity by typical routes')\n",
        "plt.ylabel('Passengers')\n",
        "\n",
        "plt.scatter(embeddings_1d, sample_sizes, color=colors[clusters], s=200)\n",
        "for name, x_pos, y_pos in zip(sample_names, embeddings_1d, sample_sizes):\n",
        "  plt.annotate(name, (x_pos,  y_pos), fontsize=18, color='grey')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oqyHIYsHIT1",
        "colab_type": "text"
      },
      "source": [
        "## Making results more stable\n",
        "\n",
        "* when you visualize latent spaces they should not change much when re-training or fitting additional data points\n",
        "* when working with autoencoders or embeddings there are two ways to make that happen\n",
        "  1. save model, do not retrain from scratch and only fit new data points with low learning rate\n",
        "  1. save output from embedding and keep new latent space similar by adding to the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5aM3L7Vte_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save complete model\n",
        "model.save('airline-embedding-v1.h5')\n",
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCWb4v05HXCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}