{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embeddings-retrain.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/tf2/embeddings-retrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0SNZ3gZDa36",
        "colab_type": "text"
      },
      "source": [
        "# Robst Retraining of Airline Embeddings\n",
        "\n",
        "_Keeping existing embeddings as stable as possible when chaning the model or adding new data_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv2d1kl3HOBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur7tExIkHOlQ",
        "colab_type": "code",
        "outputId": "de800099-95ab-415e-f173-e87abb754a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq6gP6ZWKugz",
        "colab_type": "text"
      },
      "source": [
        "## Step I: Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74_7Xj83pNyk",
        "colab_type": "code",
        "outputId": "ab269348-bd57-4698-fd86-6c08d77abdff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 2321k    0 15540    0     0  36393      0  0:01:05 --:--:--  0:01:05 36308\r100 2321k  100 2321k    0     0  4596k      0 --:--:-- --:--:-- --:--:-- 4587k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q64fxjyqmyU",
        "colab_type": "code",
        "outputId": "ed39274c-85ce-49e7-9e4a-0cbe06716d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('routes.dat', quotechar=\"'\", sep=',', encoding='utf-8', header=None, na_values='\\\\N',\n",
        "                names=['Airline', 'Airline ID', 'Source airport', 'Source airport ID', 'Destination airport', 'Destination airport ID', 'Codeshare', 'Stops', 'Equipment'])\n",
        "\n",
        "# https://openflights.org/data.html#route\n",
        "  \n",
        "# Airline\t2-letter (IATA) or 3-letter (ICAO) code of the airline.\n",
        "# Airline ID\tUnique OpenFlights identifier for airline (see Airline).\n",
        "# Source airport\t3-letter (IATA) or 4-letter (ICAO) code of the source airport.\n",
        "# Source airport ID\tUnique OpenFlights identifier for source airport (see Airport)\n",
        "# Destination airport\t3-letter (IATA) or 4-letter (ICAO) code of the destination airport.\n",
        "# Destination airport ID\tUnique OpenFlights identifier for destination airport (see Airport)\n",
        "# Codeshare\t\"Y\" if this flight is a codeshare (that is, not operated by Airline, but another carrier), empty otherwise.\n",
        "# Stops\tNumber of stops on this flight (\"0\" for direct)\n",
        "# Equipment\t3-letter codes for plane type(s) generally used on this flight, separated by spaces\n",
        "\n",
        "# df[df['Stops'] == 1] gives only a dozen or so routes, so also drop it\n",
        "df.drop(['Airline ID',\t'Source airport ID', 'Destination airport ID', 'Codeshare', 'Equipment', 'Stops'], axis='columns', inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4YhKffPzMAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "airline_tokenizer = Tokenizer()\n",
        "airline_tokenizer.fit_on_texts(df['Airline'])\n",
        "\n",
        "encoded_airlines = np.array(airline_tokenizer.texts_to_sequences(df['Airline'])).reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7n-Vq0m2Hu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "routes = df[['Source airport', 'Destination airport']].apply(lambda x: ' '.join(x), axis=1)\n",
        "\n",
        "routes_tokenizer = Tokenizer()\n",
        "routes_tokenizer.fit_on_texts(routes)\n",
        "encoded_routes = np.array(routes_tokenizer.texts_to_sequences(routes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSm686Cv77Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# sequence of airlines encoded as a unique number\n",
        "x = encoded_airlines\n",
        "# sequence of pair, src, dest encoded as a unique numbers\n",
        "Y = to_categorical(encoded_routes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfrT2dBALBR5",
        "colab_type": "text"
      },
      "source": [
        "## Step II: Using Original 1-d Model to re-create existing embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_0WdDJFLYvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/DJCordhose/ai/master/models/airline-embedding-v1.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWLfVeWnLH4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('airline-embedding-v1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSsJVEC_MpaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://en.wikipedia.org/wiki/List_of_airline_codes\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_North_America\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_Europe\n",
        "\n",
        "europe_airlines = ['LH', 'BA', 'SK', 'KL', 'AF', 'FR', 'SU', 'EW', 'TP', 'BT', 'U2']\n",
        "us_airlines = ['AA', 'US', 'UA', 'WN', 'DL', 'AS', 'HA']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_iw4PbXMqVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = [airline_tokenizer.word_index[airline_code.lower()] for airline_code in europe_airlines + us_airlines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlK0ecwwMPzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = model.get_layer('embedding')\n",
        "embedding_model = Model(inputs=model.input, outputs=embedding_layer.output)\n",
        "embeddings_1d = embedding_model.predict(samples).reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sL6-oHHM52R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, np.zeros(len(embeddings_1d)))\n",
        "for index, x_pos in zip(samples, embeddings_1d):\n",
        "  name = airline_tokenizer.index_word[index].upper()\n",
        "  plt.annotate(name, (x_pos, 0), rotation=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvWtuoAfKy6K",
        "colab_type": "text"
      },
      "source": [
        "## Step III: Convert original embedding model to functional API (as sequential will no longer be enough later)\n",
        "\n",
        "https://keras.io/getting-started/functional-api-guide/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZdK4FMtEsAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "72253b2e-0663-49cd-aec1-8dfad670699d"
      },
      "source": [
        "%%time\n",
        "\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, LSTM, GRU, SimpleRNN, Embedding, RepeatVector\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "seed = 7\n",
        "\n",
        "airlines = df['Airline'].unique()\n",
        "output_dim = len(routes_tokenizer.word_index) + 1\n",
        "\n",
        "input_dim = len(airlines) + 1\n",
        "embedding_dim = 1\n",
        "\n",
        "main_input = Input(shape=(1,), name='main_input')\n",
        "\n",
        "x = Embedding(name='embedding',\n",
        "                    input_dim=input_dim, \n",
        "                    output_dim=embedding_dim, \n",
        "                    input_length=1,\n",
        "                    embeddings_initializer=glorot_normal(seed=seed))(main_input)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(units=50, activation='relu', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "x = RepeatVector(2)(x)\n",
        "\n",
        "x = SimpleRNN(units=50, return_sequences=True, bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "main_output = Dense(units=output_dim, name='output', activation='softmax', bias_initializer='zeros', kernel_initializer=glorot_normal(seed=seed))(x)\n",
        "\n",
        "model = Model(inputs=main_input, outputs=main_output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "main_input (InputLayer)      [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1, 1)              569       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 2, 50)             0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 2, 50)             5050      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2, 3426)           174726    \n",
            "=================================================================\n",
            "Total params: 180,445\n",
            "Trainable params: 180,445\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 345 ms, sys: 16.2 ms, total: 361 ms\n",
            "Wall time: 458 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y0ScvHBEbzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "EPOCHS=20\n",
        "BATCH_SIZE=10\n",
        "\n",
        "history = model.fit(x, Y, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fv_XbOyFGxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we expect this to be substantially worse than the 2d version as the bottle neck now is much more narrow\n",
        "loss, accuracy = model.evaluate(x, Y, batch_size=BATCH_SIZE)\n",
        "loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0go51sW9nSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.yscale('log')\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8a3Blxc9oAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.yscale('log')\n",
        "plt.plot(history.history['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaM-ovJLisy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "embedding_layer = model.get_layer('embedding')\n",
        "embedding_model = Model(inputs=model.input, outputs=embedding_layer.output)\n",
        "embeddings_1d = embedding_model.predict(samples).reshape(-1)\n",
        "\n",
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, np.zeros(len(embeddings_1d)))\n",
        "for index, x_pos in zip(samples, embeddings_1d):\n",
        "  name = airline_tokenizer.index_word[index].upper()\n",
        "#   print(name, (x_pos, y_pos))\n",
        "  plt.annotate(name, (x_pos, 0), rotation=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqP3yh92Rv1b",
        "colab_type": "text"
      },
      "source": [
        "## Step IV: Simulate Model Change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OigqkWUN6t3",
        "colab_type": "text"
      },
      "source": [
        "## Clustering in 2d\n",
        "\n",
        "1d embedding vs size of airline\n",
        "* find what is similar\n",
        "* what is an outlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyyRsXWdN6YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://en.wikipedia.org/wiki/List_of_airline_codes\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_North_America\n",
        "# https://www.tvlon.com/resources/airlinecodes.htm\n",
        "# https://en.wikipedia.org/wiki/List_of_largest_airlines_in_Europe\n",
        "\n",
        "airline_size = {\n",
        "    'LH': 130, 'BA': 105, 'SK': 30, 'KL': 101, 'AF': 101, 'FR': 129, 'SU': 56, 'EW': 24, 'TP': 16, 'BT': 4, 'U2': 88, 'AA': 204, 'US': 204, 'UA': 158, 'WN': 164, 'DL': 192, 'AS': 46, 'HA': 12\n",
        "}\n",
        "sample_names = [airline_tokenizer.index_word[sample].upper() for sample in samples]\n",
        "sample_sizes = [airline_size[name] * 1e6 for name in sample_names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CksSH1wHLzSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for printing only\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.figure(dpi=600)\n",
        "# plt.axis('off')\n",
        "\n",
        "plt.scatter(embeddings_1d, sample_sizes)\n",
        "for name, x_pos, y_pos in zip(sample_names, embeddings_1d, sample_sizes):\n",
        "  plt.annotate(name, (x_pos,  y_pos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZMqtkZze5fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "embeddings_1d_scaled = StandardScaler().fit_transform(embeddings_1d.reshape(-1, 1))\n",
        "sizes_for_samples_scaled = StandardScaler().fit_transform(np.array(sample_sizes).reshape(-1, 1))\n",
        "X = np.dstack((embeddings_1d_scaled.reshape(-1), sizes_for_samples_scaled.reshape(-1)))[0]\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "X_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74T57XPbwZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "clf = DBSCAN(eps=0.75, min_samples=2)\n",
        "clf.fit(X_scaled)\n",
        "clusters = clf.labels_.astype(np.int)\n",
        "clusters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaRY5XAygF7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import cycle, islice\n",
        "\n",
        "# last color is black to properly display label -1 as noise (black)\n",
        "colors = np.append(np.array(list(islice(cycle(['#AAAAFF', '#ff7f00', '#4daf4a',\n",
        "                                 '#f781bf', '#a65628', '#984ea3',\n",
        "                                 '#999999', '#e41a1c', '#dede00']),\n",
        "                          int(max(clusters) + 1)))), ['#000000'])\n",
        "\n",
        "# plt.figure(dpi=600)\n",
        "\n",
        "plt.xlabel('Similarity by typical routes')\n",
        "plt.ylabel('Passengers')\n",
        "\n",
        "plt.scatter(embeddings_1d, sample_sizes, color=colors[clusters], s=200)\n",
        "for name, x_pos, y_pos in zip(sample_names, embeddings_1d, sample_sizes):\n",
        "  plt.annotate(name, (x_pos,  y_pos), fontsize=18, color='grey')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oqyHIYsHIT1",
        "colab_type": "text"
      },
      "source": [
        "## Making results more stable\n",
        "\n",
        "* when you visualize latent spaces they should not change much when re-training or fitting additional data points\n",
        "* when working with autoencoders or embeddings there are two ways to make that happen\n",
        "  1. save model, do not retrain from scratch and only fit new data points with low learning rate\n",
        "  1. save output from embedding and keep new latent space similar by adding to the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5aM3L7Vte_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save complete model\n",
        "model.save('airline-embedding-v1.h5')\n",
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCWb4v05HXCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}