<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Unsupervised Machine Learning</title>

    <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
    <meta name="author" content="Hakim El Hattab">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
      
          <!-- Code syntax highlighting -->
          <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }
      
                      .reveal h2,
                      .reveal h3,
                      .reveal h4 {
                          letter-spacing: 2px;
                          font-family: 'Amiri', serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          font-weight: bold;
                          font-style: italic;
                          letter-spacing: -2px;
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
                      .reveal .step-subtitle h1 {
                          letter-spacing: 1px;
                      }
                      .reveal .step-subtitle h2,
                      .reveal .step-subtitle h3 {
                          text-transform: none;
                          font-style: italic;
                          font-weight: normal;
                          /* font-weight: 400; */
                          /* font-family: 'Amiri', serif; */
                          font-family: 'Lobster', serif;
                          letter-spacing: 1px;
                          color: #2aa198;
                          text-decoration: underline;
                      }
      
                      .reveal .front-page h1,
                      .reveal .front-page h2 {
                          font-family: "League Gothic";
                          font-style: normal;
                          text-transform: uppercase !important;
                          letter-spacing: 1px;
                      }
      
                      .reveal .front-page h1 {
                          font-size: 2.5em !important;
                      }
      
                      .reveal .highlight {
                          background-color: #D3337B;
                          color: white;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }
          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        var printMode = window.location.search.match(/print-pdf/gi);
        link.href = printMode ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

<div class="reveal">
    <div class="slides">

            <section data-markdown class="preparation" style="font-size: xx-large">
                    <textarea data-template>
### Preparation

Notebooks noch mal ansehen:
* Notebooks schon mal aufmachen
* Projector Example T-SNE schon mal trainieren
                        </textarea>
                        </section>
        
<!-- 
Einführung in Unsupervised Learning

Bei all dem Ruhm, den Supervised Deep Learning bekommt, kann man schnell vergessen, dass es im Bereich Machine Learning
noch viel mehr gibt. Ein komplett anderer Bereich ist das Unsupervised Machine Learning, das ohne gelabelte Daten
auskommt.

Als wichtiges Gebiet werden wir uns das Clustering am Beispiel von k-means und DBSCAN ansehen. Dabei lernst du, was die
Unterschiede sind und wie wir die Qualität unserer Klassifikationen feststellen können.

Der zweite wichtige Bereich ist die Dimensionsreduktion entweder für eine Visualisierung von Daten in hohen Dimensionen
oder für die Analyse der Unabhängigkeit von Variablen. Hier werden wir uns mit PCA und t-sne beschäftigen. -->

<section>
            <h2>Einführung in Unsupervised Machine Learning</h2>
            <p><a target="_blank" href="https://www.data2day.de/veranstaltung-7165-einf%E3%BChrung-in-unsupervised-learning.html">
                data2day, September 2018
            </a></p>
            <h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / <a href="http://twitter.com/djcordhose">@DJCordhose</a>
            </h4>
            <small>
                <a href="http://bit.ly/d2d-unsupervised">
                    http://bit.ly/d2d-unsupervised</a>
        </small>
        </section>



            <section data-markdown class="todo">
                <textarea data-template>
Leland McInnes (@leland_mcinnes) tweeted at 10:36 PM on Fri, Jan 18, 2019:
If you want to spend some time exploring a UMAP embedding of images (like MNIST) @GrantCuster put together a nice tool: https://t.co/IF9V5u3Fn9
(https://twitter.com/leland_mcinnes/status/1086376749473112065?s=03)

Get the official Twitter app at https://twitter.com/download?s=13
        </textarea>
    </section>


        <!-- <section class="todo">
                <pre>
            - plot noise (-1) in black 
                - like here http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py
                          </pre>
            </section> -->

            <!-- <section data-markdown class="todo">
                <textarea data-template>
### PCA vs unsupervised feature selection

http://efavdb.com/unsupervised-feature-selection-in-python-with-linselect/
                </textarea>
            </section> -->
                    

    <!-- <section data-markdown>
            <textarea data-template>
### Reference: Statistical Foundations

* https://machinelearningmastery.com/a-gentle-introduction-to-calculating-normal-summary-statistics/
* http://students.brown.edu/seeing-theory/
        </textarea>
    </section> -->
    
    
    <section>
        <h1>Part I</h1>
        <h2>Clustering</h2>
    </section>

    <section>
        <h3>Three different categories of ML</h3>
        <img src="img/unsupervised/types-of-ml.png" height="500px">
    </section>

    <section data-markdown>
        <textarea data-template>
### Aufgabe: Welche Cluster seht ihr?
<img src='img/unsupervised/clustering.jpg' height="550px">
    </textarea>
</section>
<section data-markdown style="font-size: xx-large">
        <textarea data-template>
### Fragen

1. Was ist bei diesen Daten grundsätzlich anders als bei den Daten zum Supervised Learning?
1. Welche Formen haben die Cluster? Wie hast du diese als Cluster erkannt?
1. Welche Formen hältst du für mehr oder weniger realistisch?
1. Was könnte an den Achsen stehen? War das wichtig für das Clustering?
1. Was könnte ein Cluster ausdrücken?
1. Was passt nicht zu einem Cluster?
1. Wie kann man diese Punkte interpretieren?
    </textarea>
</section>

<!-- <section>
        <h3>Our brains do a phenomenal job when processing images</h3>
        <p class="fragment">We quickly see patterns and do automatic clustering without even thinking.</p>
    </section>
    
    <section data-markdown>
            <textarea data-template>
### Fast Feature Decoding in our Brains

<img src='img/SteveFranconeri_fast_feature_encoding.jpg' height="500px">
<small>
https://twitter.com/SteveFranconeri/status/996309503418216448     
</small>
    </textarea>
    </section>

    <section data-markdown>
        <textarea data-template>
### Gestalt principles apply

We see things as belonging together when

* they are close to each other (proximity)
* are aligned in the same direction (continuity)

<a href="https://twitter.com/pablostanley/status/974303621092225024" target="_blank">
    Animated Gestalt Principls</a>

        </textarea>
</section>

 -->
<!-- <section data-markdown>
        <textarea data-template>
### Automatic Clustering

_Clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more
similar (in some sense) to each other than to those in other groups (clusters)._

https://en.wikipedia.org/wiki/Cluster_analysis
        </textarea>
</section> -->

<section>
            <img src='img/unsupervised/decisions/type.png'>
        </section>
                    
    <section>
        <h3>Unsupervised Learning</h3>
        <img src='img/unsupervised/decisions/question.png'>
    </section>


    <!-- <section data-markdown class="todo">
            <textarea data-template>
### Applications of clustering
* Outlier Detection: one of these things is not like the others
* https://hackernoon.com/unsupervised-machine-learning-for-fun-profit-with-basket-clusters-17a1161e7aa1
* https://flowingdata.com/2018/03/07/visualizing-outliers/?imm_mid=0fbfda&cmp=em-data-na-na-newsltr_20180314
            </textarea>
</section> -->

        <!-- <section>
            <h3>Exercise: How to automate this?</h3>
            <ol>
                <li>Work in groups</li>
                <li>Come up with an informal algorithm / approach / idea</li>
                <li>Manually apply the algorithm / approach / idea to the our clustering example</li>
            </ol>
        </section> -->

        <section data-markdown>
            <textarea data-template>
## Looking at standard implementations

<small>
https://colab.research.google.com/github/djcordhose/data-viz/blob/master/notebooks/k-means_vs_dbscan.ipynb
</small>
    
            </textarea>
        </section>

        <section>
            <img src="img/flashcards/K-Means_Clustering_print.png" height="550px">
            <p>Most Basic Algorithm</p>
        </section>

        <section>
            <h3>What do you think is the fundamental weakness of this approach?</h3>            
        </section>

    
            <section>
                <img src="img/unsupervised/blobs_kmeans_3.png" height="550px">
                <p>Perfect result for k = 3</p>
        </section>
            
        <section>
            <img src="img/unsupervised/blobs_kmeans_10.png" height="550px">
            <p>And this is the result for k = 10</p>
        </section>

        <section>
            <h3>You need to make a good guess of how many reasonable clusters there are</h3>
        </section>

        <section>
                <h3>There are more issues with the k-means approach</h3>            
        </section>

        <section data-markdown>
                <textarea data-template>
    <img src="img/unsupervised/noisy_circles.png" height="500px">

Some shapes we can identify, but can k-means?    
                </textarea>
    </section>

    <section data-markdown>
            <textarea data-template>
<img src="img/unsupervised/no_structure.png" height="500px">

What about no structure at all?    
            </textarea>
</section>

<section>
        <h3>Results for k-means</h3>            
</section>

<section data-markdown>
        <textarea data-template>
<img src="img/unsupervised/noisy_circles_kmeans.png" height="500px">

even with k=2 not a chance    
        </textarea>
</section>

<section data-markdown>
    <textarea data-template>
<img src="img/unsupervised/no_structure_kmeans.png" height="500px">

structure out of nothing
    </textarea>
</section>

<section>
    <h2>Comparing Clustering Algorithms</h2>
    <p>Choose your favorite!</p>
    <!-- <pre>
- http://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html
- http://hdbscan.readthedocs.io/en/latest/performance_and_scalability.html
    </pre> -->
</section>

<section data-markdown>
<textarea data-template>
<img src="img/unsupervised/cluster_compare.png" height="550px">

<p><small><a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html">
http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html
</a></small></p>

</textarea>
</section>

<section data-markdown>
<textarea data-template>
<img src="img/unsupervised/sphx_glr_plot_cluster_comparison_001.png" height="550px">

<p><small><a href="http://scikit-learn.org/stable/modules/clustering.html">
http://scikit-learn.org/stable/modules/clustering.html
</a></small></p>

</textarea>
</section>

<section>
    <h3>Which one is our favorite?</h3>
</section>

<section>
            <img src="img/flashcards/DBSCAN_print.png" height="550px">
            <p>Density-Based Spatial Clustering</p>
    </section>

    <section data-markdown>
            <textarea data-template>
### Demo Cluster
<img src="img/unsupervised/dbscan-demo.png" height="550px">


</textarea>
</section>

<section>
    <h3>A quick guess: What is the crucial factor here?</h3>
</section>


    <!-- <section data-markdown>
            <textarea data-template>
### Metrics

How well are we doing?

Hard to tell, since there is no (or we do not know) the ground truth

<small>
http://scikit-learn.org/stable/modules/classes.html#clustering-metrics
<br>
http://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation
</small>
    </textarea>

</section> -->

<!-- <section data-markdown class="todo">
<textarea data-template>
Aus textanalyse-2.ipynb

from sklearn import metrics

metrics.adjusted_mutual_info_score(labels1, labels2)

http://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation   
</textarea>

</section>
 -->
<!-- <section data-markdown>
<textarea data-template>
#### Try to make sense of this yourself, use our clusters as an example
<img src="img/flashcards/Silhouette_Coefficients_print.png" height="550px">
<small>
https://en.m.wikipedia.org/wiki/Silhouette_(clustering)
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Can you explain how it works?

1. What does the denominator term do?         
1. Why is the Silhouette Coefficient always between -1 and 1? What would each value mean?
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### What are the strengths and weaknesses of this Metric?

<div class="fragment">

*Strengths*
<ul>
    <li>intuition for value exists (-1 bad, 0 not clustered, 1 good)</li>
    <li>easy to understand</li>
    <li>fits well for blobs</li>
</ul>

</div>
<div class="fragment">

_Weakness_: does not work well for directions and complex patterns

</div>
</textarea>
</section> -->
<!-- <section data-markdown class="todo">
        <textarea data-template>
Show metrics from notebook

http://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient
        </textarea>
</section> -->

<!-- <section data-markdown class="todo">
        <textarea data-template>
Alternative without scaling between -1 and 1, again show metrics from notebook

http://scikit-learn.org/stable/modules/clustering.html#calinski-harabaz-index
        </textarea>
</section>
 -->

<!-- <section data-markdown class="todo">
    <textarea data-template>
### Code Exercise: 
* Add at least one implementation of one clustering algorithm shown in the overview above
* Experiment with the remaining data sets: how do the different clustering algorithms cope with them?
* How much work do you have to put into tweaking the meta parameters?
    </textarea>
</section> -->

<section>
        <h1>Part II</h2>
        <h2>Dimensionality Reduction</h2>
</section>

<!-- <section data-markdown>
        <textarea data-template>
### What is Dimensionality Reduction?

* Linear Correlations: PCA: Find out what really matters in your data
* Non-Linear Correlations: t-SNE: Visualizing High Dimensional Data
</textarea>
    </section> -->
    
<section data-markdown>
        <textarea data-template>
## PCA
### Principal Component Analysis

</textarea>
    </section>

    <section>
        <img src="img/flashcards/Principal_Component_Analysis_print.png">
    </section>
    
    <section>
        <h3>Intuition in 3d</h3>
        <p>Rotate the camera to a position that reveals the most information</p>
    </section>

    <section data-markdown>
        <textarea data-template>
<a href='https://youtu.be/4DpdpZkl8HI?t=65' target="_blank">
<img src='img/unsupervised/perceptual-shift.png' height="500px">
</a>

<small>
The Making of Perceptual Shift: https://youtu.be/4DpdpZkl8HI?t=65
</small>
</textarea>
    </section>

    <section>
        <h2><small>Turn your data to look at it from another perspective</small></h2>
        <div>
            <a href="https://twitter.com/Creatuluw/status/749151998415634432" target="_blank">
            <img src="img/cat-upside-down.jpg" height="450px"
                 style="float: left; padding-right: 50px; padding-left: 150px">
                </a>
                <a href="https://twitter.com/planetepics/status/914792139309150208" target="_blank">
            <img src="img/dataviz-cat.jpg" height="450px" style="float: left">
            </a>

        </div>
        <p style="clear: both"><small><a target="_blank" href="https://twitter.com/Creatuluw/status/749151998415634432">
            https://twitter.com/Creatuluw/status/749151998415634432</a>
            <br>
            <a href="https://twitter.com/planetepics/status/914792139309150208" target="_blank">
                https://twitter.com/planetepics/status/914792139309150208
            </a>
            </small></p>
    </section>



    <section data-markdown>
        <textarea data-template>
### Interactive Experiment

<img src="img/unsupervised/pca_setosa.png" height="400">

<small>
http://setosa.io/ev/principal-component-analysis/
</small>
    </textarea>
    </section>


<section>
<h3>Typical Use Case: Dimensionality Reduction</h3>
<div style="float: left">
        <img src="img/unsupervised/pca-example.png" height="500px">
    </div>
    <div style="float: right" class="fragment">
            <img src="img/unsupervised/pca-example-pcs.jpg" height="500px">
    </div>
<small>
    <a href="https://colab.research.google.com/github/djcordhose/data-viz/blob/master/notebooks/5-1-pca.ipynb">
https://colab.research.google.com/github/djcordhose/data-viz/blob/master/notebooks/5-1-pca.ipynb
</a>
</small>    
        </section>
    

<section>
<h2>t-SNE</h2>
<h3>t-distributed stochastic neighbor embedding</h3>
<p>Visualizing High Dimensional Data</p>
</section>

<section data-markdown>
        <textarea data-template>
### Idea of t-SNE

_Describe a projection from high dimension to 2-d as a machine learning problem_

1. Create pairwise probability distributions over high dimensional data 
1. Create similar distribution in 2-d
1. Loss is distance between the two using relative entropy
1. Minimize loss

<small>
https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding
<br>
https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Watch t-SNE learn - Dancing Bacteria

<img src='img/unsupervised/animated_tSNE.gif'>

<small>
https://twitter.com/ChaseClarkatUIC/status/984839270132338688
<br>
https://chasemc.github.io/post/animated-t-sne/
</small></textarea>
</section>

<section data-markdown>
        <textarea data-template>
### t-SNE's crucial parameter: Perplexity

* Intuition: a guess about the number of close neighbors each point has
  * Low Perplexity: Local variations dominate
  * High Perplexity: Include even more remote data in neighborhood (all data as an extreme)
* Can dramatically change the results of t-SNE

<small>
https://en.wikipedia.org/wiki/Perplexity    
</small>
            </textarea>
        </section>

<section data-markdown style="font-size: xx-large">
        <textarea data-template>
### How to Use t-SNE Effectively

1. Perplexity really matters
1. Iterate until reaching a stable configuration
1. Cluster sizes in a t-SNE plot mean nothing
1. Distances between clusters might not mean anything

<img src='img/unsupervised/misread-tsne.png' height="300px">

<small>
https://distill.pub/2016/misread-tsne/
</small>
</textarea>
</section>

<!-- <section data-markdown>
    <textarea data-template>
### T-SNE can also reduce dimensions

1. There is no model, however
1. can only perform <em>fit_transform</em>
1. works well on clusters

<small>
    https://colab.research.google.com/github/djcordhose/data-viz/blob/master/notebooks/5-2-t-sne.ipynb
</small>
</textarea>
</section> -->

<section>
<h3>UMAP: Alternative to t-SNE</h3>
<p><small>Searching for a low dimensional projection of the data that has the closest possible equivalent fuzzy topological structure (Riemannian manifold).</small></p>
<div style="float: left">
        <img src="img/unsupervised/umap_example_mnist1.png" height="300px">
        <p>
            <small>MNIST Digit Dataset</small>
        </p>
    </div>
    <div style="float: right">
            <img src="img/unsupervised/umap_example_fashion_mnist1.png" height="300px">
            <p>
            <small>Fashion Items</small>
        </p>
    </div>
<small>
    <a href="https://github.com/lmcinnes/umap">
https://github.com/lmcinnes/umap
</a>
</small>    
        </section>
        
        <section data-markdown>
            <textarea data-template>
### Fashion MNIST

28x28 grayscale images of fashion Items

<img src="img/fashion-mnist-sprite.png" height="400px">


<small>
https://github.com/zalandoresearch/fashion-mnist
<br>
https://arxiv.org/abs/1708.07747
</small>    
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### What do numbers look like?

the first million integers, represented as binary vectors indicating their prime factors 

<img src='img/primes_umap_1e6_contrast_enhanced.png' height="300">

<small>
https://youtu.be/nCk8dyU7zUM
<br>
https://twitter.com/algoritmic/status/1036658934042509312
https://johnhw.github.io/umap_primes/index.md.html
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Dimensionality Reduction with UMAP

1. Much faster than T-SNE with comparable results
1. Main parameter (number of neighbors) a bit more intinutive
1. Has abstract model
1. Can also make use of labels

<small>
    https://colab.research.google.com/github/djcordhose/data-viz/blob/master/notebooks/5-3-umap.ipynb
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Great Use Case for T-SNE (and PCA )

<a href='https://projector.tensorflow.org'>
<img src="img/unsupervised/embedding-projector.png" height="500px">
</a>

<small>
https://projector.tensorflow.org
</small>
</textarea>
</section>
        
<section data-markdown>
    <textarea data-template>
### Wrapping Up

* Clustering can find common groups and outliers
* DBSCAN is the cluster implementation to try first
* Dimensionality reduction is useful for data visualization and getting rid of features
* PCA is good for feature reduction
* T-SNE is a state-of-the-art for data viz
* UMAP might become a player soon

<p>
<small>
    Einführung in Unsupervised Machine Learning
    <br>
    data2day, September 2018
    <br>
    <a href="http://zeigermann.eu">Oliver Zeigermann</a> /
    <a href="http://twitter.com/djcordhose">@DJCordhose</a>
    <br>
    <a href="http://bit.ly/d2d-unsupervised">
        http://bit.ly/d2d-unsupervised
    </a>
</small>
</p>
</textarea>
</section>


<section>
        <h1>Bonus Part III</h1>
        <h2>Autoencoders and GANs</h2>
        <p>A very short Introduction</p>
    </section>

<section data-markdown>
        <textarea data-template>
### Autoencoders

_An autoencoder is an artificial neural network used for unsupervised learning of efficient codings._

* for autoencoders the input is the same as the output
* they are somewhere between supervised and unsupervised learning
* traditionally used for dimensionality reduction: output with less details
* lately also for generative models: generate something new

<small>
https://en.wikipedia.org/wiki/Autoencoder
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Autoencoders on Images

<img src="img/unsupervised/autoencoder.png">

<small>
https://towardsdatascience.com/deep-inside-autoencoders-7e41f319999f
https://github.com/nathanhubens/Autoencoders
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Why copy input to output?

1. _overcomplete_: capacity of latent space is large enough to completely reproduce images
   * copy the input to the output without learning anything useful about the data distribution 
1. _undercomplete_: capacity of latent space is too small to reproduce images
   * force the autoencoder to learn the most salient features of the training data
   * can denoise data
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Autoencoders and PCA

_If linear activations are used, or only a single sigmoid hidden layer, then the optimal solution to an autoencoder is strongly
related to principal component analysis (PCA)._

* principal components may be recovered from them using singular value decomposition (SVD)
* SVD is another style of computing the principal components

<small>
        https://en.wikipedia.org/wiki/Autoencoder#Relationship_with_principal_component_analysis_(PCA)
https://en.wikipedia.org/wiki/Singular-value_decomposition
</small>
</textarea>
</section>

<section data-markdown style="font-size: xx-large">
        <textarea data-template>
## GANs

 _Generates authentic looking photographs_

<small>
    https://en.wikipedia.org/wiki/Generative_adversarial_network
</small>
</textarea>
</section>

<section>
<h3>Generating Celebreties</h3>
<p>Trained for two weeks on a single high-end GPU on CelebA-HQ data set (images of celebreties)</p>
<div class="fragment" style="float: left">
    <img src="img/unsupervised/gan-model-male2.png" height="300">
</div>
<div class="fragment" style="float: left; padding-left: 100px">
        <img src="img/unsupervised/gan-model-female2.png" height="300">
</div>
<div class="fragment" style="float: right">
        <!-- <img src="img/unsupervised/gan-model-female1.png" height="300"> -->
        <img src="img/unsupervised/gan-model-male.png" height="300">
</div>
<p style="clear: both">
<small>
<a href="https://twitter.com/alanyttian/status/988242167998148608" target="_blank">https://twitter.com/alanyttian/status/988242167998148608</a>

</small>
                   
</p>
</section>                                

<section data-markdown>
        <textarea data-template>
### Usings GANs to learn image translation

<video controls 
src="img/unsupervised/dog2cat.mp4" type="video/mp4"
></video>

<small>
https://twitter.com/liu_mingyu/status/985677397172207616
https://www.youtube.com/watch?v=ab64TWzWn40
</small>
</textarea>
</section>

<section data-markdown style="font-size: xx-large">
        <textarea data-template>
### How do GANs work?

GANs consist of two networks contesting with each other (adversarial)
1. _discriminator_: convolutional network trained to tell if an image is real or generated
   * initially trained on a known data set
   * training objective is to _decrease the error rate_
1. _generator_: deconvolutional network generating images from a latent representation
  * initial latent space is just random 
  * training objective is to _increase the error rate_ of the discriminative network

<small>
https://arxiv.org/abs/1511.06434
</small>
</textarea>
</section>

<section>
    <h4>State of the Art GAN (higher is better)</h4>
    <img src="img/unsupervised/gan-clothes.jpg" height="500px">
    <p><small><a href="https://arxiv.org/abs/1711.02231" target="_blank">Visually-Aware Fashion Recommendation and Design with Generative Image Models</a></small></p>
</section>

<section>
        <h4>Only two of these images are actual images</h4>
        <img src="img/unsupervised/gan.jpg" height="500px">
        <p>
            <small>
                <a href="https://twitter.com/goodfellow_ian/status/918900712901197824" target="_blank">
                    https://twitter.com/goodfellow_ian/status/918900712901197824</a>
            </small>
        </p>
    </section>
    
    <section>
        <h4>All others generated by neural networks</h4>
        <img src="img/unsupervised/gan-real-images.jpg" height="500px">
        <p>
            <small>
                <a href="https://twitter.com/davegershgorn/status/918902123668168704" target="_blank">https://twitter.com/davegershgorn/status/918902123668168704</a>
            </small>
        </p>
    </section>


    </div>

</div>

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>
<script src="lib/jquery-2.2.4.js"></script>

<script>
        if (window.location.hostname.indexOf('localhost') !== -1 && !printMode) {
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }
        Reveal.addEventListener( 'ready', function( event ) {
            // do we want this???
            $('li').addClass('fragment')

            if (window.location.hostname.indexOf('localhost') !== -1) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
            // applies to all versions
            $('code').addClass('line-numbers');

            // make all links open in new tab
            $('a').attr('target', '_blank')

        } );
        $('section:not([data-background])').attr('data-background', "background/white.jpg");
    </script>
    
<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        width: 1100,

        transition: 'fade', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true},
            // https://github.com/mikemiles86/reveal-line-numbers
            {src: 'lib/js/line-numbers.js'}
        ]
    });

</script>

</body>
</html>
