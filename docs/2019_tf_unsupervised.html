<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Unsupervised TensorFlow</title>

    <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
    <meta name="author" content="Hakim El Hattab">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

          <link rel="stylesheet" href="reveal.js/css/reveal.css">
          <!--<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">-->
          <!--<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">-->
          <link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
      
          <!-- Code syntax highlighting -->
          <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">
          <style>
              /*pre code {*/
                  /*display: block;*/
                  /*padding: 0.5em;*/
                  /*background: #FFFFFF !important;*/
                  /*color: #000000 !important;*/
              /*}*/
      
              .right-img {
                  margin-left: 10px !important;
                  float: right;
                  height: 500px;
              }
              .todo:before {
                  content: 'TODO: ';
              }
              .todo {
                  color: red !important;
              }
              code span.line-number {
                  color: lightcoral;
              }
              .reveal pre code {
                  max-height: 1000px !important;
              }
      
              img {
                  border: 0 !important;
                  box-shadow:0 0 0 0 !important;
              }
      
              .reveal {
                  -ms-touch-action: auto !important;
                  touch-action: auto !important;
                      }
      
                      .reveal h2,
                      .reveal h3,
                      .reveal h4 {
                        letter-spacing: 2px;
                          font-family: 'Calibri', sans-serif;
                          /* font-family: 'Times New Roman', Times, serif; */
                          font-weight: bold;
                          color: black;
                          font-style: italic;
                          letter-spacing: -2px;
                          text-transform: none !important;
                      }
      
                      .reveal em {
                          font-weight: bold;
                      }
      
                      .reveal .step-subtitle h1 {
                          letter-spacing: 1px;
                      }
                      .reveal .step-subtitle h2,
                      .reveal .step-subtitle h3 {
                          text-transform: none;
                          font-style: italic;
                          font-weight: normal;
                          /* font-weight: 400; */
                          /* font-family: 'Amiri', serif; */
                          font-family: 'Lobster', serif;
                          letter-spacing: 1px;
                          color: #2aa198;
                          text-decoration: underline;
                      }
      
                      .reveal .front-page h1,
                      .reveal .front-page h2 {
                          font-family: "League Gothic";
                          font-style: normal;
                          text-transform: uppercase !important;
                          letter-spacing: 1px;
                      }
      
                      .reveal .front-page h1 {
                          font-size: 2.5em !important;
                      }
      
                      .reveal .highlight {
                          background-color: #D3337B;
                          color: white;
                      }
      
              .reveal section img {
                background: none;
              }
      
                      .reveal img.with-border {
                          border: 1px solid #586e75 !important;
                          box-shadow: 3px 3px 1px rgba(0, 0, 0, 0.15) !important;
                      }
      
                      .reveal li {
                          margin-bottom: 8px;
                      }
      
                      /* For li's that use FontAwesome icons as bullet-point */
                  .reveal ul.fa-ul li {
                      list-style-type: none;
                  }

            .reveal {
                color: black !important;
             }       

          </style>
      
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

<div class="reveal">
    <div class="slides">

<section data-markdown class="preparation">
        <textarea data-template>
### Preparation

    </textarea>
</section>

<section>
        <h2>Unsupervised Learning with TensorFlow</h2>
<h4><a href="http://zeigermann.eu">Oliver Zeigermann</a> / <a href="http://twitter.com/djcordhose">@DJCordhose</a>
</h4>
<p><small><a href="https://djcordhose.github.io/ai/2019_tf_unsupervised.html">
https://djcordhose.github.io/ai/2019_tf_unsupervised.html
</a></small></p>
</section>

<section data-markdown>
        <textarea data-template>
### How to turn categories into numbers?

* neural networks can not deal with symbols
* only numerical values can be processed by neural networks
* even words and texts can be seen as categories / symbols
* would it be possible to still make those numbers carry the semantic of the symbols? 

            </textarea>
            </section>

<section data-markdown>
    <textarea data-template>
### Motivating Exercise: Encoding Airports 

_find a numerical representation for airports_

* choose a few airports of your choice and bring them into numbers
* why did you choose this representation?
* do you think it is a good one?
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Label Encoding    

Normalize symbols such that they contain only values between 0 and number_of_symbols_in_vocab-1.

<pre><code>text = ["paris", "paris", "tokyo", "amsterdam"]
paris = 0
tokyo = 1
amsterdam = 2
encoded_text = [0, 0, 1, 2]</code></pre>

<small>
http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html
</small>
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Issues with turning symbols into integers

* numbers close to each other suggest a relation, but there might actually be none
* what would 7.5 mean?
* and what -8457878574 mean?
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Bag of Words - One/Multiple Hot Encoding
<img src="img/nlp/acolyer/word2vec-one-hot.png">
<small>
https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/
</small>
</textarea>
</section>

<section data-markdown>
        <textarea data-template>
### Issues with One-Hot-Encoding

* high dimensionalty 
* sparse representation
* neighborhood does not mean anything

            </textarea>
            </section>

            <section data-markdown>
                    <textarea data-template>
### Enter: Embeddings

* Embedding: Transform a high dim. vector space to a lower one
* word/symbol Embedding: Transform sparse one hot encodings into a dense lower dim. encoding 

<small>https://en.wikipedia.org/wiki/Word_embedding</small>
                        </textarea>
                    </section>
                
                    <section data-markdown>
<textarea data-template>
<img src="img/nlp/word_embeddings.png" height="550px">

<small>
<a href="https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.1-using-word-embeddings.ipynb">
Deep Learning with Python
</a>
</small>
</textarea>
</section>

<section data-markdown>
<textarea data-template>
### Assumption: symbols/words in similar contexts have similar meaning

* Why not have a few semantic dimensions and embed symbols/words into them?
* You define what is context and thus gives meaning
* For random texts this might be just the words that surround others
        </textarea>
    </section>

<section data-markdown>
    <textarea data-template>
## Types of Learning
<img src='img/types-of-ml.jpg'>
<small>
https://www.facebook.com/nipsfoundation/posts/795861577420073/
<br>
https://ranzato.github.io/publications/tutorial_deep_unsup_learning_part1_NeurIPS2018.pdf
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Introduction to Embeddings 

<img src='img/embedding_airport.png'>

<small>
https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/2019_tf/embeddings.ipynb
</small>
    </textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Hands-On: Find an application for an embedding 

* Run the introductory notebook
* can you come up with an interpretation for the semantics of the two dimensions of the embedding?
* then either 
  1. change the representation for airports and try to achieve good results
  1. come up with an application of your own (this is hard, make sure it still fits into the structure of the notebook) 

<small>
https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/2019_tf/embeddings.ipynb
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Arithmetic on Embeddings

_has been exaggerated recently, but still fun_

<img src='img/embedding_arithmetic.jpg' height="400px">

<small>
http://bryanlohjy.gitlab.io/spacesheet/word2vec.html
</small>
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Suprising Application of Embeddings

<img src='img/embedding-spell-checker.png' height="500px">

<small>
https://twitter.com/jeremyphoward/status/997264148655259648    
</small>
        </textarea>
        </section>

<section data-markdown>
        <textarea data-template>
### Word Embeddings using word2vec

_main assumption: words appearing in similar contexts have similar meaning_

<a href='https://projector.tensorflow.org'>
<img src="img/nlp/embedding-projector.png" height="350px">
</a>

<small>
https://projector.tensorflow.org
</small>
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### There is more to Unsupervised Deep Learning

* Autoencoders
  * VAEs
* Generative Adversarial Network (GAN) 

</textarea>
</section>

<section data-markdown style="font-size: x-large">
    <textarea data-template>
### Unsupervised Deep Learning 

Workshop at NIPS 2018
* https://www.facebook.com/nipsfoundation/posts/795861577420073/
* Slides: https://ranzato.github.io
  * https://ranzato.github.io/publications/tutorial_deep_unsup_learning_part1_NeurIPS2018.pdf
  * https://ranzato.github.io/publications/tutorial_deep_unsup_learning_part2_NeurIPS2018.pdf

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Autoencoders

* reproduce an input while going through a bottleneck
* latent representation is what you are interested in

<img src='img/autoencoder_schema.jpg'>

<small>
https://blog.keras.io/building-autoencoders-in-keras.html
</small>
        
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Why Autoencoders

* compression
* data denoising
* dimensionality reduction (for data visualization)
* building an abstract representation for further use

<small>
https://blog.keras.io/building-autoencoders-in-keras.html
</small>
        
</textarea>
</section>


<section data-markdown>
    <textarea data-template>
### Introduction to Autoencoders

_reproducing the MNIST data set_

<img src='img/mninst_ae.jpg'>

<small>
https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/2019_tf/autoencoders_intro.ipynb
</small>
        
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Autoencoding tabular data

_resulting in an advanced Keras lecture_

<img src='img/insurance_ae.png'>

<small style="font-size: large">
https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/2019_tf/autoencoders_tabular.ipynb
</small>
        
</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Exercise: Optimize training

_try to generate a more telling visualization_

* make sure you understand the architecture
* tune loss ratios
* sizes of input encodings
* what results do you get when you just average over the encoded inputs?

<small style="font-size: large">
https://colab.research.google.com/github/DJCordhose/ai/blob/master/notebooks/2019_tf/autoencoders_tabular.ipynb
</small>
        
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
### VAE

* Intro: https://youtu.be/9zKuYvjFFS8
* https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/eager/python/examples/generative_examples/cvae.ipynb
* Sean's Notebook: https://colab.research.google.com/drive/1f73wONMp8U2LvAmN0MNGyflqGFog0g2S
* VAE: 
  * https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf
  * http://tiao.io/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
## GANs

</textarea>
</section>

<section data-markdown>
    <textarea data-template>
### Understanding GANs

<a href='https://poloclub.github.io/ganlab/'>
<img src='img/tfjs/gan-lab.png'>
</a>
        
<small>
https://twitter.com/minsukkahng/status/1037016214575505409
https://poloclub.github.io/ganlab/
https://minsuk.com/research/papers/kahng-ganlab-vast2018.pdf
</small>
</textarea>
</section>

<section data-markdown class="todo">
    <textarea data-template>
### GANS    

New blog post: "GANs and Divergence Minimization", which covers the perspective of GANs as minimizing an "adversarial divergence" and draws parallels to maximum likelihood training. Also provides some motivation for better evaluation of GANs. https://t.co/XibWmoWEw8 https://t.co/tik01df1aS
(https://twitter.com/colinraffel/status/1076179243678093312?s=03)
</textarea>
</section>


    </div>

</div>

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>
<script src="lib/jquery-2.2.4.js"></script>

<script>
        $('.slido').remove();
        if (window.location.hostname.indexOf('localhost') !== -1) {
            // only applies to local version
            $('.remote').remove();
        } else {
            // only applies to public version
            $('.todo').remove();
            $('.preparation').remove();
            $('.local').remove();
        }
        Reveal.addEventListener( 'ready', function( event ) {
                // do we want this???
            $('li').addClass('fragment')

            if (window.location.hostname.indexOf('localhost') !== -1) {
                // only applies to presentation version
                Reveal.configure({ controls: false });
            } else {
                // only applies to public version
                $('.fragment').removeClass('fragment');
            }
            // applies to all versions
            $('code').addClass('line-numbers');

            // make all links open in new tab
            $('a').attr('target', '_blank')

        } );
        // $('section').attr('data-background-image', "backgrounds/light-metal.jpg");
        // $('section').attr('data-background-image', "backgrounds/pink.jpg");
        // $('section').attr('data-background-image', "backgrounds/white.jpg");
        $('section').attr('data-background-image', "backgrounds/sky.jpg");

    //    $('section').attr('data-background-image', "backgrounds/code.jpg");
    </script>
    
<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        width: 1100,


        transition: 'fade', // none/fade/slide/convex/concave/zoom

        math: {
            mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true},
            // https://github.com/mikemiles86/reveal-line-numbers
            {src: 'lib/js/line-numbers.js'},
            { src: 'reveal.js/plugin/math/math.js', async: true }
        ]
    });

</script>

</body>
</html>
